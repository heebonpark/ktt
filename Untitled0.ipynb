{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObbMws6uWeQsjF77UcjQk3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"ix7w5jG5SKvc","executionInfo":{"status":"error","timestamp":1724669231843,"user_tz":-540,"elapsed":2469,"user":{"displayName":"세은이보호자","userId":"03211434170377121056"}},"outputId":"b612e87e-3f66-4809-8560-94a065f17698"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-2-960d5870423e>, line 446)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-960d5870423e>\"\u001b[0;36m, line \u001b[0;32m446\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["import pandas as pd\n","import os\n","import glob\n","import zipfile\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from openpyxl import Workbook\n","from openpyxl.utils.dataframe import dataframe_to_rows\n","from openpyxl.styles import Border, Side, Alignment, PatternFill, Font\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","from difflib import SequenceMatcher\n","from datetime import datetime\n","\n","# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 한글 폰트 설치 및 설정\n","!apt-get install -y fonts-nanum\n","plt.rcParams['font.family'] = 'NanumGothic'\n","\n","# 압축 파일 경로 및 압축 해제 경로 설정\n","zip_file_path = '/content/drive/My Drive/회사업무/영업기회0801-23/LOCALDATA_NOWMON_CSV-3.zip'  # 실제 파일 경로로 변경\n","extract_folder = '/content/extracted_data'\n","\n","# 폴더가 없으면 생성\n","os.makedirs(extract_folder, exist_ok=True)\n","\n","# 압축 해제\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_folder)\n","    print(\"Files extracted successfully.\")  # Add a confirmation message\n","except FileNotFoundError:\n","    print(f\"Error: Specified zip file '{zip_file_path}' not found. Please check the path.\")\n","    exit(1)\n","except Exception as e:\n","    print(f\"Error extracting files: {e}\")  # Catch other potential errors\n","    exit(1)\n","\n","# 압축 해제된 폴더에서 모든 CSV 파일 목록 가져오기\n","all_files = glob.glob(os.path.join(extract_folder, \"**/*.csv\"), recursive=True)\n","\n","print(\"Found CSV files:\", all_files)  # Print the list of found CSV files\n","\n","if len(all_files) == 0:\n","    print(\"Warning: No CSV files found in the specified directory. Proceeding with an empty DataFrame.\")\n","    dfs = []  # 빈 리스트로 초기화\n","else:\n","    # 각 파일을 읽어서 하나의 DataFrame으로 병합\n","    dfs = []\n","    for file in all_files:\n","        try:\n","            df = pd.read_csv(file, encoding='cp949', on_bad_lines='skip', dtype=str, low_memory=False)\n","            # 주소라는 키워드를 포함한 열 확인\n","            address_columns = [col for col in df.columns if '주소' in col]\n","            if not address_columns:\n","                print(f\"No address column found in file: {file}\")\n","                continue\n","            # '서울', '경기', '강원'이 포함된 행 필터링\n","            df_filtered = df[df[address_columns[0]].str.contains('서울|경기|강원', na=False)]\n","            dfs.append(df_filtered)\n","            print(f\"Successfully read and filtered file: {file}\")\n","        except Exception as e:\n","            print(f\"Error reading file {file}: {e}\")\n","\n","if len(dfs) == 0:\n","    concatenated_df = pd.DataFrame()  # 이전 단계에서 파일이 없을 경우 빈 DataFrame 생성\n","else:\n","    concatenated_df = pd.concat(dfs, ignore_index=True)\n","    # 중복된 행 제거: 사업장명, 소재지전체주소, 영업상태명이 동일한 경우 하나만 남기고 제거\n","    concatenated_df.drop_duplicates(subset=['사업장명', '소재지전체주소', '영업상태명'], inplace=True)\n","\n","    # '인허가일자' 기준으로 내림차순 정렬\n","    if '인허가일자' in concatenated_df.columns:\n","        concatenated_df['인허가일자'] = pd.to_datetime(concatenated_df['인허가일자'], format='%Y%m%d', errors='coerce')\n","        concatenated_df.sort_values(by='인허가일자', ascending=False, inplace=True)\n","\n","# 필요한 열만 선택하여 필터링\n","selected_columns = ['소재지전체주소', '도로명전체주소', '도로명우편번호', '사업장명', '개방서비스명', '인허가일자', '인허가취소', '영업상태명', '폐업일자',\n","                    '휴업시작일', '휴업종료일', '재개업일자', '소재지전화', '최종수정시점', '업태구분명', '좌표정보(X)', '좌표정보(Y)', '총면적', '소재지면적']\n","\n","# 존재하는 열만 선택\n","existing_columns = [col for col in selected_columns if col in concatenated_df.columns]\n","filtered_df = concatenated_df[existing_columns]\n","\n","# CSV 파일로 저장\n","output_dir = '/content/drive/My Drive/회사업무/영업기회0801-23'\n","os.makedirs(output_dir, exist_ok=True)\n","output_csv_path = os.path.join(output_dir, '0801-23일_병합(서울,경기,강원).csv')\n","filtered_df.to_csv(output_csv_path, index=False, encoding='cp949')\n","\n","# 엑셀 파일 경로 설정\n","file1_path = os.path.join('/content/drive/My Drive/회사업무/행안부자료/0801', '1.영업구역별_주소현행화0725.xlsx')\n","file2_path = output_csv_path  # 이전 단계에서 생성한 파일 사용\n","\n","# 파일 경로 확인\n","if not os.path.exists(file1_path):\n","    raise FileNotFoundError(f\"{file1_path} 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n","if not os.path.exists(file2_path):\n","    raise FileNotFoundError(f\"{file2_path} 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n","\n","# 엑셀 파일 읽기\n","df1 = pd.read_excel(file1_path)\n","\n","# Check if df2 can be read and print its shape\n","try:\n","    df2 = pd.read_csv(file2_path, encoding='cp949')\n","    print(\"Shape of df2:\", df2.shape)  # Print the shape of df2 to see if it's empty\n","except pd.errors.EmptyDataError:\n","    print(\"Error: The CSV file at\", file2_path, \"is empty or has no columns.\")\n","except Exception as e:\n","    print(\"Error reading file\", file2_path, \":\", e)\n","\n","# 주소 정규화 함수\n","def normalize_address(address):\n","    if pd.isna(address):\n","        return None\n","    address = address.strip()\n","    address = address.replace('강원특별자치도', '강원도')\n","    address = address.replace('서울특별시', '서울시')\n","    address = address.replace(' ', '')\n","    address = address.replace('-', '')\n","    if '*' in address or len(address) < 10:  # 길이가 너무 짧은 경우는 None으로 처리\n","        return None\n","    return address\n","\n","# 유사도 비교를 위한 다양한 방식 추가\n","def get_best_match(address, df_choices, threshold=0.7):\n","    if pd.isna(address):\n","        return None\n","\n","    # 유사도 측정을 위한 다양한 방법 사용\n","    best_score = 0\n","    best_match = None\n","\n","    for choice in df_choices:\n","        # TF-IDF 및 코사인 유사도\n","        tfidf_vec = vectorizer.transform([choice])\n","        cosine_sim = cosine_similarity(vectorizer.transform([address]), tfidf_vec).flatten()[0]\n","\n","        # 레벤슈타인 거리 기반 유사도 (텍스트 유사도)\n","        seq_match = SequenceMatcher(None, address, choice)\n","        seq_similarity = seq_match.ratio()\n","\n","        # 최고 유사도 채택\n","        score = max(cosine_sim, seq_similarity)\n","        if score > best_score:\n","            best_score = score\n","            best_match = choice\n","\n","    if best_score >= threshold:\n","        return best_match\n","    return None\n","\n","# df1의 주소 정규화\n","df1['full_address'] = df1[['주소시', '주소군구', '주소동']].astype(str).agg(' '.join, axis=1).apply(normalize_address)\n","df1 = df1.dropna(subset=['full_address'])\n","\n","# df2의 주소 정규화\n","df2['소재지전체주소'] = df2['소재지전체주소'].astype(str).apply(normalize_address)\n","df2['도로명전체주소'] = df2['도로명전체주소'].astype(str).apply(normalize_address)\n","df2 = df2.dropna(subset=['소재지전체주소', '도로명전체주소'])\n","\n","# TF-IDF 벡터화\n","vectorizer = TfidfVectorizer().fit(df1['full_address'])\n","tfidf_matrix = vectorizer.transform(df1['full_address'])\n","\n","# 유사한 주소 매핑\n","choices = df1['full_address'].tolist()\n","df2['matched_address_소재지'] = df2['소재지전체주소'].apply(lambda x: get_best_match(x, choices))\n","df2['matched_address_도로명'] = df2['도로명전체주소'].apply(lambda x: get_best_match(x, choices))\n","\n","df2['matched_address'] = df2.apply(lambda x: x['matched_address_소재지'] if pd.notna(x['matched_address_소재지']) else x['matched_address_도로명'], axis=1)\n","\n","# 매핑되지 않은 항목 확인\n","unmatched = df2[df2['matched_address'].isna()]\n","print(\"매핑되지 않은 항목 수:\", len(unmatched))\n","\n","# 평수 계산을 위한 열 존재 확인 및 병합\n","merge_columns = ['full_address', '관리지사', 'SP담당']\n","if '총면적' in df1.columns:\n","    merge_columns.append('총면적')\n","if '소재지면적' in df1.columns:\n","    merge_columns.append('소재지면적')\n","\n","df_merged = df2.merge(df1[merge_columns], left_on='matched_address', right_on='full_address', how='left', suffixes=('', '_df1'))\n","\n","# 매핑 결과 확인\n","print(\"매핑 후 관리지사 및 SP담당이 비어있는 행 수:\", df_merged[['관리지사', 'SP담당']].isna().sum())\n","\n","# 평수 계산 (1평 = 3.305785 m^2)\n","def calculate_area(row):\n","    if '소재지면적' in row and pd.notna(row['소재지면적']):\n","        return round(float(row['소재지면적']) / 3.305785, 2)\n","    elif '총면적' in row and pd.notna(row['총면적']):\n","        return round(float(row['총면적']) / 3.305785, 2)\n","    else:\n","        return None\n","\n","df_merged['평수'] = df_merged.apply(calculate_area, axis=1)\n","\n","# 불필요한 열 제외하고 필요한 열만 선택\n","columns_to_keep = ['관리지사', 'SP담당', '사업장명', '개방서비스명', '업태구분명', '평수', '소재지전체주소', '도로명전체주소', '소재지전화', '폐업일자', '재개업일자', '영업상태명']\n","df_filtered = df_merged[columns_to_keep]\n","\n","# 중복된 항목 제거\n","df_filtered.drop_duplicates(inplace=True)\n","\n","# 평수 내림차순 정렬\n","df_filtered_sorted = df_filtered.sort_values(by='평수', ascending=False)\n","\n","# NaN 값 처리\n","df_filtered_sorted['관리지사'] = df_filtered_sorted['관리지사'].fillna('Unknown')\n","df_filtered_sorted['SP담당'] = df_filtered_sorted['SP담당'].fillna('Unknown')\n","\n","# 네이버 지도 하이퍼링크 생성 함수\n","def create_naver_map_link(address):\n","    return f\"https://map.naver.com/v5/search/{address}\"\n","\n","# 엑셀 파일에 네이버 지도 링크 추가하는 함수\n","def add_naver_map_links(ws, address_col_idx):\n","    ws.insert_cols(1)  # 첫 번째 열에 열 추가\n","    ws.cell(row=1, column=1, value=\"네이버 지도 링크\")  # 새 열에 헤더 추가\n","\n","    for row in range(2, ws.max_row + 1):\n","        address = ws.cell(row=row, column=address_col_idx + 1).value\n","        if address:\n","            link = create_naver_map_link(address)\n","            ws.cell(row=row, column=1).hyperlink = link\n","            ws.cell(row=row, column=1).value = \"네이버 지도 보기\"\n","            ws.cell(row=row, column=1).style = \"Hyperlink\"\n","\n","# 엑셀 파일에 데이터를 저장하고 스타일을 설정하는 함수\n","def save_to_excel(df, file_path):\n","    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n","        # 전체 시트 저장\n","        df.to_excel(writer, index=False, sheet_name='전체')\n","\n","        # 영업/정상 시트 저장\n","        df_active = df[df['영업상태명'].isin(['영업/정상'])]\n","\n","        # 필터링된 데이터 개수 확인\n","        print(f\"전체 시트에서 영업/정상 데이터 수: {len(df_active)}\")\n","\n","        df_active.to_excel(writer, index=False, sheet_name='영업_정상')\n","\n","        # 휴업 외 시트 저장 (영업/정상이 아닌 경우)\n","        df_non_active = df[~df['영업상태명'].isin(['영업/정상'])]\n","        df_non_active.to_excel(writer, index=False, sheet_name='휴업 외')\n","\n","        workbook = writer.book\n","        thin_border = Border(left=Side(style='thin', color='D3D3D3'),\n","                             right=Side(style='thin', color='D3D3D3'),\n","                             top=Side(style='thin', color='D3D3D3'),\n","                             bottom=Side(style='thin', color='D3D3D3'))\n","        header_fill = PatternFill(start_color=\"000080\", end_color=\"000080\", fill_type=\"solid\")\n","        header_font = Font(color=\"FFFFFF\", bold=True)\n","\n","        # 스타일 설정 함수\n","        def set_style(worksheet):\n","            for cell in worksheet[1]:\n","                cell.fill = header_fill\n","                cell.font = header_font\n","                cell.border = thin_border\n","                cell.alignment = Alignment(horizontal='center', vertical='center')\n","            for row in worksheet.iter_rows(min_row=2):\n","                for cell in row:\n","                    cell.border = thin_border\n","                    cell.alignment = Alignment(horizontal='center', vertical='center')\n","            for col in worksheet.columns:\n","                max_length = 0\n","                column = col[0].column_letter\n","                for cell in col:\n","                    try:\n","                        if len(str(cell.value)) > max_length:\n","                            max_length = len(cell.value)\n","                    except Exception as e:\n","                        pass\n","                adjusted_width = (max_length + 2)\n","                worksheet.column_dimensions[column].width = adjusted_width\n","\n","        set_style(writer.sheets['전체'])\n","        set_style(writer.sheets['영업_정상'])\n","        set_style(writer.sheets['휴업 외'])\n","\n","        # 네이버 지도 링크 추가\n","        # '소재지전체주소'는 G열이므로 컬럼 인덱스는 7-1=6\n","        add_naver_map_links(writer.sheets['전체'], 6)\n","        add_naver_map_links(writer.sheets['영업_정상'], 6)\n","        add_naver_map_links(writer.sheets['휴업 외'], 6)\n","\n","# 전체 데이터를 바탕으로 시각화 및 파일 저장\n","output_dir = '/content/drive/My Drive/회사업무/영업기회0801-23'\n","for manager in df_filtered_sorted['관리지사'].unique():\n","    manager_dir = os.path.join(output_dir, manager)\n","    os.makedirs(manager_dir, exist_ok=True)\n","    df_manager = df_filtered_sorted[df_filtered_sorted['관리지사'] == manager]\n","\n","    for sp in df_manager['SP담당'].unique():\n","        df_sp = df_manager[df_manager['SP담당'] == sp]\n","        sp_file_path = os.path.join(manager_dir, f'{manager}_{sp}_0801-23.xlsx')\n","        save_to_excel(df_sp, sp_file_path)\n","\n","# 전체 데이터를 저장\n","total_file_path = os.path.join(output_dir, '0801-23_전체_최종결과물.xlsx')\n","save_to_excel(df_filtered_sorted, total_file_path)\n","\n","# 전체 데이터를 바탕으로 시각화\n","status_counts = df_filtered_sorted.groupby(['관리지사', '영업상태명']).size().unstack(fill_value=0)\n","status_counts = status_counts.loc[status_counts.sum(axis=1).sort_values(ascending=False).index]\n","\n","# 시각화 및 PDF 저장\n","pdf_path = os.path.join(output_dir, '전체_영업상태명_집계현황.pdf')\n","with PdfPages(pdf_path) as pdf:\n","    # 시각화 1: 관리지사별 영업상태명 집계현황\n","    fig1, ax1 = plt.subplots(figsize=(14, 10))\n","    status_counts.plot(kind='bar', stacked=True, ax=ax1, color=['skyblue', 'salmon'])\n","    ax1.set_title('관리지사별 영업상태명 집계현황', fontsize=16)\n","    ax1.set_xlabel('관리지사', fontsize=12)\n","    ax1.set_ylabel('건수', fontsize=12)\n","    ax1.legend(title='영업상태명', fontsize=10, title_fontsize='13')\n","    plt.xticks(rotation=90)\n","    plt.tight_layout()\n","    pdf.savefig(fig1)\n","    plt.close(fig1)\n","\n","    # 시각화 2: SP담당자별 영업상태명 집계현황\n","    df_filtered_sorted['SP담당자'] = df_filtered_sorted['관리지사'].str.replace('지사', '') + '-' + df_filtered_sorted['SP담당']\n","    status_counts_sp = df_filtered_sorted.groupby(['SP담당자', '영업상태명']).size().unstack(fill_value=0)\n","    status_counts_sp = status_counts_sp.loc[status_counts_sp.sum(axis=1).sort_values(ascending=True).index]\n","\n","    fig2, ax2 = plt.subplots(figsize=(16, 12))\n","    status_counts_sp.plot(kind='barh', stacked=True, ax=ax2, color=['#4caf50', '#f44336'])\n","    ax2.set_title('SP담당자별 영업상태명 집계현황', fontsize=18)\n","    ax2.set_xlabel('건수', fontsize=14)\n","    ax2.set_ylabel('SP담당자', fontsize=14)\n","    plt.tight_layout()\n","    pdf.savefig(fig2)\n","    plt.close(fig2)\n","\n","print(f\"전체 영업상태명 집계현황 PDF가 생성되었습니다: {pdf_path}\")\n","\n","# EDA를 위한 함수 정의\n","def eda_analysis(df, condition=None):\n","    if condition:\n","        df = df.query(condition)\n","\n","    # 관리지사별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['관리지사'].value_counts().plot(kind='bar', color='skyblue')\n","    plt.title('관리지사별 데이터 분포')\n","    plt.xlabel('관리지사')\n","    plt.ylabel('건수')\n","    plt.show()\n","\n","    # SP담당별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['SP담당'].value_counts().plot(kind='bar', color='salmon')\n","    plt.title('SP담당별 데이터 분포')\n","    plt.xlabel('SP담당')\n","    plt.ylabel('건수')\n","    plt.show()\n","\n","    # 영업상태명별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['영업상태명'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=['#4caf50', '#f44336'])\n","    plt.title('영업상태명별 데이터 비율')\n","    plt.ylabel('')\n","    plt.show()\n","\n","    # 개방서비스명별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['개방서비스명'].value_counts().plot(kind='barh', color='lightgreen')\n","    plt.title('개방서비스명별 데이터 분포')\n","    plt.xlabel('건수')\n","    plt.ylabel('개방서비스명')\n","    plt.show()\n","\n","# EDA 함수 실행 예시\n","eda_analysis(df_filtered_sorted, condition=\"관리지사 == '서울지사' and 영업상태명 == '영업/정상'\")\n","\n","# \"1.14일_병합(서울,경기,강원).csv\" 파일에서 인허가일자, 최종수정시점 헤더 추가하고\n","# 인허가일자를 \"2024-08-01\"부터 \"2024-08-16\"까지 필터링\n","\n","start_date = pd.to_datetime('2024-08-01')\n","end_date = pd.to_datetime('2024-08-23')\n","\n","df_filtered_sorted['인허가일자'] = pd.to_datetime(df_filtered_sorted['인허가일자'], errors='coerce')\n","df_filtered_sorted['최종수정시점'] = pd.to_datetime(df_filtered_sorted['최종수정시점'], errors='coerce')\n","\n","# \"1.14일_병합(서울,경기,강원).csv\" 파일에서 소재지전체주소, 사업장명, 소재지전화가 같은 것 중\n","# 최종수정시점이 가장 최근인 것만 남기고 나머지는 삭제\n","df_filtered_sorted.sort_values(by='최종수정시점', ascending=False, inplace=True)\n","df_filtered_sorted.drop_duplicates(subset=['소재지전체주소', '사업장명', '소재지전화'], keep='first', inplace=True)\n","\n","# 인허가일자 범위 필터링\n","df_filtered_sorted = df_filtered_sorted[\n","    (df_filtered_sorted['인허가일자'] >= start_date) &\n","    (df_filtered_sorted['인허가일자'] <= end_date)\n","]\n","\n","# 영업상태명 헤더가 \"영업/정상\"인 데이터 필터링\n","df_active = df_filtered_sorted[df_filtered_sorted['영업상태명'] == '영업/정상']\n","\n","# 폐업일자, 휴업시작일 필터링 (2024-08-01 ~ 2024-08-16)\n","df_closed_or_suspended = df_filtered_sorted[\n","    (df_filtered_sorted['폐업일자'].between(start_date, end_date)) |\n","    (df_filtered_sorted['휴업시작일'].between(start_date, end_date))\n","]\n","\n","# 결과를 엑셀 파일에 저장 (전체, 영업/정상, 휴업 외 시트)\n","final_output_path = os.path.join(output_dir, '최종결과물_2024-0823.xlsx')\n","with pd.ExcelWriter(final_output_path, engine='openpyxl') as writer:\n","    df_filtered_sorted.to_excel(writer, index=False, sheet_name='전체')\n","    df_active.to_excel(writer, index=False, sheet_name='영업_정상')\n","    df_closed_or_suspended.to_excel(writer, index=False, sheet_name='휴업 외')\n","\n","    # 스타일 설정\n","    workbook = writer.book\n","    thin_border = Border(left=Side(style='thin', color='D3D3D3'),\n","                         right=Side(style='thin', color='D3D3D3'),\n","                         top=Side(style='thin', color='D3D3D3'),\n","                         bottom=Side(style='thin', color='D3D3D3'))\n","    header_fill = PatternFill(start_color=\"000080\", end_color=\"000080\", fill_type=\"solid\")\n","    header_font = Font(color=\"FFFFFF\", bold=True)\n","\n","    def set_style(worksheet):\n","        for cell in worksheet[1]:\n","            cell.fill = header_fill\n","            cell.font = header_font\n","            cell.border = thin_border\n","            cell.alignment = Alignment(horizontal='center', vertical='center')\n","        for row in worksheet.iter_rows(min_row=2):\n","            for cell in row:\n","                cell.border = thin_border\n","                cell.alignment = Alignment(horizontal='center', vertical='center')\n","        for col in worksheet.columns:\n","            max_length = 0\n","            column = col[0].column_letter\n","            for cell in col:\n","                try:\n","                    if len(str(cell.value)) > max_length:\n","                        max_length = len(cell.value)\n","                    except Exception as e:\n","                        pass\n","                adjusted_width = (max_length + 2)\n","                worksheet.column_dimensions[column].width = adjusted_width\n","\n","    set_style(writer.sheets['전체'])\n","    set_style(writer.sheets['영업_정상'])\n","    set_style(writer.sheets['휴업 외'])\n","\n","print(f\"최종 엑셀 파일이 생성되었습니다: {final_output_path}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"--e7fSerSNgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import glob\n","import zipfile\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from openpyxl import Workbook\n","from openpyxl.utils.dataframe import dataframe_to_rows\n","from openpyxl.styles import Border, Side, Alignment, PatternFill, Font\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","from difflib import SequenceMatcher\n","from datetime import datetime\n","\n","# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 한글 폰트 설치 및 설정\n","!apt-get install -y fonts-nanum\n","plt.rcParams['font.family'] = 'NanumGothic'\n","\n","# 압축 파일 경로 및 압축 해제 경로 설정\n","zip_file_path = '/content/drive/My Drive/회사업무/영업기회0801-23/LOCALDATA_NOWMON_CSV-3.zip'  # 실제 파일 경로로 변경\n","extract_folder = '/content/extracted_data'\n","\n","# 폴더가 없으면 생성\n","os.makedirs(extract_folder, exist_ok=True)\n","\n","# 압축 해제\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_folder)\n","    print(\"Files extracted successfully.\")  # Add a confirmation message\n","except FileNotFoundError:\n","    print(f\"Error: Specified zip file '{zip_file_path}' not found. Please check the path.\")\n","    exit(1)\n","except Exception as e:\n","    print(f\"Error extracting files: {e}\")  # Catch other potential errors\n","    exit(1)\n","\n","# 압축 해제된 폴더에서 모든 CSV 파일 목록 가져오기\n","all_files = glob.glob(os.path.join(extract_folder, \"**/*.csv\"), recursive=True)\n","\n","print(\"Found CSV files:\", all_files)  # Print the list of found CSV files\n","\n","if len(all_files) == 0:\n","    print(\"Warning: No CSV files found in the specified directory. Proceeding with an empty DataFrame.\")\n","    dfs = []  # 빈 리스트로 초기화\n","else:\n","    # 각 파일을 읽어서 하나의 DataFrame으로 병합\n","    dfs = []\n","    for file in all_files:\n","        try:\n","            df = pd.read_csv(file, encoding='cp949', on_bad_lines='skip', dtype=str, low_memory=False)\n","            # 주소라는 키워드를 포함한 열 확인\n","            address_columns = [col for col in df.columns if '주소' in col]\n","            if not address_columns:\n","                print(f\"No address column found in file: {file}\")\n","                continue\n","            # '서울', '경기', '강원'이 포함된 행 필터링\n","            df_filtered = df[df[address_columns[0]].str.contains('서울|경기|강원', na=False)]\n","            dfs.append(df_filtered)\n","            print(f\"Successfully read and filtered file: {file}\")\n","        except Exception as e:\n","            print(f\"Error reading file {file}: {e}\")\n","\n","if len(dfs) == 0:\n","    concatenated_df = pd.DataFrame()  # 이전 단계에서 파일이 없을 경우 빈 DataFrame 생성\n","else:\n","    concatenated_df = pd.concat(dfs, ignore_index=True)\n","    # 중복된 행 제거: 사업장명, 소재지전체주소, 영업상태명이 동일한 경우 하나만 남기고 제거\n","    concatenated_df.drop_duplicates(subset=['사업장명', '소재지전체주소', '영업상태명'], inplace=True)\n","\n","    # '인허가일자' 기준으로 내림차순 정렬\n","    if '인허가일자' in concatenated_df.columns:\n","        concatenated_df['인허가일자'] = pd.to_datetime(concatenated_df['인허가일자'], format='%Y%m%d', errors='coerce')\n","        concatenated_df.sort_values(by='인허가일자', ascending=False, inplace=True)\n","\n","# 필요한 열만 선택하여 필터링\n","selected_columns = ['소재지전체주소', '도로명전체주소', '도로명우편번호', '사업장명', '개방서비스명', '인허가일자', '인허가취소', '영업상태명', '폐업일자',\n","                    '휴업시작일', '휴업종료일', '재개업일자', '소재지전화', '최종수정시점', '업태구분명', '좌표정보(X)', '좌표정보(Y)', '총면적', '소재지면적']\n","\n","# 존재하는 열만 선택\n","existing_columns = [col for col in selected_columns if col in concatenated_df.columns]\n","filtered_df = concatenated_df[existing_columns]\n","\n","# CSV 파일로 저장\n","output_dir = '/content/drive/My Drive/회사업무/영업기회0801-23'\n","os.makedirs(output_dir, exist_ok=True)\n","output_csv_path = os.path.join(output_dir, '0801-23일_병합(서울,경기,강원).csv')\n","filtered_df.to_csv(output_csv_path, index=False, encoding='cp949')\n","\n","# 엑셀 파일 경로 설정\n","file1_path = os.path.join('/content/drive/My Drive/회사업무/행안부자료/0801', '1.영업구역별_주소현행화0725.xlsx')\n","file2_path = output_csv_path  # 이전 단계에서 생성한 파일 사용\n","\n","# 파일 경로 확인\n","if not os.path.exists(file1_path):\n","    raise FileNotFoundError(f\"{file1_path} 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n","if not os.path.exists(file2_path):\n","    raise FileNotFoundError(f\"{file2_path} 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n","\n","# 엑셀 파일 읽기\n","df1 = pd.read_excel(file1_path)\n","\n","# Check if df2 can be read and print its shape\n","try:\n","    df2 = pd.read_csv(file2_path, encoding='cp949')\n","    print(\"Shape of df2:\", df2.shape)  # Print the shape of df2 to see if it's empty\n","except pd.errors.EmptyDataError:\n","    print(\"Error: The CSV file at\", file2_path, \"is empty or has no columns.\")\n","except Exception as e:\n","    print(\"Error reading file\", file2_path, \":\", e)\n","\n","# 주소 정규화 함수\n","def normalize_address(address):\n","    if pd.isna(address):\n","        return None\n","    address = address.strip()\n","    address = address.replace('강원특별자치도', '강원도')\n","    address = address.replace('서울특별시', '서울시')\n","    address = address.replace(' ', '')\n","    address = address.replace('-', '')\n","    if '*' in address or len(address) < 10:  # 길이가 너무 짧은 경우는 None으로 처리\n","        return None\n","    return address\n","\n","# 유사도 비교를 위한 다양한 방식 추가\n","def get_best_match(address, df_choices, threshold=0.7):\n","    if pd.isna(address):\n","        return None\n","\n","    # 유사도 측정을 위한 다양한 방법 사용\n","    best_score = 0\n","    best_match = None\n","\n","    for choice in df_choices:\n","        # TF-IDF 및 코사인 유사도\n","        tfidf_vec = vectorizer.transform([choice])\n","        cosine_sim = cosine_similarity(vectorizer.transform([address]), tfidf_vec).flatten()[0]\n","\n","        # 레벤슈타인 거리 기반 유사도 (텍스트 유사도)\n","        seq_match = SequenceMatcher(None, address, choice)\n","        seq_similarity = seq_match.ratio()\n","\n","        # 최고 유사도 채택\n","        score = max(cosine_sim, seq_similarity)\n","        if score > best_score:\n","            best_score = score\n","            best_match = choice\n","\n","    if best_score >= threshold:\n","        return best_match\n","    return None\n","\n","# df1의 주소 정규화\n","df1['full_address'] = df1[['주소시', '주소군구', '주소동']].astype(str).agg(' '.join, axis=1).apply(normalize_address)\n","df1 = df1.dropna(subset=['full_address'])\n","\n","# df2의 주소 정규화\n","df2['소재지전체주소'] = df2['소재지전체주소'].astype(str).apply(normalize_address)\n","df2['도로명전체주소'] = df2['도로명전체주소'].astype(str).apply(normalize_address)\n","df2 = df2.dropna(subset=['소재지전체주소', '도로명전체주소'])\n","\n","# TF-IDF 벡터화\n","vectorizer = TfidfVectorizer().fit(df1['full_address'])\n","tfidf_matrix = vectorizer.transform(df1['full_address'])\n","\n","# 유사한 주소 매핑\n","choices = df1['full_address'].tolist()\n","df2['matched_address_소재지'] = df2['소재지전체주소'].apply(lambda x: get_best_match(x, choices))\n","df2['matched_address_도로명'] = df2['도로명전체주소'].apply(lambda x: get_best_match(x, choices))\n","\n","df2['matched_address'] = df2.apply(lambda x: x['matched_address_소재지'] if pd.notna(x['matched_address_소재지']) else x['matched_address_도로명'], axis=1)\n","\n","# 매핑되지 않은 항목 확인\n","unmatched = df2[df2['matched_address'].isna()]\n","print(\"매핑되지 않은 항목 수:\", len(unmatched))\n","\n","# 평수 계산을 위한 열 존재 확인 및 병합\n","merge_columns = ['full_address', '관리지사', 'SP담당']\n","if '총면적' in df1.columns:\n","    merge_columns.append('총면적')\n","if '소재지면적' in df1.columns:\n","    merge_columns.append('소재지면적')\n","\n","df_merged = df2.merge(df1[merge_columns], left_on='matched_address', right_on='full_address', how='left', suffixes=('', '_df1'))\n","\n","# 매핑 결과 확인\n","print(\"매핑 후 관리지사 및 SP담당이 비어있는 행 수:\", df_merged[['관리지사', 'SP담당']].isna().sum())\n","\n","# 평수 계산 (1평 = 3.305785 m^2)\n","def calculate_area(row):\n","    if '소재지면적' in row and pd.notna(row['소재지면적']):\n","        return round(float(row['소재지면적']) / 3.305785, 2)\n","    elif '총면적' in row and pd.notna(row['총면적']):\n","        return round(float(row['총면적']) / 3.305785, 2)\n","    else:\n","        return None\n","\n","df_merged['평수'] = df_merged.apply(calculate_area, axis=1)\n","\n","# 불필요한 열 제외하고 필요한 열만 선택\n","columns_to_keep = ['관리지사', 'SP담당', '사업장명', '개방서비스명', '업태구분명', '평수', '소재지전체주소', '도로명전체주소', '소재지전화', '폐업일자', '재개업일자', '영업상태명']\n","df_filtered = df_merged[columns_to_keep]\n","\n","# 중복된 항목 제거\n","df_filtered.drop_duplicates(inplace=True)\n","\n","# 평수 내림차순 정렬\n","df_filtered_sorted = df_filtered.sort_values(by='평수', ascending=False)\n","\n","# NaN 값 처리\n","df_filtered_sorted['관리지사'] = df_filtered_sorted['관리지사'].fillna('Unknown')\n","df_filtered_sorted['SP담당'] = df_filtered_sorted['SP담당'].fillna('Unknown')\n","\n","# 네이버 지도 하이퍼링크 생성 함수\n","def create_naver_map_link(address):\n","    return f\"https://map.naver.com/v5/search/{address}\"\n","\n","# 엑셀 파일에 네이버 지도 링크 추가하는 함수\n","def add_naver_map_links(ws, address_col_idx):\n","    ws.insert_cols(1)  # 첫 번째 열에 열 추가\n","    ws.cell(row=1, column=1, value=\"네이버 지도 링크\")  # 새 열에 헤더 추가\n","\n","    for row in range(2, ws.max_row + 1):\n","        address = ws.cell(row=row, column=address_col_idx + 1).value\n","        if address:\n","            link = create_naver_map_link(address)\n","            ws.cell(row=row, column=1).hyperlink = link\n","            ws.cell(row=row, column=1).value = \"네이버 지도 보기\"\n","            ws.cell(row=row, column=1).style = \"Hyperlink\"\n","\n","# 엑셀 파일에 데이터를 저장하고 스타일을 설정하는 함수\n","def save_to_excel(df, file_path):\n","    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n","        # 전체 시트 저장\n","        df.to_excel(writer, index=False, sheet_name='전체')\n","\n","        # 영업/정상 시트 저장\n","        df_active = df[df['영업상태명'].isin(['영업/정상'])]\n","\n","        # 필터링된 데이터 개수 확인\n","        print(f\"전체 시트에서 영업/정상 데이터 수: {len(df_active)}\")\n","\n","        df_active.to_excel(writer, index=False, sheet_name='영업_정상')\n","\n","        # 휴업 외 시트 저장 (영업/정상이 아닌 경우)\n","        df_non_active = df[~df['영업상태명'].isin(['영업/정상'])]\n","        df_non_active.to_excel(writer, index=False, sheet_name='휴업 외')\n","\n","        workbook = writer.book\n","        thin_border = Border(left=Side(style='thin', color='D3D3D3'),\n","                             right=Side(style='thin', color='D3D3D3'),\n","                             top=Side(style='thin', color='D3D3D3'),\n","                             bottom=Side(style='thin', color='D3D3D3'))\n","        header_fill = PatternFill(start_color=\"000080\", end_color=\"000080\", fill_type=\"solid\")\n","        header_font = Font(color=\"FFFFFF\", bold=True)\n","\n","        # 스타일 설정 함수\n","        def set_style(worksheet):\n","            for cell in worksheet[1]:\n","                cell.fill = header_fill\n","                cell.font = header_font\n","                cell.border = thin_border\n","                cell.alignment = Alignment(horizontal='center', vertical='center')\n","            for row in worksheet.iter_rows(min_row=2):\n","                for cell in row:\n","                    cell.border = thin_border\n","                    cell.alignment = Alignment(horizontal='center', vertical='center')\n","            for col in worksheet.columns:\n","                max_length = 0\n","                column = col[0].column_letter\n","                for cell in col:\n","                    try:\n","                        if len(str(cell.value)) > max_length:\n","                            max_length = len(cell.value)\n","                    except Exception as e:\n","                        pass\n","                adjusted_width = (max_length + 2)\n","                worksheet.column_dimensions[column].width = adjusted_width\n","\n","        set_style(writer.sheets['전체'])\n","        set_style(writer.sheets['영업_정상'])\n","        set_style(writer.sheets['휴업 외'])\n","\n","        # 네이버 지도 링크 추가\n","        # '소재지전체주소'는 G열이므로 컬럼 인덱스는 7-1=6\n","        add_naver_map_links(writer.sheets['전체'], 6)\n","        add_naver_map_links(writer.sheets['영업_정상'], 6)\n","        add_naver_map_links(writer.sheets['휴업 외'], 6)\n","\n","# 전체 데이터를 바탕으로 시각화 및 파일 저장\n","output_dir = '/content/drive/My Drive/회사업무/영업기회0801-23'\n","for manager in df_filtered_sorted['관리지사'].unique():\n","    manager_dir = os.path.join(output_dir, manager)\n","    os.makedirs(manager_dir, exist_ok=True)\n","    df_manager = df_filtered_sorted[df_filtered_sorted['관리지사'] == manager]\n","\n","    for sp in df_manager['SP담당'].unique():\n","        df_sp = df_manager[df_manager['SP담당'] == sp]\n","        sp_file_path = os.path.join(manager_dir, f'{manager}_{sp}_0801-23.xlsx')\n","        save_to_excel(df_sp, sp_file_path)\n","\n","# 전체 데이터를 저장\n","total_file_path = os.path.join(output_dir, '0801-23_전체_최종결과물.xlsx')\n","save_to_excel(df_filtered_sorted, total_file_path)\n","\n","# 전체 데이터를 바탕으로 시각화\n","status_counts = df_filtered_sorted.groupby(['관리지사', '영업상태명']).size().unstack(fill_value=0)\n","status_counts = status_counts.loc[status_counts.sum(axis=1).sort_values(ascending=False).index]\n","\n","# 시각화 및 PDF 저장\n","pdf_path = os.path.join(output_dir, '전체_영업상태명_집계현황.pdf')\n","with PdfPages(pdf_path) as pdf:\n","    # 시각화 1: 관리지사별 영업상태명 집계현황\n","    fig1, ax1 = plt.subplots(figsize=(14, 10))\n","    status_counts.plot(kind='bar', stacked=True, ax=ax1, color=['skyblue', 'salmon'])\n","    ax1.set_title('관리지사별 영업상태명 집계현황', fontsize=16)\n","    ax1.set_xlabel('관리지사', fontsize=12)\n","    ax1.set_ylabel('건수', fontsize=12)\n","    ax1.legend(title='영업상태명', fontsize=10, title_fontsize='13')\n","    plt.xticks(rotation=90)\n","    plt.tight_layout()\n","    pdf.savefig(fig1)\n","    plt.close(fig1)\n","\n","    # 시각화 2: SP담당자별 영업상태명 집계현황\n","    df_filtered_sorted['SP담당자'] = df_filtered_sorted['관리지사'].str.replace('지사', '') + '-' + df_filtered_sorted['SP담당']\n","    status_counts_sp = df_filtered_sorted.groupby(['SP담당자', '영업상태명']).size().unstack(fill_value=0)\n","    status_counts_sp = status_counts_sp.loc[status_counts_sp.sum(axis=1).sort_values(ascending=True).index]\n","\n","    fig2, ax2 = plt.subplots(figsize=(16, 12))\n","    status_counts_sp.plot(kind='barh', stacked=True, ax=ax2, color=['#4caf50', '#f44336'])\n","    ax2.set_title('SP담당자별 영업상태명 집계현황', fontsize=18)\n","    ax2.set_xlabel('건수', fontsize=14)\n","    ax2.set_ylabel('SP담당자', fontsize=14)\n","    plt.tight_layout()\n","    pdf.savefig(fig2)\n","    plt.close(fig2)\n","\n","print(f\"전체 영업상태명 집계현황 PDF가 생성되었습니다: {pdf_path}\")\n","\n","# EDA를 위한 함수 정의\n","def eda_analysis(df, condition=None):\n","    if condition:\n","        df = df.query(condition)\n","\n","    # 관리지사별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['관리지사'].value_counts().plot(kind='bar', color='skyblue')\n","    plt.title('관리지사별 데이터 분포')\n","    plt.xlabel('관리지사')\n","    plt.ylabel('건수')\n","    plt.show()\n","\n","    # SP담당별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['SP담당'].value_counts().plot(kind='bar', color='salmon')\n","    plt.title('SP담당별 데이터 분포')\n","    plt.xlabel('SP담당')\n","    plt.ylabel('건수')\n","    plt.show()\n","\n","    # 영업상태명별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['영업상태명'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=['#4caf50', '#f44336'])\n","    plt.title('영업상태명별 데이터 비율')\n","    plt.ylabel('')\n","    plt.show()\n","\n","    # 개방서비스명별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['개방서비스명'].value_counts().plot(kind='barh', color='lightgreen')\n","    plt.title('개방서비스명별 데이터 분포')\n","    plt.xlabel('건수')\n","    plt.ylabel('개방서비스명')\n","    plt.show()\n","\n","# EDA 함수 실행 예시\n","eda_analysis(df_filtered_sorted, condition=\"관리지사 == '서울지사' and 영업상태명 == '영업/정상'\")\n","\n","# 인허가일자 및 최종수정시점 기준으로 데이터 필터링 및 정리\n","\n","start_date = pd.to_datetime('2024-08-01')\n","end_date = pd.to_datetime('2024-08-23')\n","\n","df_filtered_sorted['인허가일자'] = pd.to_datetime(df_filtered_sorted['인허가일자'], errors='coerce')\n","df_filtered_sorted['최종수정시점'] = pd.to_datetime(df_filtered_sorted['최종수정시점'], errors='coerce')\n","\n","# 중복된 항목 중 최신 데이터를 유지\n","df_filtered_sorted.sort_values(by='최종수정시점', ascending=False, inplace=True)\n","df_filtered_sorted.drop_duplicates(subset=['소재지전체주소', '사업장명', '소재지전화'], keep='first', inplace=True)\n","\n","# 인허가일자 범위 필터링\n","df_filtered_sorted = df_filtered_sorted[\n","    (df_filtered_sorted['인허가일자'] >= start_date) &\n","    (df_filtered_sorted['인허가일자'] <= end_date)\n","]\n","\n","# 영업상태명이 \"영업/정상\"인 데이터 필터링\n","df_active = df_filtered_sorted[df_filtered_sorted['영업상태명'] == '영업/정상']\n","\n","# 폐업일자, 휴업시작일 필터링 (2024-08-01 ~ 2024-08-16)\n","df_closed_or_suspended = df_filtered_sorted[\n","    (df_filtered_sorted['폐업일자'].between(start_date, end_date)) |\n","    (df_filtered_sorted['휴업시작일'].between(start_date, end_date))\n","]\n","\n","# 결과를 엑셀 파일에 저장 (전체, 영업/정상, 휴업 외 시트)\n","final_output_path = os.path.join(output_dir, '최종결과물_2024-0823.xlsx')\n","with pd.ExcelWriter(final_output_path, engine='openpyxl') as writer:\n","    df_filtered_sorted.to_excel(writer, index=False, sheet_name='전체')\n","    df_active.to_excel(writer, index=False, sheet_name='영업_정상')\n","    df_closed_or_suspended.to_excel(writer, index=False, sheet_name='휴업 외')\n","\n","    # 스타일 설정\n","    workbook = writer.book\n","    thin_border = Border(left=Side(style='thin', color='D3D3D3'),\n","                         right=Side(style='thin', color='D3D3D3'),\n","                         top=Side(style='thin', color='D3D3D3'),\n","                         bottom=Side(style='thin', color='D3D3D3'))\n","    header_fill = PatternFill(start_color=\"000080\", end_color=\"000080\", fill_type=\"solid\")\n","    header_font = Font(color=\"FFFFFF\", bold=True)\n","\n","    def set_style(worksheet):\n","        for cell in worksheet[1]:\n","            cell.fill = header_fill\n","            cell.font = header_font\n","            cell.border = thin_border\n","            cell.alignment = Alignment(horizontal='center', vertical='center')\n","        for row in worksheet.iter_rows(min_row=2):\n","            for cell in row:\n","                cell.border = thin_border\n","                cell.alignment = Alignment(horizontal='center', vertical='center')\n","        for col in worksheet.columns:\n","            max_length = 0\n","            column = col[0].column_letter\n","            for cell in col:\n","                try:\n","                    if len(str(cell.value)) > max_length:\n","                        max_length = len(cell.value)\n","                    except Exception as e:\n","                    pass\n","                adjusted_width = (max_length + 2)\n","                worksheet.column_dimensions[column].width = adjusted_width\n","\n","    set_style(writer.sheets['전체'])\n","    set_style(writer.sheets['영업_정상'])\n","    set_style(writer.sheets['휴업 외'])\n","\n","print(f\"최종 엑셀 파일이 생성되었습니다: {final_output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"4kZQgrnCSNj7","executionInfo":{"status":"error","timestamp":1724670908359,"user_tz":-540,"elapsed":577,"user":{"displayName":"세은이보호자","userId":"03211434170377121056"}},"outputId":"48cffb86-3e5f-459b-a232-7b167f4b988a"},"execution_count":8,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-8-de52f6373a8b>, line 444)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-de52f6373a8b>\"\u001b[0;36m, line \u001b[0;32m444\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"uB5LfjprSNm5","executionInfo":{"status":"error","timestamp":1724709712732,"user_tz":-540,"elapsed":6,"user":{"displayName":"세은이보호자","userId":"03211434170377121056"}},"outputId":"3dd90240-a263-45f0-d295-46c6e0a08926"},"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-1-80a034dc7b68>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-80a034dc7b68>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    File \"<ipython-input-8-de52f6373a8b>\", line 444\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import glob\n","import zipfile\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from openpyxl import Workbook\n","from openpyxl.utils.dataframe import dataframe_to_rows\n","from openpyxl.styles import Border, Side, Alignment, PatternFill, Font\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","from difflib import SequenceMatcher\n","from datetime import datetime\n","\n","# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 한글 폰트 설치 및 설정\n","!apt-get install -y fonts-nanum\n","plt.rcParams['font.family'] = 'NanumGothic'\n","\n","# 압축 파일 경로 및 압축 해제 경로 설정\n","zip_file_path = '/content/drive/My Drive/회사업무/영업기회0801-23/LOCALDATA_NOWMON_CSV-3.zip'  # 실제 파일 경로로 변경\n","extract_folder = '/content/extracted_data'\n","\n","# 폴더가 없으면 생성\n","os.makedirs(extract_folder, exist_ok=True)\n","\n","# 압축 해제\n","try:\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_folder)\n","    print(\"Files extracted successfully.\")  # 압축 해제 확인 메시지 추가\n","except FileNotFoundError:\n","    print(f\"Error: Specified zip file '{zip_file_path}' not found. Please check the path.\")\n","    exit(1)\n","except Exception as e:\n","    print(f\"Error extracting files: {e}\")  # 다른 잠재적 오류 포착\n","    exit(1)\n","\n","# 압축 해제된 폴더에서 모든 CSV 파일 목록 가져오기\n","all_files = glob.glob(os.path.join(extract_folder, \"**/*.csv\"), recursive=True)\n","\n","print(\"Found CSV files:\", all_files)  # 찾은 CSV 파일 목록 출력\n","\n","if len(all_files) == 0:\n","    print(\"Warning: No CSV files found in the specified directory. Proceeding with an empty DataFrame.\")\n","    dfs = []  # 빈 리스트로 초기화\n","else:\n","   if len(all_files) == 0:\n","    print(\"Warning: No CSV files found in the specified directory. Proceeding with an empty DataFrame.\")\n","    dfs = []  # 빈 리스트로 초기화\n","else:\n","    # 각 파일을 읽어서 하나의 DataFrame으로 병합\n","    dfs = []\n","    for file in all_files:\n","        try:\n","            df = pd.read_csv(file, encoding='cp949', on_bad_lines='skip', dtype=str, low_memory=False)\n","            # 주소라는 키워드를 포함한 열 확인\n","            address_columns = [col for col in df.columns if '주소' in col]\n","            if not address_columns:\n","                print(f\"No address column found in file: {file}\")\n","                continue\n","            # '서울', '경기', '강원'이 포함된 행 필터링\n","            df_filtered = df[df[address_columns[0]].str.contains('서울|경기|강원', na=False)]\n","            # Check if df_filtered is empty before appending\n","            if not df_filtered.empty:\n","                dfs.append(df_filtered)\n","                print(f\"Successfully read and filtered file: {file}\")\n","            else:\n","                print(f\"No matching rows found in file: {file}\")\n","        except Exception as e:\n","            print(f\"Error reading file {file}: {e}\")\n","\n","if len(dfs) == 0:\n","    concatenated_df = pd.DataFrame()  # 이전 단계에서 파일이 없을 경우 빈 DataFrame 생성\n","else:\n","    concatenated_df = pd.concat(dfs, ignore_index=True)\n","    # 중복된 행 제거: 사업장명, 소재지전체주소, 영업상태명이 동일한 경우 하나만 남기고 제거\n","    concatenated_df.drop_duplicates(subset=['사업장명', '소재지전체주소', '영업상태명'], inplace=True)\n","\n","    # '인허가일자' 기준으로 내림차순 정렬\n","    if '인허가일자' in concatenated_df.columns:\n","        concatenated_df['인허가일자'] = pd.to_datetime(concatenated_df['인허가일자'], format='%Y%m%d', errors='coerce')\n","        concatenated_df.sort_values(by='인허가일자', ascending=False, inplace=True)\n","\n","# 필요한 열만 선택하여 필터링\n","selected_columns = ['소재지전체주소', '도로명전체주소', '도로명우편번호', '사업장명', '개방서비스명', '인허가일자', '인허가취소', '영업상태명', '폐업일자',\n","                    '휴업시작일', '휴업종료일', '재개업일자', '소재지전화', '최종수정시점', '업태구분명', '좌표정보(X)', '좌표정보(Y)', '총면적', '소재지면적']\n","\n","# 존재하는 열만 선택\n","existing_columns = [col for col in selected_columns if col in concatenated_df.columns]\n","filtered_df = concatenated_df[existing_columns]\n","\n","# CSV 파일로 저장\n","output_dir = '/content/drive/My Drive/회사업무/영업기회0801-23'\n","os.makedirs(output_dir, exist_ok=True)\n","output_csv_path = os.path.join(output_dir, '0801-23일_병합(서울,경기,강원).csv')\n","filtered_df.to_csv(output_csv_path, index=False, encoding='cp949')\n","\n","# 엑셀 파일 경로 설정\n","file1_path = os.path.join('/content/drive/My Drive/회사업무/행안부자료/0801', '1.영업구역별_주소현행화0725.xlsx')\n","file2_path = output_csv_path  # 이전 단계에서 생성한 파일 사용\n","\n","# 파일 경로 확인\n","if not os.path.exists(file1_path):\n","    raise FileNotFoundError(f\"{file1_path} 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n","if not os.path.exists(file2_path):\n","    raise FileNotFoundError(f\"{file2_path} 파일이 존재하지 않습니다. 경로를 확인하세요.\")\n","\n","# 엑셀 파일 읽기\n","df1 = pd.read_excel(file1_path)\n","\n","# Check if df2 can be read and print its shape\n","try:\n","    df2 = pd.read_csv(file2_path, encoding='cp949')\n","    print(\"Shape of df2:\", df2.shape)  # Print the shape of df2 to see if it's empty\n","    # If df2 is empty, raise an error to handle it explicitly\n","    if df2.empty:\n","        raise pd.errors.EmptyDataError(\"The CSV file is empty.\")\n","except pd.errors.EmptyDataError:\n","    print(\"Error: The CSV file at\", file2_path, \"is empty or has no columns.\")\n","    # Handle the empty file, e.g., create an empty DataFrame\n","    df2 = pd.DataFrame()  # Create an empty DataFrame if the file is empty\n","except Exception as e:\n","    print(\"Error reading file\", file2_path, \":\", e)\n","\n","\n","\n","# 주소 정규화 함수\n","def normalize_address(address):\n","    if pd.isna(address):\n","        return None\n","    address = address.strip()\n","    address = address.replace('강원특별자치도', '강원도')\n","    address = address.replace('서울특별시', '서울시')\n","    address = address.replace(' ', '')\n","    address = address.replace('-', '')\n","    if '*' in address or len(address) < 10:  # 길이가 너무 짧은 경우는 None으로 처리\n","        return None\n","    return address\n","\n","# 유사도 비교를 위한 다양한 방식 추가\n","def get_best_match(address, df_choices, threshold=0.7):\n","    if pd.isna(address):\n","        return None\n","\n","    # 유사도 측정을 위한 다양한 방법 사용\n","    best_score = 0\n","    best_match = None\n","\n","    for choice in df_choices:\n","        # TF-IDF 및 코사인 유사도\n","        tfidf_vec = vectorizer.transform([choice])\n","        cosine_sim = cosine_similarity(vectorizer.transform([address]), tfidf_vec).flatten()[0]\n","\n","        # 레벤슈타인 거리 기반 유사도 (텍스트 유사도)\n","        seq_match = SequenceMatcher(None, address, choice)\n","        seq_similarity = seq_match.ratio()\n","\n","        # 최고 유사도 채택\n","        score = max(cosine_sim, seq_similarity)\n","        if score > best_score:\n","            best_score = score\n","            best_match = choice\n","\n","    if best_score >= threshold:\n","        return best_match\n","    return None\n","\n","# df1의 주소 정규화\n","df1['full_address'] = df1[['주소시', '주소군구', '주소동']].astype(str).agg(' '.join, axis=1).apply(normalize_address)\n","df1 = df1.dropna(subset=['full_address'])\n","\n","# df2의 주소 정규화\n","df2['소재지전체주소'] = df2['소재지전체주소'].astype(str).apply(normalize_address)\n","df2['도로명전체주소'] = df2['도로명전체주소'].astype(str).apply(normalize_address)\n","df2 = df2.dropna(subset=['소재지전체주소', '도로명전체주소'])\n","\n","# TF-IDF 벡터화\n","vectorizer = TfidfVectorizer().fit(df1['full_address'])\n","tfidf_matrix = vectorizer.transform(df1['full_address'])\n","\n","# 유사한 주소 매핑\n","choices = df1['full_address'].tolist()\n","df2['matched_address_소재지'] = df2['소재지전체주소'].apply(lambda x: get_best_match(x, choices))\n","df2['matched_address_도로명'] = df2['도로명전체주소'].apply(lambda x: get_best_match(x, choices))\n","\n","df2['matched_address'] = df2.apply(lambda x: x['matched_address_소재지'] if pd.notna(x['matched_address_소재지']) else x['matched_address_도로명'], axis=1)\n","\n","# 매핑되지 않은 항목 확인\n","unmatched = df2[df2['matched_address'].isna()]\n","print(\"매핑되지 않은 항목 수:\", len(unmatched))\n","\n","# 평수 계산을 위한 열 존재 확인 및 병합\n","merge_columns = ['full_address', '관리지사', 'SP담당']\n","if '총면적' in df1.columns:\n","    merge_columns.append('총면적')\n","if '소재지면적' in df1.columns:\n","    merge_columns.append('소재지면적')\n","\n","df_merged = df2.merge(df1[merge_columns], left_on='matched_address', right_on='full_address', how='left', suffixes=('', '_df1'))\n","\n","# 매핑 결과 확인\n","print(\"매핑 후 관리지사 및 SP담당이 비어있는 행 수:\", df_merged[['관리지사', 'SP담당']].isna().sum())\n","\n","# 평수 계산 (1평 = 3.305785 m^2)\n","def calculate_area(row):\n","    if '소재지면적' in row and pd.notna(row['소재지면적']):\n","        return round(float(row['소재지면적']) / 3.305785, 2)\n","    elif '총면적' in row and pd.notna(row['총면적']):\n","        return round(float(row['총면적']) / 3.305785, 2)\n","    else:\n","        return None\n","\n","df_merged['평수'] = df_merged.apply(calculate_area, axis=1)\n","\n","# 불필요한 열 제외하고 필요한 열만 선택\n","columns_to_keep = ['관리지사', 'SP담당', '사업장명', '개방서비스명', '업태구분명', '평수', '소재지전체주소', '도로명전체주소', '소재지전화', '폐업일자', '재개업일자', '영업상태명']\n","df_filtered = df_merged[columns_to_keep]\n","\n","# 중복된 항목 제거\n","df_filtered.drop_duplicates(inplace=True)\n","\n","# 평수 내림차순 정렬\n","df_filtered_sorted = df_filtered.sort_values(by='평수', ascending=False)\n","\n","# NaN 값 처리\n","df_filtered_sorted['관리지사'] = df_filtered_sorted['관리지사'].fillna('Unknown')\n","df_filtered_sorted['SP담당'] = df_filtered_sorted['SP담당'].fillna('Unknown')\n","\n","# 네이버 지도 하이퍼링크 생성 함수\n","def create_naver_map_link(address):\n","    return f\"https://map.naver.com/v5/search/{address}\"\n","\n","# 엑셀 파일에 네이버 지도 링크 추가하는 함수\n","def add_naver_map_links(ws, address_col_idx):\n","    ws.insert_cols(1)  # 첫 번째 열에 열 추가\n","    ws.cell(row=1, column=1, value=\"네이버 지도 링크\")  # 새 열에 헤더 추가\n","\n","    for row in range(2, ws.max_row + 1):\n","        address = ws.cell(row=row, column=address_col_idx + 1).value\n","        if address:\n","            link = create_naver_map_link(address)\n","            ws.cell(row=row, column=1).hyperlink = link\n","            ws.cell(row=row, column=1).value = \"네이버 지도 보기\"\n","            ws.cell(row=row, column=1).style = \"Hyperlink\"\n","\n","# 엑셀 파일에 데이터를 저장하고 스타일을 설정하는 함수\n","def save_to_excel(df, file_path):\n","    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n","        # 전체 시트 저장\n","        df.to_excel(writer, index=False, sheet_name='전체')\n","\n","        # 영업/정상 시트 저장\n","        df_active = df[df['영업상태명'].isin(['영업/정상'])]\n","\n","        # 필터링된 데이터 개수 확인\n","        print(f\"전체 시트에서 영업/정상 데이터 수: {len(df_active)}\")\n","\n","        df_active.to_excel(writer, index=False, sheet_name='영업_정상')\n","\n","        # 휴업 외 시트 저장 (영업/정상이 아닌 경우)\n","        df_non_active = df[~df['영업상태명'].isin(['영업/정상'])]\n","        df_non_active.to_excel(writer, index=False, sheet_name='휴업 외')\n","\n","        workbook = writer.book\n","        thin_border = Border(left=Side(style='thin', color='D3D3D3'),\n","                             right=Side(style='thin', color='D3D3D3'),\n","                             top=Side(style='thin', color='D3D3D3'),\n","                             bottom=Side(style='thin', color='D3D3D3'))\n","        header_fill = PatternFill(start_color=\"000080\", end_color=\"000080\", fill_type=\"solid\")\n","        header_font = Font(color=\"FFFFFF\", bold=True)\n","\n","        # 스타일 설정 함수\n","        def set_style(worksheet):\n","            for cell in worksheet[1]:\n","                cell.fill = header_fill\n","                cell.font = header_font\n","                cell.border = thin_border\n","                cell.alignment = Alignment(horizontal='center', vertical='center')\n","            for row in worksheet.iter_rows(min_row=2):\n","                for cell in row:\n","                    cell.border = thin_border\n","                    cell.alignment = Alignment(horizontal='center', vertical='center')\n","            for col in worksheet.columns:\n","                max_length = 0\n","                column = col[0].column_letter\n","                for cell in col:\n","                    try:\n","                        if len(str(cell.value)) > max_length:\n","                            max_length = len(cell.value)\n","                    except Exception as e:\n","                        pass\n","                adjusted_width = (max_length + 2)\n","                worksheet.column_dimensions[column].width = adjusted_width\n","\n","        set_style(writer.sheets['전체'])\n","        set_style(writer.sheets['영업_정상'])\n","        set_style(writer.sheets['휴업 외'])\n","\n","        # 네이버 지도 링크 추가\n","        # '소재지전체주소'는 G열이므로 컬럼 인덱스는 7-1=6\n","        add_naver_map_links(writer.sheets['전체'], 6)\n","        add_naver_map_links(writer.sheets['영업_정상'], 6)\n","        add_naver_map_links(writer.sheets['휴업 외'], 6)\n","\n","# 전체 데이터를 바탕으로 시각화 및 파일 저장\n","output_dir = '/content/drive/My Drive/회사업무/영업기회0801-23'\n","for manager in df_filtered_sorted['관리지사'].unique():\n","    manager_dir = os.path.join(output_dir, manager)\n","    os.makedirs(manager_dir, exist_ok=True)\n","    df_manager = df_filtered_sorted[df_filtered_sorted['관리지사'] == manager]\n","\n","    for sp in df_manager['SP담당'].unique():\n","        df_sp = df_manager[df_manager['SP담당'] == sp]\n","        sp_file_path = os.path.join(manager_dir, f'{manager}_{sp}_0801-23.xlsx')\n","        save_to_excel(df_sp, sp_file_path)\n","\n","# 전체 데이터를 저장\n","total_file_path = os.path.join(output_dir, '0801-23_전체_최종결과물.xlsx')\n","save_to_excel(df_filtered_sorted, total_file_path)\n","\n","# 전체 데이터를 바탕으로 시각화\n","status_counts = df_filtered_sorted.groupby(['관리지사', '영업상태명']).size().unstack(fill_value=0)\n","status_counts = status_counts.loc[status_counts.sum(axis=1).sort_values(ascending=False).index]\n","\n","# 시각화 및 PDF 저장\n","pdf_path = os.path.join(output_dir, '전체_영업상태명_집계현황.pdf')\n","with PdfPages(pdf_path) as pdf:\n","    # 시각화 1: 관리지사별 영업상태명 집계현황\n","    fig1, ax1 = plt.subplots(figsize=(14, 10))\n","    status_counts.plot(kind='bar', stacked=True, ax=ax1, color=['skyblue', 'salmon'])\n","    ax1.set_title('관리지사별 영업상태명 집계현황', fontsize=16)\n","    ax1.set_xlabel('관리지사', fontsize=12)\n","    ax1.set_ylabel('건수', fontsize=12)\n","    ax1.legend(title='영업상태명', fontsize=10, title_fontsize='13')\n","    plt.xticks(rotation=90)\n","    plt.tight_layout()\n","    pdf.savefig(fig1)\n","    plt.close(fig1)\n","\n","    # 시각화 2: SP담당자별 영업상태명 집계현황\n","    df_filtered_sorted['SP담당자'] = df_filtered_sorted['관리지사'].str.replace('지사', '') + '-' + df_filtered_sorted['SP담당']\n","    status_counts_sp = df_filtered_sorted.groupby(['SP담당자', '영업상태명']).size().unstack(fill_value=0)\n","    status_counts_sp = status_counts_sp.loc[status_counts_sp.sum(axis=1).sort_values(ascending=True).index]\n","\n","    fig2, ax2 = plt.subplots(figsize=(16, 12))\n","    status_counts_sp.plot(kind='barh', stacked=True, ax=ax2, color=['#4caf50', '#f44336'])\n","    ax2.set_title('SP담당자별 영업상태명 집계현황', fontsize=18)\n","    ax2.set_xlabel('건수', fontsize=14)\n","    ax2.set_ylabel('SP담당자', fontsize=14)\n","    plt.tight_layout()\n","    pdf.savefig(fig2)\n","    plt.close(fig2)\n","\n","print(f\"전체 영업상태명 집계현황 PDF가 생성되었습니다: {pdf_path}\")\n","\n","# EDA를 위한 함수 정의\n","def eda_analysis(df, condition=None):\n","    if condition:\n","        df = df.query(condition)\n","\n","    # 관리지사별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['관리지사'].value_counts().plot(kind='bar', color='skyblue')\n","    plt.title('관리지사별 데이터 분포')\n","    plt.xlabel('관리지사')\n","    plt.ylabel('건수')\n","    plt.show()\n","\n","    # SP담당별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['SP담당'].value_counts().plot(kind='bar', color='salmon')\n","    plt.title('SP담당별 데이터 분포')\n","    plt.xlabel('SP담당')\n","    plt.ylabel('건수')\n","    plt.show()\n","\n","    # 영업상태명별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['영업상태명'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=['#4caf50', '#f44336'])\n","    plt.title('영업상태명별 데이터 비율')\n","    plt.ylabel('')\n","    plt.show()\n","\n","    # 개방서비스명별 데이터 분포 시각화\n","    plt.figure(figsize=(12, 8))\n","    df['개방서비스명'].value_counts().plot(kind='barh', color='lightgreen')\n","    plt.title('개방서비스명별 데이터 분포')\n","    plt.xlabel('건수')\n","    plt.ylabel('개방서비스명')\n","    plt.show()\n","\n","# EDA 함수 실행 예시\n","eda_analysis(df_filtered_sorted, condition=\"관리지사 == '서울지사' and 영업상태명 == '영업/정상'\")\n","\n","# 인허가일자 및 최종수정시점 기준으로 데이터 필터링 및 정리\n","\n","start_date = pd.to_datetime('2024-08-01')\n","end_date = pd.to_datetime('2024-08-23')\n","\n","df_filtered_sorted['인허가일자'] = pd.to_datetime(df_filtered_sorted['인허가일자'], errors='coerce')\n","df_filtered_sorted['최종수정시점'] = pd.to_datetime(df_filtered_sorted['최종수정시점'], errors='coerce')\n","\n","# 중복된 항목 중 최신 데이터를 유지\n","df_filtered_sorted.sort_values(by='최종수정시점', ascending=False, inplace=True)\n","df_filtered_sorted.drop_duplicates(subset=['소재지전체주소', '사업장명', '소재지전화'], keep='first', inplace=True)\n","\n","# 인허가일자 범위 필터링\n","df_filtered_sorted = df_filtered_sorted[\n","    (df_filtered_sorted['인허가일자'] >= start_date) &\n","    (df_filtered_sorted['인허가일자'] <= end_date)\n","]\n","\n","# 영업상태명이 \"영업/정상\"인 데이터 필터링\n","df_active = df_filtered_sorted[df_filtered_sorted['영업상태명'] == '영업/정상']\n","\n","# 폐업일자, 휴업시작일 필터링 (2024-08-01 ~ 2024-08-16)\n","df_closed_or_suspended = df_filtered_sorted[\n","    (df_filtered_sorted['폐업일자'].between(start_date, end_date)) |\n","    (df_filtered_sorted['휴업시작일'].between(start_date, end_date))\n","]\n","\n","# 결과를 엑셀 파일에 저장 (전체, 영업/정상, 휴업 외 시트)\n","final_output_path = os.path.join(output_dir, '최종결과물_2024-0823.xlsx')\n","with pd.ExcelWriter(final_output_path, engine='openpyxl') as writer:\n","    df_filtered_sorted.to_excel(writer, index=False, sheet_name='전체')\n","    df_active.to_excel(writer, index=False, sheet_name='영업_정상')\n","    df_closed_or_suspended.to_excel(writer, index=False, sheet_name='휴업 외')\n","\n","    # 스타일 설정\n","    workbook = writer.book\n","    thin_border = Border(left=Side(style='thin', color='D3D3D3'),\n","                         right=Side(style='thin', color='D3D3D3'),\n","                         top=Side(style='thin', color='D3D3D3'),\n","                         bottom=Side(style='thin', color='D3D3D3'))\n","    header_fill = PatternFill(start_color=\"000080\", end_color=\"000080\", fill_type=\"solid\")\n","    header_font = Font(color=\"FFFFFF\", bold=True)\n","\n","    def set_style(worksheet):\n","        for cell in worksheet[1]:\n","            cell.fill = header_fill\n","            cell.font = header_font\n","            cell.border = thin_border\n","            cell.alignment = Alignment(horizontal='center', vertical='center')\n","        for row in worksheet.iter_rows(min_row=2):\n","            for cell in row:\n","                cell.border = thin_border\n","                cell.alignment = Alignment(horizontal='center', vertical='center')\n","        for col in worksheet.columns:\n","            max_length = 0\n","            column = col[0].column_letter\n","            for cell in col:\n","                try:\n","                    if len(str(cell.value)) > max_length:\n","                        max_length = len(cell.value)\n","                except:\n","                    pass\n","                adjusted_width = (max_length + 2)\n","                worksheet.column_dimensions[column].width = adjusted_width\n","\n","    set_style(writer.sheets['전체'])\n","    set_style(writer.sheets['영업_정상'])\n","    set_style(writer.sheets['휴업 외'])\n","\n","print(f\"최종 엑셀 파일이 생성되었습니다: {final_output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"eerdc7ONSNpU","executionInfo":{"status":"error","timestamp":1724710743178,"user_tz":-540,"elapsed":934,"user":{"displayName":"세은이보호자","userId":"03211434170377121056"}},"outputId":"7629a31a-f082-4328-ff02-c60218c4dad6"},"execution_count":10,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-10-76d9951b3851>, line 54)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-76d9951b3851>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lcPyyO_6SNsA"},"execution_count":null,"outputs":[]}]}