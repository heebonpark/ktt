{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d7a10a-10dd-4b25-8270-f45e7b9f90a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 라이브러리등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590ddd77-39bd-4bff-a3b6-6be889f7bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gspread\n",
      "  Downloading gspread-6.1.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (5.22.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (8.1.5)\n",
      "Collecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting google-auth>=1.12.0 (from gspread)\n",
      "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-oauthlib>=0.4.1 (from gspread)\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (3.0.13)\n",
      "Collecting httplib2>=0.9.1 (from oauth2client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client) (0.2.8)\n",
      "Collecting rsa>=3.1.4 (from oauth2client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=1.12.0->gspread) (5.3.3)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib>=0.4.1->gspread)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.2)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.8.30)\n",
      "Downloading gspread-6.1.4-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 98.2/98.2 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.8 kB ? eta -:--:--\n",
      "   ---------------------------------------  204.8/209.8 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 209.8/209.8 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB ? eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: rsa, oauthlib, httplib2, requests-oauthlib, oauth2client, google-auth, google-auth-oauthlib, gspread\n",
      "Successfully installed google-auth-2.37.0 google-auth-oauthlib-1.2.1 gspread-6.1.4 httplib2-0.22.0 oauth2client-4.1.3 oauthlib-3.2.2 requests-oauthlib-2.0.0 rsa-4.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install gspread pandas matplotlib plotly ipywidgets oauth2client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9f1bd-8e40-4ea6-9dac-13802cb9861c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac89d24-6ca0-4283-b91e-c2e479d4ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.156.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth-httplib2\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: google-auth-oauthlib in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (1.2.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.37.0)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
      "Downloading google_api_python_client-2.156.0-py2.py3-none-any.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.7 MB 3.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.6/12.7 MB 9.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/12.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/12.7 MB 13.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.5/12.7 MB 14.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.9/12.7 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.7/12.7 MB 14.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.1/12.7 MB 13.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.9/12.7 MB 14.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.6/12.7 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.2/12.7 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.9/12.7 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.7 MB 14.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.7 MB 14.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.6/12.7 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 14.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.8/12.7 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.7 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.7 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.7 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.6/158.6 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 221.7/221.7 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, proto-plus, googleapis-common-protos, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed google-api-core-2.24.0 google-api-python-client-2.156.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.66.0 proto-plus-1.25.0 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc89c00-c1d1-40e1-91b1-dc1581b1338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google-api-python-client\n",
      "Version: 2.156.0\n",
      "Summary: Google API Client Library for Python\n",
      "Home-page: https://github.com/googleapis/google-api-python-client/\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "Requires: google-api-core, google-auth, google-auth-httplib2, httplib2, uritemplate\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b17f547f-6c3e-4a8c-a010-adbd76f66921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.156.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (1.2.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.37.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (2.24.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!python -m venv myenv\n",
    "!myenv\\Scripts\\activate      # Windows\n",
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "062c1908-8759-49f0-a190-75f81ac58460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyDrive2\n",
      "  Downloading PyDrive2-1.21.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-api-python-client>=1.12.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from PyDrive2) (2.156.0)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from PyDrive2) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDrive2) (6.0.1)\n",
      "Requirement already satisfied: cryptography<44 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDrive2) (42.0.5)\n",
      "Requirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDrive2) (24.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography<44->PyDrive2) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.37.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.24.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client>=1.12.5->PyDrive2) (4.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client>=4.0.0->PyDrive2) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client>=4.0.0->PyDrive2) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from oauth2client>=4.0.0->PyDrive2) (4.9)\n",
      "Requirement already satisfied: six>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client>=4.0.0->PyDrive2) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography<44->PyDrive2) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.12.5->PyDrive2) (5.3.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.12.5->PyDrive2) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2024.8.30)\n",
      "Downloading PyDrive2-1.21.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/48.0 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/48.0 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 41.0/48.0 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 48.0/48.0 kB 598.9 kB/s eta 0:00:00\n",
      "Installing collected packages: PyDrive2\n",
      "Successfully installed PyDrive2-1.21.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyDrive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963ee19-6199-46f2-8984-c5b0510b9bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b823cda-a41f-460f-b29f-8d4ba486c753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601c627-28d7-40b3-b5c6-282e6ca1de09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ecb172-2e30-49c5-8f9c-039940f2440d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38783117-8b7c-48d7-893e-ea4d2486ac25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13a6fc-0a45-4d4e-af35-028f08779af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "903825b6-39b8-4460-aaf8-5ac4f88a877f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'credentials.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m credentials_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredentials.json\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# credentials.json 파일 경로\u001b[39;00m\n\u001b[0;32m     10\u001b[0m SCOPES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.googleapis.com/auth/drive/Key/\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m creds \u001b[38;5;241m=\u001b[39m Credentials\u001b[38;5;241m.\u001b[39mfrom_service_account_file(credentials_file, scopes\u001b[38;5;241m=\u001b[39mSCOPES)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Google Drive API 클라이언트 생성\u001b[39;00m\n\u001b[0;32m     14\u001b[0m drive_service \u001b[38;5;241m=\u001b[39m build(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv3\u001b[39m\u001b[38;5;124m'\u001b[39m, credentials\u001b[38;5;241m=\u001b[39mcreds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\oauth2\\service_account.py:260\u001b[0m, in \u001b[0;36mCredentials.from_service_account_file\u001b[1;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_service_account_file\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a Credentials instance from a service account json file.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m            credentials.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m     info, signer \u001b[38;5;241m=\u001b[39m _service_account_info\u001b[38;5;241m.\u001b[39mfrom_filename(\n\u001b[0;32m    261\u001b[0m         filename, require\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_email\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_signer_and_info(signer, info, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\auth\\_service_account_info.py:78\u001b[0m, in \u001b[0;36mfrom_filename\u001b[1;34m(filename, require, use_rsa_signer)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_filename\u001b[39m(filename, require\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_rsa_signer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reads a Google service account JSON file and returns its parsed info.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m            info and a signer instance.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m     79\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data, from_dict(data, require\u001b[38;5;241m=\u001b[39mrequire, use_rsa_signer\u001b[38;5;241m=\u001b[39muse_rsa_signer)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credentials.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# 1. Google Drive 인증 설정\n",
    "credentials_file = \"credentials.json\"  # credentials.json 파일 경로\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive/Key/']\n",
    "creds = Credentials.from_service_account_file(credentials_file, scopes=SCOPES)\n",
    "\n",
    "# Google Drive API 클라이언트 생성\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# 2. Google Drive 파일 목록 가져오기\n",
    "def list_drive_files():\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=100, fields=\"nextPageToken, files(id, name)\"\n",
    "    ).execute()\n",
    "    items = results.get('files', [])\n",
    "   \n",
    "    if not items:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "        return []\n",
    "   \n",
    "    print(\"Google Drive 파일 목록:\")\n",
    "    for item in items:\n",
    "        print(f\"{item['name']} (ID: {item['id']})\")\n",
    "    return items\n",
    "\n",
    "# 3. Google Drive 파일 다운로드\n",
    "def download_file(file_id, save_path):\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    with io.FileIO(save_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {save_path}\")\n",
    "\n",
    "# 4. 데이터 분석 (Pandas)\n",
    "def analyze_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='cp949')  # 파일 인코딩에 따라 cp949 또는 utf-8 사용\n",
    "        print(f\"CSV 파일 로드 완료: {file_path}\")\n",
    "        print(\"데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "       \n",
    "        # 분석 예시: 열 이름, 데이터 통계\n",
    "        print(\"\\n열 이름:\", df.columns.tolist())\n",
    "        print(\"\\n데이터 통계:\")\n",
    "        print(df.describe())\n",
    "       \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# 5. 전체 프로세스 실행\n",
    "def main():\n",
    "    # Step 1: Google Drive에서 파일 목록 가져오기\n",
    "    drive_files = list_drive_files()\n",
    "   \n",
    "    # Step 2: 특정 파일 선택 (여기서는 첫 번째 파일을 선택)\n",
    "    if drive_files:\n",
    "        target_file = drive_files[0]  # 첫 번째 파일 선택\n",
    "        file_id = target_file['id']\n",
    "        file_name = target_file['name']\n",
    "       \n",
    "        # Step 3: 파일 다운로드\n",
    "        download_path = os.path.join(os.getcwd(), file_name)  # 현재 디렉토리에 저장\n",
    "        download_file(file_id, download_path)\n",
    "       \n",
    "        # Step 4: 다운로드한 파일 분석\n",
    "        if file_name.endswith('.csv'):\n",
    "            analyze_csv(download_path)\n",
    "        else:\n",
    "            print(f\"다운로드한 파일은 CSV 형식이 아닙니다: {file_name}\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b44e1d15-e4de-49d8-9675-62a491bff617",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 94\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[29], line 69\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Step 1: 인증 파일 업로드\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     upload_credentials()\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Step 2: Google Drive 인증\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     drive_service \u001b[38;5;241m=\u001b[39m authenticate_google_drive()\n",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m, in \u001b[0;36mupload_credentials\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_credentials\u001b[39m():\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m     11\u001b[0m     uploaded \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()  \u001b[38;5;66;03m# 인증 파일 업로드\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredentials.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m uploaded:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "\n",
    "# 1. 인증 파일 업로드 받기\n",
    "def upload_credentials():\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()  # 인증 파일 업로드\n",
    "    if 'credentials.json' not in uploaded:\n",
    "        raise FileNotFoundError(\"업로드된 파일에 'credentials.json'이 없습니다.\")\n",
    "    print(\"인증 파일 업로드 완료: credentials.json\")\n",
    "\n",
    "# 2. Google Drive 인증\n",
    "def authenticate_google_drive():\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    creds = Credentials.from_service_account_file(\"credentials.json\", scopes=SCOPES)\n",
    "    drive_service = build('drive', 'v3', credentials=creds)\n",
    "    return drive_service\n",
    "\n",
    "# 3. Google Drive 파일 목록 가져오기\n",
    "def list_drive_files(drive_service):\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=10, fields=\"nextPageToken, files(id, name)\"\n",
    "    ).execute()\n",
    "    items = results.get('files', [])\n",
    "    if not items:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "    else:\n",
    "        print(\"Google Drive 파일 목록:\")\n",
    "        for item in items:\n",
    "            print(f\"{item['name']} (ID: {item['id']})\")\n",
    "    return items\n",
    "\n",
    "# 4. Google Drive 파일 다운로드\n",
    "def download_file(drive_service, file_id, file_name):\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    with io.FileIO(file_name, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_name}\")\n",
    "\n",
    "# 5. 데이터 분석 (Pandas)\n",
    "def analyze_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')  # 필요한 경우 'cp949'로 변경\n",
    "        print(f\"CSV 파일 로드 완료: {file_path}\")\n",
    "        print(\"데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # 간단한 분석: 열 이름과 데이터 통계\n",
    "        print(\"\\n열 이름:\", df.columns.tolist())\n",
    "        print(\"\\n데이터 통계:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# 6. 전체 실행\n",
    "def main():\n",
    "    # Step 1: 인증 파일 업로드\n",
    "    upload_credentials()\n",
    "\n",
    "    # Step 2: Google Drive 인증\n",
    "    drive_service = authenticate_google_drive()\n",
    "\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    drive_files = list_drive_files(drive_service)\n",
    "\n",
    "    # Step 4: 특정 파일 다운로드 및 분석 (첫 번째 파일 예시)\n",
    "    if drive_files:\n",
    "        target_file = drive_files[0]  # 첫 번째 파일 선택\n",
    "        file_id = target_file['id']\n",
    "        file_name = target_file['name']\n",
    "\n",
    "        # 파일 다운로드\n",
    "        download_file(drive_service, file_id, file_name)\n",
    "\n",
    "        # 다운로드한 파일 분석\n",
    "        if file_name.endswith('.csv'):\n",
    "            analyze_csv(file_name)\n",
    "        else:\n",
    "            print(f\"다운로드한 파일은 CSV 형식이 아닙니다: {file_name}\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34a9dd2-a44d-43a7-b83d-07476d27ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인증 파일 경로 확인 완료: credentials.json\n",
      "Google Drive 파일 목록:\n",
      "코인정보 (ID: 1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI)\n",
      "유통망정산 (ID: 1gZ468AqM4wApPDMD5LZnA3WZpi2q6zqP8M4ZU_xUWcY)\n"
     ]
    },
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://www.googleapis.com/drive/v3/files/1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI?alt=media returned \"Only files with binary content can be downloaded. Use Export with Docs Editors files.\". Details: \"[{'message': 'Only files with binary content can be downloaded. Use Export with Docs Editors files.', 'domain': 'global', 'reason': 'fileNotDownloadable', 'location': 'alt', 'locationType': 'parameter'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 95\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[33], line 85\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m file_name \u001b[38;5;241m=\u001b[39m target_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# 파일 다운로드\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m download_file(drive_service, file_id, file_name)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# 다운로드한 파일 분석\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[33], line 45\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(drive_service, file_id, file_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 45\u001b[0m         status, done \u001b[38;5;241m=\u001b[39m downloader\u001b[38;5;241m.\u001b[39mnext_chunk()\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m다운로드 진행률: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(status\u001b[38;5;241m.\u001b[39mprogress()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파일 다운로드 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\googleapiclient\\http.py:780\u001b[0m, in \u001b[0;36mMediaIoBaseDownload.next_chunk\u001b[1;34m(self, num_retries)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    776\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    777\u001b[0m             MediaDownloadProgress(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_size),\n\u001b[0;32m    778\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done,\n\u001b[0;32m    779\u001b[0m         )\n\u001b[1;32m--> 780\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uri)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 403 when requesting https://www.googleapis.com/drive/v3/files/1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI?alt=media returned \"Only files with binary content can be downloaded. Use Export with Docs Editors files.\". Details: \"[{'message': 'Only files with binary content can be downloaded. Use Export with Docs Editors files.', 'domain': 'global', 'reason': 'fileNotDownloadable', 'location': 'alt', 'locationType': 'parameter'}]\">"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "\n",
    "\n",
    "# 1. 인증 파일 경로 설정\n",
    "def set_credentials():\n",
    "    credentials_path = \"D:\\\\구글key\\\\credentials (1).json\"  # 실제 credentials.json 파일 경로 입력\n",
    "    if not os.path.exists(credentials_path):\n",
    "        raise FileNotFoundError(\"credentials.json 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "    print(\"인증 파일 경로 확인 완료: credentials.json\")\n",
    "    return credentials_path\n",
    "\n",
    "# 2. Google Drive 인증\n",
    "def authenticate_google_drive(credentials_path):\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)\n",
    "    drive_service = build('drive', 'v3', credentials=creds)\n",
    "    return drive_service\n",
    "\n",
    "# 3. Google Drive 파일 목록 가져오기\n",
    "def list_drive_files(drive_service):\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=10, fields=\"nextPageToken, files(id, name)\"\n",
    "    ).execute()\n",
    "    items = results.get('files', [])\n",
    "    if not items:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "    else:\n",
    "        print(\"Google Drive 파일 목록:\")\n",
    "        for item in items:\n",
    "            print(f\"{item['name']} (ID: {item['id']})\")\n",
    "    return items\n",
    "\n",
    "# 4. Google Drive 파일 다운로드\n",
    "def download_file(drive_service, file_id, file_name):\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "    with io.FileIO(file_name, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_name}\")\n",
    "\n",
    "# 5. 데이터 분석 (Pandas)\n",
    "def analyze_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')  # 필요한 경우 'cp949'로 변경\n",
    "        print(f\"CSV 파일 로드 완료: {file_path}\")\n",
    "        print(\"데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # 간단한 분석: 열 이름과 데이터 통계\n",
    "        print(\"\\n열 이름:\", df.columns.tolist())\n",
    "        print(\"\\n데이터 통계:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "# 6. 전체 실행\n",
    "def main():\n",
    "    # Step 1: 인증 파일 경로 설정\n",
    "    credentials_path = set_credentials()\n",
    "\n",
    "    # Step 2: Google Drive 인증\n",
    "    drive_service = authenticate_google_drive(credentials_path)\n",
    "\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    drive_files = list_drive_files(drive_service)\n",
    "\n",
    "    # Step 4: 특정 파일 다운로드 및 분석 (첫 번째 파일 예시)\n",
    "    if drive_files:\n",
    "        target_file = drive_files[0]  # 첫 번째 파일 선택\n",
    "        file_id = target_file['id']\n",
    "        file_name = target_file['name']\n",
    "\n",
    "        # 파일 다운로드\n",
    "        download_file(drive_service, file_id, file_name)\n",
    "\n",
    "        # 다운로드한 파일 분석\n",
    "        if file_name.endswith('.csv'):\n",
    "            analyze_csv(file_name)\n",
    "        else:\n",
    "            print(f\"다운로드한 파일은 CSV 형식이 아닙니다: {file_name}\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa46caa8-2044-435a-ae74-2fd3051a2ee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:27\u001b[1;36m\u001b[0m\n\u001b[1;33m    if not os.path.exists(credentials_path):\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Google Drive 파일 다운로드 (Export 방식)\n",
    "def download_google_sheets_as_csv(drive_service, file_id, file_name):\n",
    "    # CSV 형식으로 변환하여 다운로드\n",
    "    request = drive_service.files().export_media(fileId=file_id, mimeType='text/csv')\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "    with io.FileIO(file_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# 수정된 main 함수\n",
    "def main():\n",
    "  # 1. 인증 파일 경로 설정\n",
    "   def set_credentials():\n",
    "     credentials_path = \"D:\\\\구글key\\\\credentials (1).json\"  # 실제 credentials.json 파일 경로 입력\n",
    "    if not os.path.exists(credentials_path):\n",
    "        raise FileNotFoundError(\"credentials.json 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "    print(\"인증 파일 경로 확인 완료: credentials.json\")\n",
    "    return credentials_path\n",
    "\n",
    "  # 2. Google Drive 인증\n",
    "   def authenticate_google_drive(credentials_path):\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)\n",
    "    drive_service = build('drive', 'v3', credentials=creds)\n",
    "    return drive_service\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=10, fields=\"nextPageToken, files(id, name, mimeType)\"\n",
    "    ).execute()\n",
    "    files = results.get('files', [])\n",
    "   \n",
    "    if not files:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "        return\n",
    "   \n",
    "    print(\"Google Drive 파일 목록:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} (ID: {file['id']}, MIME Type: {file['mimeType']})\")\n",
    "   \n",
    "    # Step 4: 특정 파일 다운로드 및 변환\n",
    "    target_file = files[0]  # 첫 번째 파일 선택\n",
    "    file_id = target_file['id']\n",
    "    file_name = target_file['name']\n",
    "    mime_type = target_file['mimeType']\n",
    "   \n",
    "    if mime_type == 'application/vnd.google-apps.spreadsheet':  # Google Sheets 파일\n",
    "        print(f\"{file_name} 파일은 Google Sheets 형식입니다. CSV로 변환하여 다운로드합니다.\")\n",
    "        file_path = download_google_sheets_as_csv(drive_service, file_id, file_name + \".csv\")\n",
    "       \n",
    "        # 다운로드한 CSV 파일 분석\n",
    "        analyze_csv(file_path)\n",
    "    else:\n",
    "        print(f\"{file_name} 파일은 변환이 필요하지 않은 형식입니다. 직접 다운로드하세요.\")\n",
    "\n",
    "# 데이터 분석 함수\n",
    "def analyze_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"CSV 데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9c948-de8d-4da6-8490-18c3807de3eb",
   "metadata": {},
   "source": [
    "## 코인 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25c6efd2-bbe0-4840-8b6b-6e4d5d37ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인증 파일 경로 확인 완료: credentials.json\n",
      "Google Drive 파일 목록:\n",
      "코인정보 (ID: 1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "유통망정산 (ID: 1gZ468AqM4wApPDMD5LZnA3WZpi2q6zqP8M4ZU_xUWcY, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "코인정보 파일은 Google Sheets 형식입니다. CSV로 변환하여 다운로드합니다.\n",
      "다운로드 진행률: 100%\n",
      "파일 다운로드 완료: C:\\Users\\User\\Desktop\\jupytertest\\코인정보.csv\n",
      "CSV 데이터 미리보기:\n",
      "   2024-10-01 00:05:36       N/A  Unnamed: 2 Unnamed: 3\n",
      "0  2024-10-01 00:11:45       NaN         NaN        NaN\n",
      "1  2024-10-01 00:22:35   Bitcoin  $63,161.68        NaN\n",
      "2  2024-10-01 00:24:24   Bitcoin  $63,161.68        NaN\n",
      "3  2024-10-01 00:24:24  Ethereum   $2,599.15        NaN\n",
      "4  2024-10-01 00:24:24      Mina     $0.5561        NaN\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Google Drive 파일 다운로드 (Export 방식)\n",
    "def download_google_sheets_as_csv(drive_service, file_id, file_name):\n",
    "    # CSV 형식으로 변환하여 다운로드\n",
    "    request = drive_service.files().export_media(fileId=file_id, mimeType='text/csv')\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "    with io.FileIO(file_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# 데이터 분석 함수\n",
    "def analyze_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"CSV 데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    # 1. 인증 파일 경로 설정\n",
    "    def set_credentials():\n",
    "        credentials_path = \"D:\\\\구글key\\\\credentials (1).json\"  # 실제 credentials.json 파일 경로 입력\n",
    "        if not os.path.exists(credentials_path):\n",
    "            raise FileNotFoundError(\"credentials.json 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        print(\"인증 파일 경로 확인 완료: credentials.json\")\n",
    "        return credentials_path\n",
    "\n",
    "    # 2. Google Drive 인증\n",
    "    def authenticate_google_drive(credentials_path):\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "        creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)\n",
    "        drive_service = build('drive', 'v3', credentials=creds)\n",
    "        return drive_service\n",
    "\n",
    "    # Step 1: 인증 파일 경로 가져오기\n",
    "    credentials_path = set_credentials()\n",
    "\n",
    "    # Step 2: Google Drive 인증\n",
    "    drive_service = authenticate_google_drive(credentials_path)\n",
    "\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=10, fields=\"nextPageToken, files(id, name, mimeType)\"\n",
    "    ).execute()\n",
    "    files = results.get('files', [])\n",
    "   \n",
    "    if not files:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "        return\n",
    "   \n",
    "    print(\"Google Drive 파일 목록:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} (ID: {file['id']}, MIME Type: {file['mimeType']})\")\n",
    "   \n",
    "    # Step 4: 특정 파일 다운로드 및 변환\n",
    "    target_file = files[0]  # 첫 번째 파일 선택\n",
    "    file_id = target_file['id']\n",
    "    file_name = target_file['name']\n",
    "    mime_type = target_file['mimeType']\n",
    "   \n",
    "    if mime_type == 'application/vnd.google-apps.spreadsheet':  # Google Sheets 파일\n",
    "        print(f\"{file_name} 파일은 Google Sheets 형식입니다. CSV로 변환하여 다운로드합니다.\")\n",
    "        file_path = download_google_sheets_as_csv(drive_service, file_id, file_name + \".csv\")\n",
    "       \n",
    "        # 다운로드한 CSV 파일 분석\n",
    "        analyze_csv(file_path)\n",
    "    else:\n",
    "        print(f\"{file_name} 파일은 변환이 필요하지 않은 형식입니다. 직접 다운로드하세요.\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c243a30-7291-4b4e-8adc-28139ef353a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인증 파일 경로 확인 완료: credentials.json\n",
      "Google Drive 파일 목록:\n",
      "코인정보 (ID: 1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "유통망정산 (ID: 1gZ468AqM4wApPDMD5LZnA3WZpi2q6zqP8M4ZU_xUWcY, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "Google Drive에 '일시정지관리' 파일이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Google Drive 파일 다운로드 (Export 방식)\n",
    "def download_google_sheets_as_csv(drive_service, file_id, file_name):\n",
    "    # CSV 형식으로 변환하여 다운로드\n",
    "    request = drive_service.files().export_media(fileId=file_id, mimeType='text/csv')\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "    with io.FileIO(file_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# 데이터 분석 및 시각화 함수\n",
    "def analyze_and_visualize(file_path):\n",
    "    try:\n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"CSV 데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "       \n",
    "        # 데이터프레임 정보 확인\n",
    "        print(\"\\n데이터프레임 요약:\")\n",
    "        print(df.info())\n",
    "       \n",
    "        # 결측값 확인\n",
    "        print(\"\\n결측값 확인:\")\n",
    "        print(df.isnull().sum())\n",
    "       \n",
    "        # 데이터 요약 통계\n",
    "        print(\"\\n기초 통계:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        # 시각화 예제\n",
    "        # 1. 특정 열의 값 분포 확인 (예: '상태' 열)\n",
    "        if '상태' in df.columns:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            df['상태'].value_counts().plot(kind='bar', title='상태별 분포')\n",
    "            plt.xlabel('상태')\n",
    "            plt.ylabel('개수')\n",
    "            plt.show()\n",
    "       \n",
    "        # 2. 시간별 데이터 추세 (예: '시간' 열이 있을 경우)\n",
    "        if '시간' in df.columns:\n",
    "            df['시간'] = pd.to_datetime(df['시간'])  # 시간 열을 datetime 형식으로 변환\n",
    "            df.set_index('시간', inplace=True)\n",
    "            df.resample('D').size().plot(title='시간별 데이터 추세')\n",
    "            plt.xlabel('날짜')\n",
    "            plt.ylabel('건수')\n",
    "            plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    # 1. 인증 파일 경로 설정\n",
    "    def set_credentials():\n",
    "        credentials_path = \"D:\\\\구글key\\\\credentials (1).json\"  # 실제 credentials.json 파일 경로 입력\n",
    "        if not os.path.exists(credentials_path):\n",
    "            raise FileNotFoundError(\"credentials.json 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        print(\"인증 파일 경로 확인 완료: credentials.json\")\n",
    "        return credentials_path\n",
    "\n",
    "    # 2. Google Drive 인증\n",
    "    def authenticate_google_drive(credentials_path):\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "        creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)\n",
    "        drive_service = build('drive', 'v3', credentials=creds)\n",
    "        return drive_service\n",
    "\n",
    "    # Step 1: 인증 파일 경로 가져오기\n",
    "    credentials_path = set_credentials()\n",
    "\n",
    "    # Step 2: Google Drive 인증\n",
    "    drive_service = authenticate_google_drive(credentials_path)\n",
    "\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=10, fields=\"nextPageToken, files(id, name, mimeType)\"\n",
    "    ).execute()\n",
    "    files = results.get('files', [])\n",
    "   \n",
    "    if not files:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "        return\n",
    "   \n",
    "    print(\"Google Drive 파일 목록:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} (ID: {file['id']}, MIME Type: {file['mimeType']})\")\n",
    "   \n",
    "    # Step 4: '일시정지관리' 파일 다운로드 및 변환\n",
    "    target_file = next((f for f in files if f['name'] == '일시정지관리'), None)\n",
    "    if not target_file:\n",
    "        print(\"Google Drive에 '일시정지관리' 파일이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    file_id = target_file['id']\n",
    "    file_name = target_file['name']\n",
    "    file_path = download_google_sheets_as_csv(drive_service, file_id, file_name + \".csv\")\n",
    "\n",
    "    # Step 5: 다운로드한 CSV 파일 분석 및 시각화\n",
    "    analyze_and_visualize(file_path)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f386d480-4692-4f58-ae38-eed6e6e80c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인증 파일 경로 확인 완료: credentials.json\n",
      "Google Drive 파일 목록:\n",
      "코인정보 (ID: 1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "유통망정산 (ID: 1gZ468AqM4wApPDMD5LZnA3WZpi2q6zqP8M4ZU_xUWcY, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "Google Drive에 '일시정지관리' 파일이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Google Drive 파일 다운로드 (Export 방식)\n",
    "def download_google_sheets_as_csv(drive_service, file_id, file_name):\n",
    "    # CSV 형식으로 변환하여 다운로드\n",
    "    request = drive_service.files().export_media(fileId=file_id, mimeType='text/csv')\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "    with io.FileIO(file_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# 데이터 분석 및 시각화 함수\n",
    "def analyze_and_visualize(file_path):\n",
    "    try:\n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"CSV 데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "       \n",
    "        # 데이터프레임 정보 확인\n",
    "        print(\"\\n데이터프레임 요약:\")\n",
    "        print(df.info())\n",
    "       \n",
    "        # 결측값 확인\n",
    "        print(\"\\n결측값 확인:\")\n",
    "        print(df.isnull().sum())\n",
    "       \n",
    "        # 데이터 요약 통계\n",
    "        print(\"\\n기초 통계:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        # 시각화 예제\n",
    "        # 1. 특정 열의 값 분포 확인 (예: '상태' 열)\n",
    "        if '상태' in df.columns:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            df['상태'].value_counts().plot(kind='bar', title='상태별 분포')\n",
    "            plt.xlabel('상태')\n",
    "            plt.ylabel('개수')\n",
    "            plt.show()\n",
    "       \n",
    "        # 2. 시간별 데이터 추세 (예: '시간' 열이 있을 경우)\n",
    "        if '시간' in df.columns:\n",
    "            df['시간'] = pd.to_datetime(df['시간'])  # 시간 열을 datetime 형식으로 변환\n",
    "            df.set_index('시간', inplace=True)\n",
    "            df.resample('D').size().plot(title='시간별 데이터 추세')\n",
    "            plt.xlabel('날짜')\n",
    "            plt.ylabel('건수')\n",
    "            plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    # 1. 인증 파일 경로 설정\n",
    "    def set_credentials():\n",
    "        credentials_path = \"D:\\\\구글key\\\\credentials.json\"  # 실제 credentials.json 파일 경로 입력\n",
    "        if not os.path.exists(credentials_path):\n",
    "            raise FileNotFoundError(\"credentials.json 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        print(\"인증 파일 경로 확인 완료: credentials.json\")\n",
    "        return credentials_path\n",
    "\n",
    "    # 2. Google Drive 인증\n",
    "    def authenticate_google_drive(credentials_path):\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "        creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)\n",
    "        drive_service = build('drive', 'v3', credentials=creds)\n",
    "        return drive_service\n",
    "\n",
    "    # Step 1: 인증 파일 경로 가져오기\n",
    "    credentials_path = set_credentials()\n",
    "\n",
    "    # Step 2: Google Drive 인증\n",
    "    drive_service = authenticate_google_drive(credentials_path)\n",
    "\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=100, fields=\"nextPageToken, files(id, name, mimeType)\"\n",
    "    ).execute()\n",
    "    files = results.get('files', [])\n",
    "   \n",
    "    if not files:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "        return\n",
    "   \n",
    "    print(\"Google Drive 파일 목록:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} (ID: {file['id']}, MIME Type: {file['mimeType']})\")\n",
    "   \n",
    "    # Step 4: '일시정지관리' 파일 다운로드 및 변환\n",
    "    target_file = next((f for f in files if f['name'] == '일시정지관리'), None)\n",
    "    if not target_file:\n",
    "        print(\"Google Drive에 '일시정지관리' 파일이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    file_id = target_file['id']\n",
    "    file_name = target_file['name']\n",
    "    file_path = download_google_sheets_as_csv(drive_service, file_id, file_name + \".csv\")\n",
    "\n",
    "    # Step 5: 다운로드한 CSV 파일 분석 및 시각화\n",
    "    analyze_and_visualize(file_path)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f5effab-77f7-47c4-888b-7a17db53bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인증 파일 경로 확인 완료: credentials.json\n",
      "Google Drive 파일 목록:\n",
      "코인정보 (ID: 1Fla5yZ3owaIOaSfRJF8PAly_7i2itC2BILtAlZgVJtI, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "유통망정산 (ID: 1gZ468AqM4wApPDMD5LZnA3WZpi2q6zqP8M4ZU_xUWcY, MIME Type: application/vnd.google-apps.spreadsheet)\n",
      "Google Drive에 '일시정지관리' 파일이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2.service_account import Credentials\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Google Drive 파일 다운로드 (Export 방식)\n",
    "def download_google_sheets_as_csv(drive_service, file_id, file_name):\n",
    "    # CSV 형식으로 변환하여 다운로드\n",
    "    request = drive_service.files().export_media(fileId=file_id, mimeType='text/csv')\n",
    "    file_path = os.path.join(os.getcwd(), file_name)\n",
    "    with io.FileIO(file_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"다운로드 진행률: {int(status.progress() * 100)}%\")\n",
    "    print(f\"파일 다운로드 완료: {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "# 데이터 분석 및 시각화 함수\n",
    "def analyze_and_visualize(file_path):\n",
    "    try:\n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"CSV 데이터 미리보기:\")\n",
    "        print(df.head())\n",
    "       \n",
    "        # 데이터프레임 정보 확인\n",
    "        print(\"\\n데이터프레임 요약:\")\n",
    "        print(df.info())\n",
    "       \n",
    "        # 결측값 확인\n",
    "        print(\"\\n결측값 확인:\")\n",
    "        print(df.isnull().sum())\n",
    "       \n",
    "        # 데이터 요약 통계\n",
    "        print(\"\\n기초 통계:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        # 시각화 예제\n",
    "        # 1. '관리지사'별 계약 수 분포\n",
    "        if '관리지사' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df['관리지사'].value_counts().plot(kind='bar', title='관리지사별 계약 수')\n",
    "            plt.xlabel('관리지사')\n",
    "            plt.ylabel('계약 수')\n",
    "            plt.show()\n",
    "\n",
    "        # 2. 서비스(소)별 분포\n",
    "        if '서비스(소)' in df.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df['서비스(소)'].value_counts().plot(kind='bar', title='서비스(소)별 분포')\n",
    "            plt.xlabel('서비스(소)')\n",
    "            plt.ylabel('개수')\n",
    "            plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 분석 중 오류 발생: {e}\")\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    # 1. 인증 파일 경로 설정\n",
    "    def set_credentials():\n",
    "        credentials_path = \"D:\\\\구글key\\\\credentials.json\"  # 실제 credentials.json 파일 경로 입력\n",
    "        if not os.path.exists(credentials_path):\n",
    "            raise FileNotFoundError(\"credentials.json 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        print(\"인증 파일 경로 확인 완료: credentials.json\")\n",
    "        return credentials_path\n",
    "\n",
    "    # 2. Google Drive 인증\n",
    "    def authenticate_google_drive(credentials_path):\n",
    "        SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "        creds = Credentials.from_service_account_file(credentials_path, scopes=SCOPES)\n",
    "        drive_service = build('drive', 'v3', credentials=creds)\n",
    "        return drive_service\n",
    "\n",
    "    # Step 1: 인증 파일 경로 가져오기\n",
    "    credentials_path = set_credentials()\n",
    "\n",
    "    # Step 2: Google Drive 인증\n",
    "    drive_service = authenticate_google_drive(credentials_path)\n",
    "\n",
    "    # Step 3: Google Drive 파일 목록 가져오기\n",
    "    results = drive_service.files().list(\n",
    "        pageSize=100, fields=\"nextPageToken, files(id, name, mimeType)\"\n",
    "    ).execute()\n",
    "    files = results.get('files', [])\n",
    "   \n",
    "    if not files:\n",
    "        print(\"Google Drive에 파일이 없습니다.\")\n",
    "        return\n",
    "   \n",
    "    print(\"Google Drive 파일 목록:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} (ID: {file['id']}, MIME Type: {file['mimeType']})\")\n",
    "   \n",
    "    # Step 4: '일시정지관리' 파일 다운로드 및 변환\n",
    "    target_file = next((f for f in files if f['name'] == '일시정지관리'), None)\n",
    "    if not target_file:\n",
    "        print(\"Google Drive에 '일시정지관리' 파일이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    file_id = target_file['id']\n",
    "    file_name = target_file['name']\n",
    "    file_path = download_google_sheets_as_csv(drive_service, file_id, file_name + \".csv\")\n",
    "\n",
    "    # Step 5: 다운로드한 CSV 파일 분석 및 시각화\n",
    "    analyze_and_visualize(file_path)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19fa1ea-0886-4256-aeca-8172a30caf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관리본부코드\n",
      "관리본부명\n",
      "관리지사코드\n",
      "관리지사명\n",
      "고객번호\n",
      "고객명\n",
      "계약번호\n",
      "유지보수기간\n",
      "계약자명\n",
      "서비스번호\n",
      "서비스(대)\n",
      "서비스(중)\n",
      "서비스(소)\n",
      "영상전환일\n",
      "상호\n",
      "고객구분\n",
      "사업용구분\n",
      "주민등록번호\n",
      "사업자번호\n",
      "계약상태(대)\n",
      "계약상태(중)\n",
      "서비스상태(대)\n",
      "서비스상태(중)\n",
      "접속전화번호\n",
      "설치우편번호\n",
      "설치주소\n",
      "견적월정료\n",
      "KTT월정료\n",
      "KT월정료\n",
      "할인율(%)\n",
      "계약개월수\n",
      "월정료 면제사유\n",
      "면제시작일\n",
      "면제종료일\n",
      "계약보증금\n",
      "보증금 면제사유\n",
      "판매상품비\n",
      "견적설치공사비\n",
      "설치공사할부개월\n",
      "계약공사비(ktt)\n",
      "계약공사비(kt)\n",
      "면제공사비\n",
      "실징수액\n",
      "계약시작일\n",
      "계약종료일\n",
      "영업구분\n",
      "추천구분\n",
      "추천경로\n",
      "영업본부코드\n",
      "영업본부명\n",
      "영업지사코드\n",
      "영업지사명\n",
      "영업자소속\n",
      "영업자사번\n",
      "영업자명\n",
      "영업자연락처\n",
      "모집유형\n",
      "가망고객번호\n",
      "추천본부코드\n",
      "추천본부명\n",
      "추천지사코드\n",
      "추천지사명\n",
      "유통망대분류\n",
      "유통망중분류\n",
      "유통망소분류\n",
      "추천자사번\n",
      "추천자명\n",
      "추천자유형\n",
      "정보제공자부서\n",
      "정보제공자사번\n",
      "정보제공자명\n",
      "정보제공자연락처\n",
      "청구본부코드\n",
      "청구본부명\n",
      "청구지사코드\n",
      "청구지사명\n",
      "청구자명\n",
      "합산여부\n",
      "수납구분\n",
      "세금계산서발행여부\n",
      "계산서발행여부\n",
      "선후납구분\n",
      "청구번호\n",
      "청구전화번호\n",
      "청구우편번호\n",
      "청구주소\n",
      "청약일자\n",
      "청약취소일자\n",
      "공사희망일\n",
      "공사예정일\n",
      "공사완료일\n",
      "준공완료일\n",
      "관제개통일\n",
      "서비스개시일\n",
      "서비스재개시일\n",
      "공사의뢰유형\n",
      "회선방식(대)\n",
      "회선방식(중)\n",
      "MUX / SYSTEM_ID\n",
      "전용회선번호\n",
      "MIN번호\n",
      "정지시작일자\n",
      "해지일자\n",
      "종목\n",
      "업태\n",
      "업종(대)\n",
      "업종(중)\n",
      "보험등급\n",
      "비고\n",
      "결합구분\n",
      "결합상품명\n",
      "결합약정개월수\n",
      "결합시작일\n",
      "금융기관코드\n",
      "면책구분\n",
      "타사전환\n",
      "이전고객번호\n",
      "E-MAIL\n",
      "담당자\n",
      "휴대폰\n",
      "전입신규여부\n",
      "고객추가정보\n",
      "계약최초서비스게시일\n",
      "청약취소사유\n",
      "계약본부\n",
      "계약지사\n",
      "매출본사\n",
      "출동구역정보\n",
      "영업구역정보\n",
      "구역담당지점\n",
      "구역담당영업사원\n",
      "선장품\n",
      "브랜드\n",
      "보조회선\n",
      "고객계약유형\n",
      "A/S운용기간\n",
      "판매할부개월\n",
      "월정료일시납\n",
      "장기요금인상여부\n",
      "장기요금인상액\n",
      "장기Upselling여부\n",
      "장기Upselling매출액\n",
      "기술구역정보\n",
      "계약서작성주체\n",
      "카드사명\n",
      "GiGAeyes계약Id\n",
      "월정료\n",
      "kt oct 마스터 아이디\n",
      "정지희망종료일\n",
      "보조MIN번호\n",
      "영업지점\n",
      "설치지점\n",
      "팩토링여부\n",
      "외부고객KEY\n",
      "무인매장구분\n",
      "무인매장업종구분\n",
      "팩토링상태\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정, 확장자가 .cs\n",
    "file_path = 'D:/시설/정지/일일정지/고객리스트 정지시설 전체/C150_G0000_00024.csv'\n",
    "\n",
    "# CSV 파일 읽기, 헤더 및 데이터 타입 경고 처리\n",
    "df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "# 헤더만 출력, 보기 좋게 줄바꿈하여 표시\n",
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dbb328-8611-49dc-b668-d925b4cc8eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['영업채널', '매출인정구분', '시설구분', '요금구분', '실적본부', '실적지사', '실적최초등록일', '실적구분', '매출구분', '영업본부2', '영업지사2', '실적채널', '실적부서', 'KTT월정료(조정)', 'KT월정료(조정)', '고알프', '제외사유'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     10\u001b[0m columns_to_extract \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m관리본부명\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m관리지사명\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m계약번호\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m서비스(중)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m서비스(소)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m상호\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m고객구분\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m사업용구분\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m계약상태(중)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m서비스상태(중)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m설치주소\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m월정료\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m계약시작일\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m영업자명\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m영업채널\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m청구번호\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m서비스개시일\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKTT월정료(조정)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKT월정료(조정)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m고알프\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m제외사유\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 지정된 헤더만 추출\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m df[columns_to_extract]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# \"관리본부명\" 값 변경: \"강원본부\"를 \"강북강원본부\"로 변경\u001b[39;00m\n\u001b[0;32m     23\u001b[0m filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m관리본부명\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m관리본부명\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m강원본부\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m강북/강원본부\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['영업채널', '매출인정구분', '시설구분', '요금구분', '실적본부', '실적지사', '실적최초등록일', '실적구분', '매출구분', '영업본부2', '영업지사2', '실적채널', '실적부서', 'KTT월정료(조정)', 'KT월정료(조정)', '고알프', '제외사유'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정 (확장자 .cs)\n",
    "file_path = 'D:/시설/정지/일일정지/고객리스트 정지시설 전체/C150_G0000_00024.csv'\n",
    "\n",
    "# CSV 파일 읽기 (헤더 및 데이터 타입 경고 처리)\n",
    "df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "# 추출할 헤더(열) 지정\n",
    "columns_to_extract = ['관리본부명', '관리지사명', '계약번호', '서비스(중)', '서비스(소)', '상호',\n",
    "    '고객구분', '사업용구분', '계약상태(중)', '서비스상태(중)',\n",
    "    '설치주소', '월정료', '계약시작일', '영업자명', '영업채널', '청구번호', '서비스개시일',\n",
    "    '서비스재개시일', '정지시작일자', '종목', 'E-MAIL', '담당자', '휴대폰', '계약최초서비스게시일', '매출본사',\n",
    "    '매출인정구분', '시설구분', '요금구분', '고객계약유형', '실적본부', '실적지사',\n",
    "    '실적최초등록일', '실적구분', '영업구역정보', '매출구분', '영업본부2', '영업지사2', '실적채널', '실적부서',\n",
    "    'KTT월정료(조정)', 'KT월정료(조정)',\n",
    "    '고알프', '제외사유']\n",
    "\n",
    "# 지정된 헤더만 추출\n",
    "extracted_data = df[columns_to_extract]\n",
    "\n",
    "# \"관리본부명\" 값 변경: \"강원본부\"를 \"강북강원본부\"로 변경\n",
    "filtered_data['관리본부명'] = filtered_data['관리본부명'].replace('강원본부', '강북/강원본부')\n",
    "filtered_data['관리본부명'] = filtered_data['관리본부명'].replace('서부본부', '강남/서부본부')\n",
    "\n",
    "\n",
    "# 추출한 데이터 저장 (엑셀 파일로)\n",
    "output_path = 'D:/시설/정지/일일정지/고객리스트 정지시설 전체/2025년0108_전사 정지조건리스트_db.xlsx'\n",
    "extracted_data.to_excel(output_path, index=False, engine='openpyxl')  # openpyxl 엔진 사용\n",
    "\n",
    "# 추출한 데이터 표시\n",
    "print(\"지정된 헤더 데이터가 저장되었습니다:\", output_path)\n",
    "display(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43414a3-8bdb-404f-b80b-997039376313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff177e0-9ea3-4b70-9e35-e3dd0e576d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계약번호 ['관리본부코드', '관리본부명', '관리지사코드', '관리지사명', '고객번호', '고객명', '계약번호', '유지보수기간', '계약자명', '서비스번호', '서비스(대)', '서비스(중)', '서비스(소)', '영상전환일', '상호', '고객구분', '사업용구분', '주민등록번호', '사업자번호', '계약상태(대)', '계약상태(중)', '서비스상태(대)', '서비스상태(중)', '접속전화번호', '설치우편번호', '설치주소', '견적월정료', 'KTT월정료', 'KT월정료', '할인율(%)', '계약개월수', '월정료 면제사유', '면제시작일', '면제종료일', '계약보증금', '보증금 면제사유', '판매상품비', '견적설치공사비', '설치공사할부개월', '계약공사비(ktt)', '계약공사비(kt)', '면제공사비', '실징수액', '계약시작일', '계약종료일', '영업구분', '추천구분', '추천경로', '영업본부코드', '영업본부명', '영업지사코드', '영업지사명', '영업자소속', '영업자사번', '영업자명', '영업자연락처', '모집유형', '가망고객번호', '추천본부코드', '추천본부명', '추천지사코드', '추천지사명', '유통망대분류', '유통망중분류', '유통망소분류', '추천자사번', '추천자명', '추천자유형', '정보제공자부서', '정보제공자사번', '정보제공자명', '정보제공자연락처', '청구본부코드', '청구본부명', '청구지사코드', '청구지사명', '청구자명', '합산여부', '수납구분', '세금계산서발행여부', '계산서발행여부', '선후납구분', '청구번호', '청구전화번호', '청구우편번호', '청구주소', '청약일자', '청약취소일자', '공사희망일', '공사예정일', '공사완료일', '준공완료일', '관제개통일', '서비스개시일', '서비스재개시일', '공사의뢰유형', '회선방식(대)', '회선방식(중)', 'MUX / SYSTEM_ID', '전용회선번호', 'MIN번호', '정지시작일자', '해지일자', '종목', '업태', '업종(대)', '업종(중)', '보험등급', '비고', '결합구분', '결합상품명', '결합약정개월수', '결합시작일', '금융기관코드', '면책구분', '타사전환', '이전고객번호', 'E-MAIL', '담당자', '휴대폰', '전입신규여부', '고객추가정보', '계약최초서비스게시일', '청약취소사유', '계약본부', '계약지사', '매출본사', '출동구역정보', '영업구역정보', '구역담당지점', '구역담당영업사원', '선장품', '브랜드', '보조회선', '고객계약유형', 'A/S운용기간', '판매할부개월', '월정료일시납', '장기요금인상여부', '장기요금인상액', '장기Upselling여부', '장기Upselling매출액', '기술구역정보', '계약서작성주체', '카드사명', 'GiGAeyes계약Id', '월정료', 'kt oct 마스터 아이디', '정지희망종료일', '보조MIN번호', '영업지점', '설치지점', '팩토링여부', '외부고객KEY', '무인매장구분', '무인매장업종구분', '팩토링상태']\n",
      "필터링된 헤더를 D:\\시설\\정지\\일일정지\\20250131\\filtered_headers.xlsx에 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 파일 경로 설정 (윈도우 드라이브 경로)\n",
    "file_path = r\"D:\\시설\\정지\\일일정지\\20250131\\G000_02995_00008.csv\"\n",
    "output_excel_path = r\"D:\\시설\\정지\\일일정지\\20250131\\filtered_headers.xlsx\"\n",
    "\n",
    "try:\n",
    "    # CSV 파일 불러오기 (인코딩 자동 감지)\n",
    "    df = pd.read_csv(file_path, encoding=\"utf-8\", low_memory=False)\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding=\"cp949\", low_memory=False)\n",
    "except Exception as e:\n",
    "    print(f\"파일 로드 실패: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 헤더 리스트 가져오기\n",
    "headers = df.columns.tolist()\n",
    "print(\"계약번호\", headers)\n",
    "\n",
    "# 특정 조건에 맞는 헤더만 선택 (예: '정지' 포함하는 컬럼)\n",
    "condition_headers = [col for col in headers if \"정지\" in col]\n",
    "\n",
    "# 결과 저장할 DataFrame 생성\n",
    "filtered_df = pd.DataFrame({\"Filtered Headers\": condition_headers})\n",
    "\n",
    "# Excel 파일로 저장\n",
    "filtered_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"필터링된 헤더를 {output_excel_path}에 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ed26eac-705d-43cf-9772-f469ef68c6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관리본부코드\n",
      "관리본부명\n",
      "관리지사코드\n",
      "관리지사명\n",
      "고객번호\n",
      "고객명\n",
      "계약번호\n",
      "유지보수기간\n",
      "계약자명\n",
      "서비스번호\n",
      "서비스(대)\n",
      "서비스(중)\n",
      "서비스(소)\n",
      "영상전환일\n",
      "상호\n",
      "고객구분\n",
      "사업용구분\n",
      "주민등록번호\n",
      "사업자번호\n",
      "계약상태(대)\n",
      "계약상태(중)\n",
      "서비스상태(대)\n",
      "서비스상태(중)\n",
      "접속전화번호\n",
      "설치우편번호\n",
      "설치주소\n",
      "견적월정료\n",
      "KTT월정료\n",
      "KT월정료\n",
      "할인율(%)\n",
      "계약개월수\n",
      "월정료 면제사유\n",
      "면제시작일\n",
      "면제종료일\n",
      "계약보증금\n",
      "보증금 면제사유\n",
      "판매상품비\n",
      "견적설치공사비\n",
      "설치공사할부개월\n",
      "계약공사비(ktt)\n",
      "계약공사비(kt)\n",
      "면제공사비\n",
      "실징수액\n",
      "계약시작일\n",
      "계약종료일\n",
      "영업구분\n",
      "추천구분\n",
      "추천경로\n",
      "영업본부코드\n",
      "영업본부명\n",
      "영업지사코드\n",
      "영업지사명\n",
      "영업자소속\n",
      "영업자사번\n",
      "영업자명\n",
      "영업자연락처\n",
      "모집유형\n",
      "가망고객번호\n",
      "추천본부코드\n",
      "추천본부명\n",
      "추천지사코드\n",
      "추천지사명\n",
      "유통망대분류\n",
      "유통망중분류\n",
      "유통망소분류\n",
      "추천자사번\n",
      "추천자명\n",
      "추천자유형\n",
      "정보제공자부서\n",
      "정보제공자사번\n",
      "정보제공자명\n",
      "정보제공자연락처\n",
      "청구본부코드\n",
      "청구본부명\n",
      "청구지사코드\n",
      "청구지사명\n",
      "청구자명\n",
      "합산여부\n",
      "수납구분\n",
      "세금계산서발행여부\n",
      "계산서발행여부\n",
      "선후납구분\n",
      "청구번호\n",
      "청구전화번호\n",
      "청구우편번호\n",
      "청구주소\n",
      "청약일자\n",
      "청약취소일자\n",
      "공사희망일\n",
      "공사예정일\n",
      "공사완료일\n",
      "준공완료일\n",
      "관제개통일\n",
      "서비스개시일\n",
      "서비스재개시일\n",
      "공사의뢰유형\n",
      "회선방식(대)\n",
      "회선방식(중)\n",
      "MUX / SYSTEM_ID\n",
      "전용회선번호\n",
      "MIN번호\n",
      "정지시작일자\n",
      "해지일자\n",
      "종목\n",
      "업태\n",
      "업종(대)\n",
      "업종(중)\n",
      "보험등급\n",
      "비고\n",
      "결합구분\n",
      "결합상품명\n",
      "결합약정개월수\n",
      "결합시작일\n",
      "금융기관코드\n",
      "면책구분\n",
      "타사전환\n",
      "이전고객번호\n",
      "E-MAIL\n",
      "담당자\n",
      "휴대폰\n",
      "전입신규여부\n",
      "고객추가정보\n",
      "계약최초서비스게시일\n",
      "청약취소사유\n",
      "계약본부\n",
      "계약지사\n",
      "매출본사\n",
      "출동구역정보\n",
      "영업구역정보\n",
      "구역담당지점\n",
      "구역담당영업사원\n",
      "선장품\n",
      "브랜드\n",
      "보조회선\n",
      "고객계약유형\n",
      "A/S운용기간\n",
      "판매할부개월\n",
      "월정료일시납\n",
      "장기요금인상여부\n",
      "장기요금인상액\n",
      "장기Upselling여부\n",
      "장기Upselling매출액\n",
      "기술구역정보\n",
      "계약서작성주체\n",
      "카드사명\n",
      "GiGAeyes계약Id\n",
      "월정료\n",
      "kt oct 마스터 아이디\n",
      "정지희망종료일\n",
      "보조MIN번호\n",
      "영업지점\n",
      "설치지점\n",
      "팩토링여부\n",
      "외부고객KEY\n",
      "무인매장구분\n",
      "무인매장업종구분\n",
      "팩토링상태\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정, 확장자가 .cs\n",
    "file_path = 'D:/시설/정지/일일정지/20250131/G000_02995_00008.csv'\n",
    "\n",
    "# CSV 파일 읽기, 헤더 및 데이터 타입 경고 처리\n",
    "df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "# 헤더만 출력, 보기 좋게 줄바꿈하여 표시\n",
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5610e1ea-97b3-48c0-ac6f-b13918e5596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 엑셀 및 CS 파일이 저장되었습니다:\n",
      " - 엑셀 파일: D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_db.xlsx\n",
      " - CS 파일: D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_db.cs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250209\\C150_G0000_00019.csv'\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_db.xlsx'\n",
    "output_cs_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_db.cs'  # CSV 대신 CS 확장자로 저장\n",
    "\n",
    "try:\n",
    "    # CSV 파일 읽기 (인코딩 처리 및 경고 방지)\n",
    "    df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "   \n",
    "    # 추출할 헤더(열) 지정\n",
    "    columns_to_extract = ['관리본부명', '관리지사명', '계약번호',\n",
    "                          '서비스(대)', '서비스(중)', '서비스(소)', '상호', '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료',\n",
    "                          '계약시작일', '계약종료일',\n",
    "                          '영업자명', '정지시작일자', '정지희망종료일', '담당자', '휴대폰', '계약최초서비스게시일',\n",
    "                          '영업구역정보','kt oct 마스터 아이디', '외부고객KEY', '무인매장구분',\n",
    "                          '무인매장업종구분']\n",
    "   \n",
    "    # 데이터에서 지정된 헤더만 추출\n",
    "    extracted_data = df[columns_to_extract].copy()  # 복사하여 수정 가능하도록 함\n",
    "\n",
    "    # \"관리본부명\" 값 변경\n",
    "    extracted_data['관리본부명'] = extracted_data['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "    # 🔹 서비스(소)가 공백(NaN)인 경우 서비스(중) 값으로 대체\n",
    "    extracted_data['서비스(소)'] = extracted_data['서비스(소)'].fillna(extracted_data['서비스(중)'])\n",
    "\n",
    "    # 날짜 변환 함수 정의\n",
    "    def convert_date(date_str):\n",
    "        \"\"\" YYYYMMDD 또는 YYYYMMDDHHMMSS 형식을 YYYY-MM-DD로 변환 \"\"\"\n",
    "        try:\n",
    "            date_str = str(date_str).strip()  # 문자열 변환 후 공백 제거\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"  # YYYY-MM-DD 변환\n",
    "            else:\n",
    "                return None  # 변환 불가능한 값은 None 처리\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 날짜 변환 적용할 필드 목록\n",
    "    date_columns = ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']\n",
    "\n",
    "    # 각 날짜 컬럼 변환 적용\n",
    "    for col in date_columns:\n",
    "        extracted_data[col] = extracted_data[col].astype(str).apply(convert_date)\n",
    "\n",
    "    # 천단위 콤마 변환 함수 정의 (NaN 또는 0은 공백)\n",
    "    def format_currency(value):\n",
    "        \"\"\" 숫자를 천단위 콤마 적용한 문자열로 변환 (예: 60000 -> 60,000, NaN & 0 -> 공백) \"\"\"\n",
    "        try:\n",
    "            if pd.isna(value) or value in [\"0\", \"0.0\"]:  # NaN 또는 0이면 공백 처리\n",
    "                return \"\"\n",
    "            return int(float(value))  # 엑셀에서 회계 형식 적용 가능하도록 숫자로 변환\n",
    "        except:\n",
    "            return value  # 변환 실패 시 원본 값 유지\n",
    "\n",
    "    # 천단위 콤마 적용할 필드 목록\n",
    "    currency_columns = ['KTT월정료']\n",
    "\n",
    "    # 각 숫자 컬럼 변환 적용 (NaN 및 0을 공백으로 변환)\n",
    "    for col in currency_columns:\n",
    "        extracted_data[col] = extracted_data[col].astype(str).apply(format_currency)\n",
    "\n",
    "    # 엑셀 파일로 저장 (일반 저장)\n",
    "    extracted_data.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # 🔹 엑셀에서 회계 형식 적용 (₩ 제외, 천단위 콤마 유지)\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    for col in ws.iter_cols():\n",
    "        if col[0].value in currency_columns:  # 월정료 관련 컬럼만 적용\n",
    "            for cell in col[1:]:  # 헤더 제외, 데이터 행부터 적용\n",
    "                if isinstance(cell.value, (int, float)):  # 숫자만 서식 적용\n",
    "                    cell.number_format = '#,##0'  # 원화(₩) 없이 천단위 콤마 적용\n",
    "                    cell.alignment = Alignment(horizontal='right')  # 오른쪽 정렬\n",
    "\n",
    "    # 수정된 엑셀 저장\n",
    "    wb.save(output_excel_path)\n",
    "\n",
    "    # 🔹 CS 확장자로 CSV 저장 (쉼표로 구분)\n",
    "    extracted_data.to_csv(output_cs_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(\"✅ 엑셀 및 CS 파일이 저장되었습니다:\")\n",
    "    print(f\" - 엑셀 파일: {output_excel_path}\")\n",
    "    print(f\" - CS 파일: {output_cs_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbefff5-412b-4cc3-884b-0611ebe2be21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 일수, 일수구간, 금액구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48784b95-74ca-432e-93df-21898d5a92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250209\\C150_G0000_00019.csv'\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_db_일수,금액구간적용.xlsx'\n",
    "output_cs_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_db_일수,금액구간적용.cs'  # CSV 대신 CS 확장자로 저장\n",
    "\n",
    "try:\n",
    "    # CSV 파일 읽기 (인코딩 처리 및 경고 방지)\n",
    "    df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "    # ✅ **오류 수정: 모든 문자열에 따옴표(`'`) 추가**\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '계약번호', '서비스(대)', '서비스(중)', '서비스(소)', '상호',\n",
    "        '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료', '계약시작일', '계약종료일',\n",
    "        '영업자명', '정지시작일자', '정지희망종료일', '담당자', '휴대폰', '계약최초서비스게시일',\n",
    "        '영업구역정보', 'kt oct 마스터 아이디', '외부고객KEY', '무인매장구분', '무인매장업종구분'\n",
    "    ]\n",
    "\n",
    "    # 데이터에서 지정된 헤더만 추출\n",
    "    extracted_data = df[columns_to_extract].copy()\n",
    "\n",
    "    # \"관리본부명\" 값 변경\n",
    "    extracted_data['관리본부명'] = extracted_data['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "    # 🔹 서비스(소)가 공백(NaN)인 경우 서비스(중) 값으로 대체\n",
    "    extracted_data['서비스(소)'] = extracted_data['서비스(소)'].fillna(extracted_data['서비스(중)'])\n",
    "\n",
    "    # 날짜 변환 함수 정의\n",
    "    def convert_date(date_str):\n",
    "        \"\"\"YYYYMMDD 또는 YYYYMMDDHHMMSS 형식을 YYYY-MM-DD로 변환\"\"\"\n",
    "        try:\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 날짜 변환 적용할 필드 목록\n",
    "    date_columns = ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']\n",
    "\n",
    "    # 각 날짜 컬럼 변환 적용\n",
    "    for col in date_columns:\n",
    "        extracted_data[col] = extracted_data[col].astype(str).apply(convert_date)\n",
    "\n",
    "    # 현재 실행하는 달의 말일 계산 (예: 2월이면 2월 28일 또는 29일)\n",
    "    today = datetime.today()\n",
    "    last_day_of_month = (today.replace(day=1) + timedelta(days=31)).replace(day=1) - timedelta(days=1)\n",
    "\n",
    "    # 🔹 정지일수 계산 함수\n",
    "    def calculate_freeze_days(start_date, end_date, reference_end_date):\n",
    "        \"\"\"정지시작일자부터 종료일까지의 일수를 계산, 종료일이 없으면 기준 종료일 사용\"\"\"\n",
    "        try:\n",
    "            if pd.isna(start_date):\n",
    "                return None\n",
    "            start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "            # 종료일이 없으면 기준 종료일(현재 달의 말일) 사용\n",
    "            end_date = datetime.strptime(end_date, \"%Y-%m-%d\") if pd.notna(end_date) else reference_end_date\n",
    "\n",
    "            freeze_days = (end_date - start_date).days + 1\n",
    "            return freeze_days if freeze_days > 0 else 0\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 종료기준 정지일수 (정지희망종료일까지 계산)\n",
    "    extracted_data['종료기준 정지일수'] = extracted_data.apply(\n",
    "        lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일'], last_day_of_month), axis=1\n",
    "    )\n",
    "\n",
    "    # 당월기준 정지일수 (당월 말일까지 계산)\n",
    "    extracted_data['당월기준 정지일수'] = extracted_data.apply(\n",
    "        lambda row: calculate_freeze_days(row['정지시작일자'], last_day_of_month.strftime(\"%Y-%m-%d\"), last_day_of_month), axis=1\n",
    "    )\n",
    "\n",
    "    # 🔹 일시정지 구간 추가 (종료기준 & 당월기준)\n",
    "    def categorize_freeze_days(days):\n",
    "        \"\"\"일시정지 일수를 기준으로 구간을 설정\"\"\"\n",
    "        if pd.isna(days):\n",
    "            return None\n",
    "        elif days <= 89:\n",
    "            return '89일 이하'\n",
    "        elif 90 <= days <= 119:\n",
    "            return '90~119일'\n",
    "        elif 120 <= days <= 149:\n",
    "            return '120~149일'\n",
    "        else:\n",
    "            return '150일 이상'\n",
    "\n",
    "    # 종료기준 정지구간\n",
    "    extracted_data['종료기준 정지구간'] = extracted_data['종료기준 정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # 당월기준 정지구간\n",
    "    extracted_data['당월기준 정지구간'] = extracted_data['당월기준 정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # 🔹 KTT월정료 금액 구간 추가\n",
    "    def categorize_fee(amount):\n",
    "        \"\"\"KTT월정료를 기준으로 금액 구간을 설정\"\"\"\n",
    "        try:\n",
    "            amount = float(amount)\n",
    "            if amount <= 50000:\n",
    "                return '5만원 이하'\n",
    "            elif 50000 < amount <= 70000:\n",
    "                return '5만원 초과 ~ 7만원 이하'\n",
    "            elif 70000 < amount <= 100000:\n",
    "                return '7만원 초과 ~ 10만원 이하'\n",
    "            elif 100000 < amount <= 200000:\n",
    "                return '10만원 초과 ~ 20만원 이하'\n",
    "            else:\n",
    "                return '20만원 초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    extracted_data['월정료 구간'] = extracted_data['KTT월정료'].apply(categorize_fee)\n",
    "\n",
    "    # 엑셀 파일로 저장\n",
    "    extracted_data.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # 🔹 CS 확장자로 CSV 저장\n",
    "    extracted_data.to_csv(output_cs_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(\"✅ 엑셀 및 CS 파일이 저장되었습니다:\")\n",
    "    print(f\" - 엑셀 파일: {output_excel_path}\")\n",
    "    print(f\" - CS 파일: {output_cs_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857c2d2-22f6-42ce-87de-ae9b011778c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 정지파일, 유지파일 조건 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbaae607-c1ec-4c4d-a3ce-cd5e2950dd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 엑셀 및 CS 파일이 저장되었습니다 (새 열은 맨 왼쪽, 노란색 음영 적용):\n",
      " - 엑셀 파일: D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_완성.xlsx\n",
      " - CS 파일: D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_완성.cs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 📌 파일 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250209\\C150_G0000_00019.csv'  # 기존 데이터\n",
    "additional_file_path = r\"D:\\시설\\정지\\일일정지\\고객리스트 정지시설 전체\\'24년12월 조건요약.cs\"  # 추가 데이터\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_완성.xlsx'\n",
    "output_cs_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_완성.cs'  # CSV 대신 CS 확장자로 저장\n",
    "\n",
    "try:\n",
    "    # 📌 기존 데이터 불러오기\n",
    "    df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "    # 📌 필요한 컬럼만 추출\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '계약번호', '서비스(대)', '서비스(중)', '서비스(소)', '상호',\n",
    "        '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료', '계약시작일', '계약종료일',\n",
    "        '영업자명', '정지시작일자', '정지희망종료일', '담당자', '휴대폰', '계약최초서비스게시일',\n",
    "        '영업구역정보', 'kt oct 마스터 아이디', '외부고객KEY', '무인매장구분', '무인매장업종구분'\n",
    "    ]\n",
    "    df = df[columns_to_extract]\n",
    "\n",
    "    # 📌 추가 데이터 불러오기\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "    # 📌 필요한 컬럼 선택 (계약번호 기준으로 병합)\n",
    "    additional_columns = ['계약번호', '시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프']\n",
    "    additional_df = additional_df[additional_columns]\n",
    "\n",
    "    # 📌 계약번호 기준으로 추가 데이터 병합 (LEFT JOIN)\n",
    "    df = df.merge(additional_df, on='계약번호', how='left')\n",
    "\n",
    "    # 📌 새 열을 기존 데이터의 맨 왼쪽으로 이동\n",
    "    new_columns = additional_columns + columns_to_extract\n",
    "    df = df[new_columns]\n",
    "\n",
    "    # 📌 \"관리본부명\" 값 변경\n",
    "    df['관리본부명'] = df['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "    # 📌 서비스(소)가 공백(NaN)인 경우 서비스(중) 값으로 대체\n",
    "    df['서비스(소)'] = df['서비스(소)'].fillna(df['서비스(중)'])\n",
    "\n",
    "    # 📌 날짜 변환 함수\n",
    "    def convert_date(date_str):\n",
    "        \"\"\"YYYYMMDD 또는 YYYYMMDDHHMMSS 형식을 YYYY-MM-DD로 변환\"\"\"\n",
    "        try:\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 📌 날짜 변환 적용할 필드 목록\n",
    "    date_columns = ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']\n",
    "    for col in date_columns:\n",
    "        df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    " # 📌 현재 실행하는 달의 말일 계산\n",
    "    today = datetime.today()\n",
    "    last_day_of_month = (today.replace(day=1) + timedelta(days=31)).replace(day=1) - timedelta(days=1)\n",
    "\n",
    "    # 📌 정지일수 계산 함수\n",
    "    def calculate_freeze_days(start_date, end_date, reference_end_date):\n",
    "        try:\n",
    "            if pd.isna(start_date):\n",
    "                return None\n",
    "            start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(end_date, \"%Y-%m-%d\") if pd.notna(end_date) else reference_end_date\n",
    "            freeze_days = (end_date - start_date).days + 1\n",
    "            return freeze_days if freeze_days > 0 else 0\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 📌 종료기준 정지일수 (정지희망종료일까지 계산)\n",
    "    df['종료기준 정지일수'] = df.apply(\n",
    "        lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일'], last_day_of_month), axis=1\n",
    "    )\n",
    "\n",
    "    # 📌 당월기준 정지일수 (당월 말일까지 계산)\n",
    "    df['당월기준 정지일수'] = df.apply(\n",
    "        lambda row: calculate_freeze_days(row['정지시작일자'], last_day_of_month.strftime(\"%Y-%m-%d\"), last_day_of_month), axis=1\n",
    "    )\n",
    "\n",
    "    # 📌 정지구간 분류 함수\n",
    "    def categorize_freeze_days(days):\n",
    "        if pd.isna(days):\n",
    "            return None\n",
    "        elif days <= 89:\n",
    "            return '89일 이하'\n",
    "        elif 90 <= days <= 119:\n",
    "            return '90~119일'\n",
    "        elif 120 <= days <= 149:\n",
    "            return '120~149일'\n",
    "        else:\n",
    "            return '150일 이상'\n",
    "\n",
    "    # 📌 종료기준 및 당월기준 정지구간 추가\n",
    "    df['종료기준 정지구간'] = df['종료기준 정지일수'].apply(categorize_freeze_days)\n",
    "    df['당월기준 정지구간'] = df['당월기준 정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # 📌 KTT월정료 금액 구간 추가\n",
    "    def categorize_fee(amount):\n",
    "        try:\n",
    "            amount = float(amount)\n",
    "            if amount <= 50000:\n",
    "                return '5만원 이하'\n",
    "            elif 50000 < amount <= 70000:\n",
    "                return '5만원 초과 ~ 7만원 이하'\n",
    "            elif 70000 < amount <= 100000:\n",
    "                return '7만원 초과 ~ 10만원 이하'\n",
    "            elif 100000 < amount <= 200000:\n",
    "                return '10만원 초과 ~ 20만원 이하'\n",
    "            else:\n",
    "                return '20만원 초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['월정료 구간'] = df['KTT월정료'].apply(categorize_fee)\n",
    "   \n",
    "    # 📌 엑셀 파일로 저장\n",
    "    df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # 📌 엑셀 파일 열어서 새 열을 노란색 음영(50%) 적용\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "\n",
    "    # 새로 추가된 열에 노란색 음영 적용\n",
    "    for col_num in range(1, len(additional_columns) + 1):  # 첫 번째 열부터 적용\n",
    "        for row_num in range(1, ws.max_row + 1):\n",
    "            ws.cell(row=row_num, column=col_num).fill = yellow_fill\n",
    "\n",
    "    \n",
    "    # 저장\n",
    "    wb.save(output_excel_path)\n",
    "\n",
    "    # 📌 CS 확장자로 CSV 저장\n",
    "    df.to_csv(output_cs_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(\"✅ 엑셀 및 CS 파일이 저장되었습니다 (새 열은 맨 왼쪽, 노란색 음영 적용):\")\n",
    "    print(f\" - 엑셀 파일: {output_excel_path}\")\n",
    "    print(f\" - CS 파일: {output_cs_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류 발생:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd95bb-634c-40db-ac22-0f464874a365",
   "metadata": {},
   "source": [
    "## ktt월정료 공백, 제외사유 있음 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b88e57ef-064f-4690-8028-cf2db7774b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 엑셀 및 CS 파일이 저장되었습니다 (5884행 유지, 추가 열 노란색 음영 적용):\n",
      " - 엑셀 파일: D:\\시설\\정지\\일일정지\\20250212\\2025년0212_전사 정지조건리스트_완성.xlsx\n",
      " - CS 파일: D:\\시설\\정지\\일일정지\\20250212\\2025년0212_전사 정지조건리스트_완성.cs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 📌 파일 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250212\\C150_G0000_00072.csv'  # 기존 데이터\n",
    "additional_file_path = r\"D:\\시설\\정지\\일일정지\\고객리스트 정지시설 전체\\'24년12월 조건요약.cs\"  # 추가 데이터\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250212\\2025년0212_전사 정지조건리스트_완성.xlsx'\n",
    "output_cs_path = r'D:\\시설\\정지\\일일정지\\20250212\\2025년0212_전사 정지조건리스트_완성.cs'  # CSV 대신 CS 확장자로 저장\n",
    "\n",
    "try:\n",
    "    # 📌 기존 데이터 불러오기 (행 개수 유지)\n",
    "    df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "    original_row_count = df.shape[0]  # 원래 행 개수 저장 (예: 5884)\n",
    "\n",
    "    # 📌 필요한 컬럼만 추출\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '계약번호', '서비스(중)', '서비스(소)', '상호',\n",
    "        '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료', '계약시작일', '계약종료일',\n",
    "        '영업자명', '정지시작일자', '정지희망종료일', '계약최초서비스게시일',\n",
    "        '영업구역정보', 'kt oct 마스터 아이디', '외부고객KEY'\n",
    "    ]\n",
    "    df = df[columns_to_extract]\n",
    "\n",
    "    # 📌 추가 데이터 불러오기\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "    # 📌 중복 제거 (계약번호가 중복되면 첫 번째 값만 사용)\n",
    "    additional_df = additional_df.drop_duplicates(subset=['계약번호'])\n",
    "\n",
    "    # 📌 필요한 컬럼 선택 (계약번호 기준으로 매핑)\n",
    "    additional_columns = ['시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프']\n",
    "    additional_df = additional_df[['계약번호'] + additional_columns]\n",
    "\n",
    "    # 📌 추가 데이터 매핑 (병합이 아닌 기존 데이터에 조건 추가)\n",
    "    for col in additional_columns:\n",
    "        df[col] = df['계약번호'].map(additional_df.set_index('계약번호')[col])\n",
    "\n",
    "    # 📌 병합 후 행 개수 검증 (5884 유지)\n",
    "    assert df.shape[0] == original_row_count, \"매핑 후 행 개수가 변경되었습니다!\"\n",
    "\n",
    "    # 📌 날짜 변환 함수\n",
    "    def convert_date(date_str):\n",
    "        \"\"\"YYYYMMDD 또는 YYYYMMDDHHMMSS 형식을 YYYY-MM-DD로 변환\"\"\"\n",
    "        try:\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 📌 날짜 변환 적용할 필드 목록\n",
    "    date_columns = ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']\n",
    "    for col in date_columns:\n",
    "        df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    "    # 현재 날짜\n",
    "    today = datetime.today()\n",
    "\n",
    "    # 📌 종료희망일 초과 여부 추가\n",
    "    def check_exceeding_end_date(start_date, end_date):\n",
    "        \"\"\"현재 날짜를 기준으로 정지희망종료일 초과 여부 판단\"\"\"\n",
    "        try:\n",
    "            if pd.isna(start_date) or pd.isna(end_date):\n",
    "                return None\n",
    "            start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "            if end_date < today:\n",
    "                return '초과'\n",
    "            elif (today - start_date).days > 500:\n",
    "                return '확인대상'\n",
    "            else:\n",
    "                return '미초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['종료희망일 초과 여부'] = df.apply(\n",
    "        lambda row: check_exceeding_end_date(row['정지시작일자'], row['정지희망종료일']), axis=1\n",
    "    )\n",
    "\n",
    "    # 📌 새 열을 기존 데이터의 맨 왼쪽으로 이동\n",
    "    new_columns = additional_columns + ['종료희망일 초과 여부'] + columns_to_extract\n",
    "    df = df[new_columns]\n",
    "\n",
    "    # 📌 엑셀 파일로 저장\n",
    "    df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # 📌 엑셀 파일 열어서 새 열을 노란색 음영(50%) 적용\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "\n",
    "    # 새로 추가된 열에 노란색 음영 적용\n",
    "    for col_num in range(1, len(additional_columns) + 2):  # 추가된 열 개수만큼 적용\n",
    "        for row_num in range(1, ws.max_row + 1):\n",
    "            ws.cell(row=row_num, column=col_num).fill = yellow_fill\n",
    "\n",
    "    # 저장\n",
    "    wb.save(output_excel_path)\n",
    "\n",
    "    # 📌 CS 확장자로 CSV 저장\n",
    "    df.to_csv(output_cs_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(\"✅ 엑셀 및 CS 파일이 저장되었습니다 (5884행 유지, 추가 열 노란색 음영 적용):\")\n",
    "    print(f\" - 엑셀 파일: {output_excel_path}\")\n",
    "    print(f\" - CS 파일: {output_cs_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ec5ae0-f4cd-47c7-b1ca-bedee1d90c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 원본 데이터 행 개수: 5883\n",
      "📌 월정료 없음 / 제외사유 있음 데이터 행 개수: 1143\n",
      "📌 최종 정리된 데이터 행 개수: 4740\n",
      "📌 계약번호 기준 중복 제거 후 데이터 행 개수: 4729\n",
      "✅ 엑셀 파일 저장 완료! (새 열 노란색 음영 적용)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 📌 기존 결과 파일 경로\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_완성.xlsx'\n",
    "\n",
    "# 📌 필터링 후 저장할 새 파일 경로\n",
    "filtered_output_excel_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_월정료없음_제외사유있음.xlsx'\n",
    "updated_output_excel_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_최종.xlsx'\n",
    "unique_contract_output_path = r'D:\\시설\\정지\\일일정지\\20250209\\2025년0209_전사 정지조건리스트_중복제거.xlsx'\n",
    "\n",
    "# 📌 기존 결과 파일 불러오기\n",
    "df = pd.read_excel(output_excel_path, engine='openpyxl')\n",
    "\n",
    "# 📌 원본 데이터 행 개수 확인\n",
    "original_count = df.shape[0]\n",
    "print(f\"📌 원본 데이터 행 개수: {original_count}\")\n",
    "\n",
    "# 📌 KTT월정료가 비어 있거나 제외사유가 있는 행 필터링\n",
    "filtered_df = df[(df['KTT월정료'].isna()) | (df['제외사유'].notna())]\n",
    "\n",
    "# 📌 필터링된 데이터 별도 저장\n",
    "filtered_df.to_excel(filtered_output_excel_path, index=False, engine='openpyxl')\n",
    "filtered_count = filtered_df.shape[0]\n",
    "print(f\"📌 월정료 없음 / 제외사유 있음 데이터 행 개수: {filtered_count}\")\n",
    "\n",
    "# 📌 원본 데이터에서 해당 행 제거 후 업데이트\n",
    "df = df[(df['KTT월정료'].notna()) & (df['제외사유'].isna())]\n",
    "\n",
    "# 📌 최종 정리된 데이터 저장\n",
    "df.to_excel(updated_output_excel_path, index=False, engine='openpyxl')\n",
    "updated_count = df.shape[0]\n",
    "print(f\"📌 최종 정리된 데이터 행 개수: {updated_count}\")\n",
    "\n",
    "# 📌 데이터 개수 검증\n",
    "assert original_count == (filtered_count + updated_count), \"❌ 오류 발생: 행 개수가 일치하지 않습니다!\"\n",
    "\n",
    "# 📌 날짜 변환 함수\n",
    "def convert_date(date_str):\n",
    "    \"\"\"YYYYMMDD 또는 YYYYMMDDHHMMSS 형식을 YYYY-MM-DD로 변환\"\"\"\n",
    "    try:\n",
    "        if pd.isna(date_str) or not date_str.strip():\n",
    "            return None\n",
    "        date_str = str(date_str).strip()\n",
    "        if len(date_str) >= 8:\n",
    "            return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 📌 날짜 변환 적용\n",
    "date_columns = ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']\n",
    "for col in date_columns:\n",
    "    df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    "today = datetime.today()\n",
    "\n",
    "# 📌 정지일수 계산 함수\n",
    "def calculate_freeze_days(start_date, end_date):\n",
    "    try:\n",
    "        if not start_date or not end_date:\n",
    "            return None\n",
    "        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        freeze_days = (end_date - start_date).days + 1\n",
    "        return freeze_days if freeze_days > 0 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['정지일수'] = df.apply(lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일']), axis=1)\n",
    "\n",
    "# 📌 정지일수 구간 분류\n",
    "def categorize_freeze_days(days):\n",
    "    if pd.isna(days):\n",
    "        return None\n",
    "    elif days <= 89:\n",
    "        return '89일 이하'\n",
    "    elif 90 <= days <= 119:\n",
    "        return '90~119일'\n",
    "    elif 120 <= days <= 149:\n",
    "        return '120~149일'\n",
    "    else:\n",
    "        return '150일 이상'\n",
    "\n",
    "df['정지일수 구간'] = df['정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "# 📌 종료희망일 초과 여부 추가 (9999-12-31 포함)\n",
    "def check_exceeding_end_date(start_date, end_date):\n",
    "    try:\n",
    "        if not start_date or not end_date:\n",
    "            return None\n",
    "        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "        if end_date.strftime(\"%Y-%m-%d\") == \"9999-12-31\":\n",
    "            return '확인대상'\n",
    "        elif end_date < today:\n",
    "            return '초과'\n",
    "        elif (today - start_date).days > 500:\n",
    "            return '확인대상'\n",
    "        else:\n",
    "            return '미초과'\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['종료희망일 초과 여부'] = df.apply(\n",
    "    lambda row: check_exceeding_end_date(row['정지시작일자'], row['정지희망종료일']), axis=1\n",
    ")\n",
    "\n",
    "# 📌 KTT월정료 금액 구간 추가\n",
    "def categorize_fee(amount):\n",
    "    try:\n",
    "        amount = float(amount)\n",
    "        if amount <= 50000:\n",
    "            return '5만원 이하'\n",
    "        elif 50000 < amount <= 70000:\n",
    "            return '5만원 초과 ~ 7만원 이하'\n",
    "        elif 70000 < amount <= 100000:\n",
    "            return '7만원 초과 ~ 10만원 이하'\n",
    "        elif 100000 < amount <= 200000:\n",
    "            return '10만원 초과 ~ 20만원 이하'\n",
    "        else:\n",
    "            return '20만원 초과'\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['월정료 구간'] = df['KTT월정료'].apply(categorize_fee)\n",
    "\n",
    "# 📌 계약번호 기준 중복 제거 및 KTT월정료 합산\n",
    "df['KTT월정료'] = pd.to_numeric(df['KTT월정료'], errors='coerce').fillna(0)\n",
    "df_grouped = df.groupby('계약번호', as_index=False).agg(lambda x: x.iloc[0] if x.dtype == 'O' else x.sum())\n",
    "\n",
    "# 📌 중복 제거된 데이터 저장\n",
    "df_grouped.to_excel(unique_contract_output_path, index=False, engine='openpyxl')\n",
    "\n",
    "# 📌 중복 제거 후 행 개수 확인\n",
    "unique_count = df_grouped.shape[0]\n",
    "print(f\"📌 계약번호 기준 중복 제거 후 데이터 행 개수: {unique_count}\")\n",
    "\n",
    "# 📌 엑셀 파일 열어서 새 열을 노란색 음영(50%) 적용\n",
    "wb = load_workbook(unique_contract_output_path)\n",
    "ws = wb.active\n",
    "yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "\n",
    "# 📌 새로 생성된 열(조건 적용된 열)에만 노란색 음영 처리\n",
    "new_columns = ['정지일수', '정지일수 구간', '종료희망일 초과 여부', '월정료 구간']\n",
    "for col in new_columns:\n",
    "    col_index = df_grouped.columns.get_loc(col) + 1  # 엑셀에서는 1부터 시작\n",
    "    for row_num in range(2, ws.max_row + 1):  # 헤더 제외\n",
    "        ws.cell(row=row_num, column=col_index).fill = yellow_fill\n",
    "\n",
    "wb.save(unique_contract_output_path)\n",
    "\n",
    "print(f\"✅ 엑셀 파일 저장 완료! (새 열 노란색 음영 적용)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ce5bc-b6d8-449e-8be6-a08fafb9415c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e6de08-0e64-4ddc-9802-a33397b44d31",
   "metadata": {},
   "source": [
    "## 정지, 계약번호 중복시 월정료 높은것만 존재, 나머지 삭제, 일수, 구간별 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b0c78-e578-4a1d-a5fc-f0ebd98857de",
   "metadata": {},
   "source": [
    "# 조건 재정립 20250414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afbffd90-6b45-494e-a96b-5df292e8f787",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4ec99-ef3b-4ccc-91a9-0f7528d878a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58c423-dd85-490f-a89f-e73c7651e39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dea675-3cc9-4bc5-b2f5-37e9b102904a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eba90fe-72cb-4c93-aaf9-9cd2579d0fb5",
   "metadata": {},
   "source": [
    "## 정지코드 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c94e3a-26dd-4da4-97b1-e007ad797386",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3364359455.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 49\u001b[1;36m\u001b[0m\n\u001b[1;33m    df['관리본부명'] = df['관리본부명'].replace({\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250225\\C150_G0000_00049.csv'  \n",
    "additional_file_path = r\"D:\\시설\\유지\\2025\\2025.01월 유지전체변환.cs\"\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250225\\2025년0225_전사 정지조건리스트_완성.xlsx'\n",
    "output_cs_path = r'D:\\시설\\정지\\일일정지\\20250225\\2025년0225_전사 정지조건리스트_완성.cs'  \n",
    "\n",
    "try:\n",
    "    # 기존 데이터 불러오기 (행 개수 유지)\n",
    "    df = pd.read_csv(file_path, encoding='cp949', low_memory=False)\n",
    "    original_row_count = df.shape[0]  \n",
    "\n",
    "\n",
    "    # ✅ 2. 유지관리 데이터 불러오기 (설치주소 포함)\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "\n",
    "    # 필요한 컬럼만 추출\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '계약번호', '서비스(대)', '서비스(중)', '서비스(소)', '상호',\n",
    "        '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료', '계약시작일', '계약종료일',\n",
    "        '영업자명', '정지시작일자', '정지희망종료일', '담당자', '휴대폰', '계약최초서비스게시일',\n",
    "        '영업구역정보'\n",
    "    ]\n",
    "\n",
    "    # 'kt oct 마스터 아이디', '외부고객KEY', '무인매장구분', '무인매장업종구분'\n",
    "    \n",
    "    df = df[columns_to_extract]\n",
    "\n",
    "    # 추가 데이터 불러오기\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "    # 중복 제거 (계약번호가 중복되면 첫 번째 값만 사용)\n",
    "    additional_df = additional_df.drop_duplicates(subset=['계약번호'])\n",
    "\n",
    "  \n",
    "    # ✅ 3. 유지파일에서 필요한 컬럼 선택\n",
    "    columns_to_merge = ['계약번호', '설치주소', '청구번호', '시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프']\n",
    "    additional_df = additional_df[columns_to_merge].drop_duplicates(subset=['계약번호'])\n",
    "\n",
    "\n",
    "\n",
    "      # 📌 \"관리본부명\" 값 변경\n",
    "      df['관리본부명'] = df['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "      # ✅ 4. 유지자료에서 매핑 (설치주소 포함)\n",
    "      df = df.merge(additional_df, on='계약번호', how='left')\n",
    "\n",
    "      # ✅ 5. 제외사유 값이 존재하면 해당 행 전체 삭제\n",
    "      df = df[df['제외사유'].isna()]\n",
    "\n",
    "      # ✅ 6. 계약번호 중복 제거 (KTT월정료 합산 후 가장 높은 금액 유지)\n",
    "      df['KTT월정료'] = pd.to_numeric(df['KTT월정료'], errors='coerce').fillna(0)\n",
    "      df = df.sort_values(['계약번호', 'KTT월정료'], ascending=[True, False])\n",
    "      df = df.groupby('계약번호', as_index=False).agg(lambda x: x.iloc[0] if x.dtype == 'O' else x.sum())\n",
    "\n",
    "\n",
    "     # 기존 데이터 개수 유지하면서 계약번호 기준 매핑 (NaN 방지)\n",
    "    for col in additional_columns:\n",
    "        df[col] = df['계약번호'].map(additional_df.set_index('계약번호')[col]).fillna('')\n",
    "\n",
    "    # 병합 후 행 개수 검증 (5884 유지)\n",
    "    assert df.shape[0] == original_row_count, f\"오류 발생: 원본 행 개수({original_row_count})와 다름! 현재 행 개수: {df.shape[0]}\"\n",
    "\n",
    "    # 날짜 변환 함수\n",
    "    def convert_date(date_str):\n",
    "        \"\"\"YYYYMMDD 또는 YYYYMMDDHHMMSS 형식을 YYYY-MM-DD로 변환\"\"\"\n",
    "        try:\n",
    "            if pd.isna(date_str) or not date_str.strip():\n",
    "                return None\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # 날짜 변환 적용\n",
    "    date_columns = ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']\n",
    "    for col in date_columns:\n",
    "        df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    "    today = datetime.today()\n",
    "\n",
    "    # 정지일수 계산 함수\n",
    "    def calculate_freeze_days(start_date, end_date):\n",
    "        try:\n",
    "            if not start_date or not end_date:\n",
    "                return None\n",
    "            start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "            freeze_days = (end_date - start_date).days + 1\n",
    "            return freeze_days if freeze_days > 0 else 0\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['정지일수'] = df.apply(lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일']), axis=1)\n",
    "\n",
    "    # 정지일수 구간 분류\n",
    "    def categorize_freeze_days(days):\n",
    "        if pd.isna(days):\n",
    "            return None\n",
    "        elif days <= 89:\n",
    "            return '89일이하'\n",
    "        elif 90 <= days <= 119:\n",
    "            return '90~119일'\n",
    "        elif 120 <= days <= 149:\n",
    "            return '120~149일'\n",
    "        else:\n",
    "            return '150일이상'\n",
    "\n",
    "    df['정지일수 구간'] = df['정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # 종료희망일 초과 여부 추가 (9999-12-31 포함)\n",
    "    def check_exceeding_end_date(start_date, end_date):\n",
    "        try:\n",
    "            if not start_date or not end_date:\n",
    "                return None\n",
    "            start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "            if end_date.strftime(\"%Y-%m-%d\") == \"9999-12-31\":\n",
    "                return '확인대상'\n",
    "            elif end_date < today:\n",
    "                return '초과'\n",
    "            elif (today - start_date).days > 500:\n",
    "                return '확인대상'\n",
    "            else:\n",
    "                return '미초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['종료희망일 초과 여부'] = df.apply(\n",
    "        lambda row: check_exceeding_end_date(row['정지시작일자'], row['정지희망종료일']), axis=1\n",
    "    )\n",
    "\n",
    "    # KTT월정료 금액 구간 추가\n",
    "    def categorize_fee(amount):\n",
    "        try:\n",
    "            amount = float(amount)\n",
    "            if amount <= 50000:\n",
    "                return '5만원 이하'\n",
    "            elif 50000 < amount <= 70000:\n",
    "                return '5만원 초과 ~ 7만원 이하'\n",
    "            elif 70000 < amount <= 100000:\n",
    "                return '7만원 초과 ~ 10만원 이하'\n",
    "            elif 100000 < amount <= 200000:\n",
    "                return '10만원 초과 ~ 20만원 이하'\n",
    "            else:\n",
    "                return '20만원 초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['월정료 구간'] = df['KTT월정료'].apply(categorize_fee)\n",
    "\n",
    "    # 새 열을 기존 데이터의 맨 왼쪽으로 이동\n",
    "    new_columns = additional_columns + ['정지일수', '정지일수 구간', '종료희망일 초과 여부', '월정료 구간'] + columns_to_extract\n",
    "    df = df[new_columns]\n",
    "\n",
    "    df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # 엑셀 파일 열어서 새 열을 노란색 음영(50%) 적용\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "\n",
    "    for col_num in range(1, len(additional_columns) + 5):  # 모든 추가 열에 대해 적용\n",
    "        for row_num in range(1, ws.max_row + 1):\n",
    "            ws.cell(row=row_num, column=col_num).fill = yellow_fill\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    df.to_csv(output_cs_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(f\"엑셀 및 CS 파일 저장 완료 (5884행 유지, 추가 열 노란색 음영 적용)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232f11b-749d-4cf8-ae23-80f2cffeeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 2. 유지관리 데이터 불러오기 (설치주소 포함)\n",
    "additional_df = pd.read_csv(additional_file_path, encoding='cp949', low_memory=False)\n",
    "\n",
    "# ✅ 3. 유지파일에서 필요한 컬럼 선택\n",
    "columns_to_merge = ['계약번호', '설치주소', '청구번호', '시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프']\n",
    "additional_df = additional_df[columns_to_merge].drop_duplicates(subset=['계약번호'])\n",
    "\n",
    "# 📌 \"관리본부명\" 값 변경\n",
    "df['관리본부명'] = df['관리본부명'].replace({\n",
    "    '강원본부': '강북/강원본부',\n",
    "    '서부본부': '강남/서부본부'\n",
    "})\n",
    "\n",
    "# ✅ 4. 유지자료에서 매핑 (설치주소 포함)\n",
    "df = df.merge(additional_df, on='계약번호', how='left')\n",
    "\n",
    "# ✅ 5. 제외사유 값이 존재하면 해당 행 전체 삭제\n",
    "df = df[df['제외사유'].isna()]\n",
    "\n",
    "# ✅ 6. 계약번호 중복 제거 (KTT월정료 합산 후 가장 높은 금액 유지)\n",
    "df['KTT월정료'] = pd.to_numeric(df['KTT월정료'], errors='coerce').fillna(0)\n",
    "df = df.sort_values(['계약번호', 'KTT월정료'], ascending=[True, False])\n",
    "df = df.groupby('계약번호', as_index=False).agg(lambda x: x.iloc[0] if x.dtype == 'O' else x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222c5181-590f-4ad6-92fe-f2197a902032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\programdata\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tkinter (from versions: none)\n",
      "ERROR: No matching distribution found for tkinter\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl tkinter matplotlib chardet pandastable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef061d1f-aa45-429e-82e7-d204a5617225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandastable\n",
      "  Downloading pandastable-0.13.1.tar.gz (241 kB)\n",
      "     ---------------------------------------- 0.0/241.5 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 20.5/241.5 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 51.2/241.5 kB 871.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 241.5/241.5 kB 2.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandastable) (3.8.4)\n",
      "Requirement already satisfied: pandas>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandastable) (2.2.2)\n",
      "Requirement already satisfied: numexpr>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandastable) (2.8.7)\n",
      "Requirement already satisfied: xlrd>=0.9 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandastable) (2.0.1)\n",
      "Collecting future (from pandastable)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.5->pandastable) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.5->pandastable) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->pandastable) (1.16.0)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.3 kB ? eta -:--:--\n",
      "   --------------------------------------  481.3/491.3 kB 31.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 491.3/491.3 kB 7.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pandastable\n",
      "  Building wheel for pandastable (setup.py): started\n",
      "  Building wheel for pandastable (setup.py): finished with status 'done'\n",
      "  Created wheel for pandastable: filename=pandastable-0.13.1-py3-none-any.whl size=256892 sha256=363df94c873bd4a0993107d251c580a9559afdd586ac1c65505623d358b49672\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\9a\\83\\4d\\b38f2b068b023a5bd9cc5b95c19b6856a59147855616e2f38d\n",
      "Successfully built pandastable\n",
      "Installing collected packages: future, pandastable\n",
      "Successfully installed future-1.0.0 pandastable-0.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts futurize.exe and pasteurize.exe are installed in 'C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install pandastable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f872e-2181-4c1a-9585-1e9c50bfb9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3155c-cb90-4a2d-baaf-18c605407a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f729dbee-dcf8-49c4-aecc-622872112ba8",
   "metadata": {},
   "source": [
    "## ✅ **기능 개요**\n",
    "✔ **사용자가 직접 피벗 테이블의 행/열/값/필터 선택 가능**  \n",
    "✔ **한글 깨짐 없는 시각화 (Matplotlib, 한글 폰트 적용)**  \n",
    "✔ **CSV 및 Excel 저장 (인코딩: `949(EUC-KR)`)**  \n",
    " **다양한 집계 방식 지원 (SUM, COUNT, MEAN, MAX, MIN)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "545d0fdc-b641-445b-baf5-39242706a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['관리본부코드', '관리본부명', '관리지사코드', '관리지사명', '고객번호', '고객명', '계약번호', '유지보수기간',\n",
      "       '계약자명', '서비스번호',\n",
      "       ...\n",
      "       'kt oct 마스터 아이디', '정지희망종료일', '보조MIN번호', '영업지점', '설치지점', '팩토링여부',\n",
      "       '외부고객KEY', '무인매장구분', '무인매장업종구분', '팩토링상태'],\n",
      "      dtype='object', length=157)\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2182116a-b473-4183-bb7f-0c14e61947e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관리본부코드\n",
      "관리본부명\n",
      "관리지사코드\n",
      "관리지사명\n",
      "고객번호\n",
      "고객명\n",
      "계약번호\n",
      "유지보수기간\n",
      "계약자명\n",
      "서비스번호\n",
      "서비스(대)\n",
      "서비스(중)\n",
      "서비스(소)\n",
      "영상전환일\n",
      "상호\n",
      "고객구분\n",
      "사업용구분\n",
      "주민등록번호\n",
      "사업자번호\n",
      "계약상태(대)\n",
      "계약상태(중)\n",
      "서비스상태(대)\n",
      "서비스상태(중)\n",
      "접속전화번호\n",
      "설치우편번호\n",
      "설치주소\n",
      "견적월정료\n",
      "KTT월정료\n",
      "KT월정료\n",
      "할인율(%)\n",
      "계약개월수\n",
      "월정료 면제사유\n",
      "면제시작일\n",
      "면제종료일\n",
      "계약보증금\n",
      "보증금 면제사유\n",
      "판매상품비\n",
      "견적설치공사비\n",
      "설치공사할부개월\n",
      "계약공사비(ktt)\n",
      "계약공사비(kt)\n",
      "면제공사비\n",
      "실징수액\n",
      "계약시작일\n",
      "계약종료일\n",
      "영업구분\n",
      "추천구분\n",
      "추천경로\n",
      "영업본부코드\n",
      "영업본부명\n",
      "영업지사코드\n",
      "영업지사명\n",
      "영업자소속\n",
      "영업자사번\n",
      "영업자명\n",
      "영업자연락처\n",
      "모집유형\n",
      "가망고객번호\n",
      "추천본부코드\n",
      "추천본부명\n",
      "추천지사코드\n",
      "추천지사명\n",
      "유통망대분류\n",
      "유통망중분류\n",
      "유통망소분류\n",
      "추천자사번\n",
      "추천자명\n",
      "추천자유형\n",
      "정보제공자부서\n",
      "정보제공자사번\n",
      "정보제공자명\n",
      "정보제공자연락처\n",
      "청구본부코드\n",
      "청구본부명\n",
      "청구지사코드\n",
      "청구지사명\n",
      "청구자명\n",
      "합산여부\n",
      "수납구분\n",
      "세금계산서발행여부\n",
      "계산서발행여부\n",
      "선후납구분\n",
      "청구번호\n",
      "청구전화번호\n",
      "청구우편번호\n",
      "청구주소\n",
      "청약일자\n",
      "청약취소일자\n",
      "공사희망일\n",
      "공사예정일\n",
      "공사완료일\n",
      "준공완료일\n",
      "관제개통일\n",
      "서비스개시일\n",
      "서비스재개시일\n",
      "공사의뢰유형\n",
      "회선방식(대)\n",
      "회선방식(중)\n",
      "MUX / SYSTEM_ID\n",
      "전용회선번호\n",
      "MIN번호\n",
      "정지시작일자\n",
      "해지일자\n",
      "종목\n",
      "업태\n",
      "업종(대)\n",
      "업종(중)\n",
      "보험등급\n",
      "비고\n",
      "결합구분\n",
      "결합상품명\n",
      "결합약정개월수\n",
      "결합시작일\n",
      "금융기관코드\n",
      "면책구분\n",
      "타사전환\n",
      "이전고객번호\n",
      "E-MAIL\n",
      "담당자\n",
      "휴대폰\n",
      "전입신규여부\n",
      "고객추가정보\n",
      "계약최초서비스게시일\n",
      "청약취소사유\n",
      "계약본부\n",
      "계약지사\n",
      "매출본사\n",
      "출동구역정보\n",
      "영업구역정보\n",
      "구역담당지점\n",
      "구역담당영업사원\n",
      "선장품\n",
      "브랜드\n",
      "보조회선\n",
      "고객계약유형\n",
      "A/S운용기간\n",
      "판매할부개월\n",
      "월정료일시납\n",
      "장기요금인상여부\n",
      "장기요금인상액\n",
      "장기Upselling여부\n",
      "장기Upselling매출액\n",
      "기술구역정보\n",
      "계약서작성주체\n",
      "카드사명\n",
      "GiGAeyes계약Id\n",
      "월정료\n",
      "kt oct 마스터 아이디\n",
      "정지희망종료일\n",
      "보조MIN번호\n",
      "영업지점\n",
      "설치지점\n",
      "팩토링여부\n",
      "외부고객KEY\n",
      "무인매장구분\n",
      "무인매장업종구분\n",
      "팩토링상태\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1223dbd0-aa3b-46eb-85e2-aab8e76ff6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  관리본부코드    관리본부명 관리지사코드  관리지사명      고객번호        고객명      계약번호  유지보수기간  \\\n",
      "0   O000  전남/전북본부   O510   제주지사  30736522        추*탁  51497532     NaN   \n",
      "1   O000  전남/전북본부   O420   익산지사  30803933        강*숙  51619691     NaN   \n",
      "2   J000     서부본부   J050   관악지사  30822965         반*  51651888     NaN   \n",
      "3   M000  대구/경북본부   M320  서대구지사  30897415  이**뜸길협동조합  51791664     NaN   \n",
      "4   M000  대구/경북본부   M320  서대구지사  30897415  이**뜸길협동조합  51791664     NaN   \n",
      "\n",
      "        계약자명     서비스번호 서비스(대) 서비스(중)                   서비스(소)  영상전환일  \\\n",
      "0        추*탁  62004450  기본서비스  텔레캅아이  ktt GiGAeyes view+(DVR)    NaN   \n",
      "1        강*숙  62263339  기본서비스  텔레캅아이          GiGAeyes i-slim    NaN   \n",
      "2         반*  62333727  기본서비스  텔레캅아이    GiGAeyes i-slim(2210)    NaN   \n",
      "3  이**뜸길협동조합  62625535  기본서비스  텔레캅아이     GiGAeyes guard+(DVR)    NaN   \n",
      "4  이**뜸길협동조합  62625536  기본서비스  텔레캅아이     GiGAeyes guard+(DVR)    NaN   \n",
      "\n",
      "                          상호       고객구분 사업용구분          주민등록번호         사업자번호  \\\n",
      "0                     추형탁님주택         개인  비사업용  800819-*******  2.979402e+09   \n",
      "1                        강문숙         개인  비사업용  730315-*******           NaN   \n",
      "2                         반슈      개인사업자  비사업용  820303-*******  3.152417e+09   \n",
      "3  이곡으뜸길협동조합(GiGAeyes guard)  기타재단법인/협회  비사업용             NaN  1.838703e+09   \n",
      "4  이곡으뜸길협동조합(GiGAeyes guard)  기타재단법인/협회  비사업용             NaN  1.838703e+09   \n",
      "\n",
      "  계약상태(대) 계약상태(중) 서비스상태(대) 서비스상태(중)         접속전화번호  설치우편번호  \\\n",
      "0      정지    일시정지       정지     일시정지  064-70**-**00  695920   \n",
      "1      정지    일시정지       정지     일시정지   02-12**-**34  579852   \n",
      "2      정지    일시정지       정지     일시정지   02-12**-**34  150714   \n",
      "3      정지    일시정지       정지     일시정지  053-12**-**34  704786   \n",
      "4      정지    일시정지       정지     일시정지  053-12**-**34  704786   \n",
      "\n",
      "                    설치주소     견적월정료   KTT월정료  KT월정료  할인율(%)  계약개월수 월정료 면제사유  \\\n",
      "0    제주 제주시 한림읍 ********   65260.0  30000.0    NaN     NaN     12      NaN   \n",
      "1    전북 부안군 변산면 ********   17000.0  17000.0    0.0     NaN     36      NaN   \n",
      "2  서울 영등포구 여의도동 ********   27000.0  27000.0    0.0     NaN     36      NaN   \n",
      "3    대구 달서구 이곡동 ********  124200.0  45000.0    NaN     NaN     36      NaN   \n",
      "4    대구 달서구 이곡동 ********       0.0      NaN    NaN     NaN     36      NaN   \n",
      "\n",
      "   면제시작일  면제종료일  계약보증금 보증금 면제사유   판매상품비   견적설치공사비  설치공사할부개월  계약공사비(ktt)  \\\n",
      "0    NaN    NaN    NaN      NaN     NaN  198441.0       NaN    200000.0   \n",
      "1    NaN    NaN    NaN      NaN     NaN  100000.0       NaN         NaN   \n",
      "2    NaN    NaN    NaN      NaN     NaN  160000.0       NaN         NaN   \n",
      "3    NaN    NaN    NaN      NaN     NaN  221431.0       NaN    250000.0   \n",
      "4    NaN    NaN    NaN      NaN  6000.0       0.0       NaN         NaN   \n",
      "\n",
      "   계약공사비(kt)     면제공사비  실징수액     계약시작일     계약종료일  영업구분 추천구분 추천경로 영업본부코드  \\\n",
      "0        NaN  200000.0   NaN  20241201  20251130  추천영업  내부망  NaN   O000   \n",
      "1        NaN       NaN   NaN  20220603  20250913  추천영업  외부망  NaN   O000   \n",
      "2        NaN       NaN   NaN  20220808  20250927  추천영업  외부망  NaN   J000   \n",
      "3        NaN  250000.0   NaN  20230426  20260425  직접영업  내부망  NaN   M000   \n",
      "4        NaN       NaN   NaN  20230426  20260425  직접영업  내부망  NaN   M000   \n",
      "\n",
      "     영업본부명 영업지사코드  영업지사명  영업자소속    영업자사번    영업자명        영업자연락처   모집유형  \\\n",
      "0  전남/전북본부   O510   제주지사   제주지사    05265     신건희           NaN  영업직사원   \n",
      "1  전남/전북본부   O420   익산지사     본사  iview01  추천자와동일           NaN    NaN   \n",
      "2     서부본부   J050   관악지사     본사  iview01  추천자와동일           NaN    NaN   \n",
      "3  대구/경북본부   M320  서대구지사  서대구지사    03306     정동화  1.038188e+09  영업직사원   \n",
      "4  대구/경북본부   M320  서대구지사  서대구지사    03306     정동화  1.038188e+09  영업직사원   \n",
      "\n",
      "     가망고객번호 추천본부코드    추천본부명 추천지사코드  추천지사명   유통망대분류   유통망중분류   유통망소분류  \\\n",
      "0  31427091   O000  전남/전북본부   O510   제주지사      NaN      NaN      NaN   \n",
      "1  31532230   1000       본사   V020  채널운영팀  kt사외유통망  kt사외유통망  kt사외유통망   \n",
      "2  31559738   1000       본사   V020  채널운영팀  kt사외유통망  kt사외유통망  kt사외유통망   \n",
      "3  31679807   M000  대구/경북본부   M320  서대구지사      NaN      NaN      NaN   \n",
      "4  31679807   M000  대구/경북본부   M320  서대구지사      NaN      NaN      NaN   \n",
      "\n",
      "      추천자사번 추천자명  추천자유형 정보제공자부서  정보제공자사번 정보제공자명  정보제공자연락처 청구본부코드    청구본부명  \\\n",
      "0     07535  정승원  텔레캅사원     NaN      NaN    NaN       NaN   O000  전남/전북본부   \n",
      "1  D2031354  김진욱  KT사외망     NaN      NaN    NaN      10.0   O000  전남/전북본부   \n",
      "2  D2030912  김상현  KT사외망     NaN      NaN    NaN      10.0   J000     서부본부   \n",
      "3     03306  정동화  텔레캅사원     NaN      NaN    NaN       NaN   M000  대구/경북본부   \n",
      "4     03306  정동화  텔레캅사원     NaN      NaN    NaN       NaN   M000  대구/경북본부   \n",
      "\n",
      "  청구지사코드  청구지사명       청구자명 합산여부     수납구분 세금계산서발행여부 계산서발행여부 선후납구분      청구번호  \\\n",
      "0   O510   제주지사        추*탁   개별    CMS청구        효성      발행   당월납  41617487   \n",
      "1   O420   익산지사        강*숙   개별  KT인터넷청구     효성모바일      발행    후납  41748708   \n",
      "2   J050   관악지사         반*   개별  KT인터넷청구     효성모바일      발행    후납  41783416   \n",
      "3   M320  서대구지사  이**뜸길협동조합   개별    CMS청구        효성      발행   당월납  41934738   \n",
      "4   M320  서대구지사  이**뜸길협동조합   개별    CMS청구        효성      발행   당월납  41934738   \n",
      "\n",
      "          청구전화번호  청구우편번호                   청구주소        청약일자  청약취소일자  \\\n",
      "0  064-70**-**00  695920    제주 제주시 한림읍 ********  20211021.0     NaN   \n",
      "1   02-12**-**34  579852    전북 부안군 변산면 ********  20220530.0     NaN   \n",
      "2   02-12**-**34  150714  서울 영등포구 여의도동 ********  20220725.0     NaN   \n",
      "3  053-12**-**34  704786    대구 달서구 이곡동 ********  20230424.0     NaN   \n",
      "4  053-12**-**34  704786    대구 달서구 이곡동 ********  20230424.0     NaN   \n",
      "\n",
      "        공사희망일       공사예정일       공사완료일       준공완료일       관제개통일      서비스개시일  \\\n",
      "0  20211026.0  20211026.0  20211026.0  20211026.0         NaN  20211026.0   \n",
      "1  20220601.0  20220603.0  20220603.0  20220603.0         NaN  20220603.0   \n",
      "2  20220805.0  20220804.0  20220808.0  20220808.0         NaN  20220808.0   \n",
      "3  20230424.0  20230425.0  20230425.0  20230426.0  20230426.0  20230426.0   \n",
      "4  20230424.0  20230425.0  20230425.0  20230426.0  20230426.0  20230426.0   \n",
      "\n",
      "      서비스재개시일 공사의뢰유형 회선방식(대)          회선방식(중) MUX / SYSTEM_ID  전용회선번호 MIN번호  \\\n",
      "0  20241201.0   신규설치     무회선             로컬운영        58340500     NaN   NaN   \n",
      "1  20220603.0   신규설치  초고속인터넷  TCP-IP(All-IoT)        52267900     NaN   NaN   \n",
      "2  20220808.0   신규설치  초고속인터넷  TCP-IP(All-IoT)        23526300     NaN   NaN   \n",
      "3  20230426.0   신규설치  초고속인터넷  TCP-IP(All-IoT)        44464700     NaN   NaN   \n",
      "4  20230426.0   신규설치  초고속인터넷  TCP-IP(All-IoT)        44464701     NaN   NaN   \n",
      "\n",
      "     정지시작일자  해지일자       종목     업태 업종(대)            업종(중)  보험등급  \\\n",
      "0  20250201   NaN      NaN    가정집    주택          단독/전원주택   무보험   \n",
      "1  20240920   NaN  NOTHING   주택관리    주택          단독/전원주택   무보험   \n",
      "2  20240912   NaN  NOTHING   음식점업   사무실              사무실   무보험   \n",
      "3  20250101   NaN    농수축산물  도/소매업  도소매점  농수산/축산물(정육점등)상점  안심형A   \n",
      "4  20250101   NaN    농수축산물  도/소매업  도소매점  농수산/축산물(정육점등)상점  안심형A   \n",
      "\n",
      "                        비고 결합구분        결합상품명  결합약정개월수       결합시작일  \\\n",
      "0            25년 1월 체납직권정지   결합  쿡인터넷_텔레캅 결합      0.0  20211026.0   \n",
      "1  kt biznaru 직권정지(인터넷-kt)  미결합          NaN      NaN         NaN   \n",
      "2   kt biznaru 직권정지(체납-kt)  미결합          NaN      NaN         NaN   \n",
      "3            25년 1월 체납직권정지  미결합          미결합      0.0         NaN   \n",
      "4            25년 1월 체납직권정지  미결합          미결합      0.0         NaN   \n",
      "\n",
      "        금융기관코드 면책구분 타사전환  이전고객번호              E-MAIL  담당자            휴대폰  \\\n",
      "0  쿡인터넷_텔레캅 결합  NaN  NaN     NaN         ㅇ@naver.com  NaN  010-2693-8704   \n",
      "1          NaN  NaN  NaN     NaN      2400@naver.com  NaN  010-3472-2400   \n",
      "2          NaN  NaN  NaN     NaN  happyroh@gmail.com  NaN  010-3012-1344   \n",
      "3          미결합  NaN  NaN     NaN    sul5171@daum.net  NaN  010-3803-5171   \n",
      "4          미결합  NaN  NaN     NaN    sul5171@daum.net  NaN  010-3803-5171   \n",
      "\n",
      "  전입신규여부 고객추가정보      계약최초서비스게시일  청약취소사유     계약본부   계약지사   매출본사   출동구역정보  \\\n",
      "0   일반신규    NaN  20211026000000     NaN  전남/전북본부   제주지사  마케팅본부  O000602   \n",
      "1   일반신규    NaN  20220603000000     NaN  전남/전북본부   익산지사  마케팅본부  O000306   \n",
      "2   일반신규    NaN  20220808000000     NaN     서부본부   관악지사  마케팅본부  J000602   \n",
      "3   일반신규    NaN  20230426000000     NaN  대구/경북본부  서대구지사  마케팅본부  M000108   \n",
      "4   일반신규    NaN  20230426000000     NaN  대구/경북본부  서대구지사  마케팅본부  M000108   \n",
      "\n",
      "    영업구역정보 구역담당지점 구역담당영업사원   선장품    브랜드 보조회선 고객계약유형  A/S운용기간  판매할부개월 월정료일시납  \\\n",
      "0  O000602    NaN      임재민  해당없음  텔레캅아이  NaN   개별계약      NaN     NaN    NaN   \n",
      "1  O000306    NaN      NaN  해당없음    텔레캅  NaN   개별계약      NaN     NaN    NaN   \n",
      "2  J000602    NaN      NaN  해당없음    텔레캅  NaN   개별계약      NaN     NaN    NaN   \n",
      "3  M000108    NaN      NaN  해당없음  텔레캅아이  NaN   개별계약      NaN     NaN    NaN   \n",
      "4  M000108    NaN      NaN  해당없음  텔레캅아이  NaN   개별계약      NaN     NaN    NaN   \n",
      "\n",
      "   장기요금인상여부  장기요금인상액 장기Upselling여부  장기Upselling매출액   기술구역정보 계약서작성주체  카드사명  \\\n",
      "0       NaN      NaN           NaN             NaN  O510602     NaN  현대카드   \n",
      "1       NaN      NaN           NaN             NaN  O420003     NaN   NaN   \n",
      "2       NaN      NaN           NaN             NaN  J050001     NaN   NaN   \n",
      "3       NaN      NaN           NaN             NaN  M320104     NaN   NaN   \n",
      "4       NaN      NaN           NaN             NaN  M320104     NaN   NaN   \n",
      "\n",
      "     GiGAeyes계약Id      월정료  kt oct 마스터 아이디     정지희망종료일 보조MIN번호  영업지점  설치지점  \\\n",
      "0             NaN      NaN    2.021102e+12  20250331.0     NaN   NaN   NaN   \n",
      "1  bn!S0039499250  17000.0    2.022053e+12  99991231.0     NaN   NaN   NaN   \n",
      "2  bn!S0040085070  27000.0    2.022073e+12  99991231.0     NaN   NaN   NaN   \n",
      "3             NaN      NaN    2.023042e+12  20250228.0     NaN   NaN   NaN   \n",
      "4             NaN      NaN    2.023042e+12  20250228.0     NaN   NaN   NaN   \n",
      "\n",
      "  팩토링여부  외부고객KEY 무인매장구분 무인매장업종구분  팩토링상태  \n",
      "0    미정      NaN    NaN      NaN    NaN  \n",
      "1    미정      NaN    NaN      NaN    NaN  \n",
      "2    미정      NaN    NaN      NaN    NaN  \n",
      "3    미정      NaN   유인매장      NaN    NaN  \n",
      "4    미정      NaN   유인매장      NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(data.head()) # 데이터 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46a1fc-0a3c-4fd7-81dd-e459ec4206bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade gspread gspread_dataframe oauth2client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c85e95-79af-472a-9c4c-30a137718057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845d335-5436-409e-a8ab-8f4b4f2cbc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fe922e8-be32-40d1-aa4b-cba85d2e06c7",
   "metadata": {},
   "source": [
    "## 정지 개선작업2_20250414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54880aa6-80cf-4255-8c35-5946cba628d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Google Drive 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ✅ 인증 키 경로 설정\n",
    "json_keyfile_path = \"/content/drive/MyDrive/Key/credentials.json\"\n",
    "\n",
    "# ✅ 인증 및 gspread 연결\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from gspread_dataframe import get_as_dataframe\n",
    "\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "# ✅ 스프레드시트 열기\n",
    "spreadsheet = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/13hT-Ea5-P5Vi-37d1dZp2ev_Mi3QUQ5Rh9XT33sqxhA/edit\")\n",
    "worksheet = spreadsheet.worksheet(\"DB_04.03\")\n",
    "\n",
    "# ✅ 데이터 가져오기\n",
    "sheet_df = get_as_dataframe(worksheet).dropna(subset=['계약번호'])\n",
    "mapping_df = sheet_df[['계약번호', 'L/i형구분', '체납구분1', '체납구분2']].dropna()\n",
    "\n",
    "# ✅ 기존 df에 병합\n",
    "df['L/i형구분'] = df['계약번호'].map(mapping_df.set_index('계약번호')['L/i형구분']).fillna('')\n",
    "df['체납구분1'] = df['계약번호'].map(mapping_df.set_index('계약번호')['체납구분1']).fillna('')\n",
    "df['체납구분2'] = df['계약번호'].map(mapping_df.set_index('계약번호')['체납구분2']).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d02b3-090c-47d0-bc6b-c12652d8fe06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56832545-5e1b-4c16-8063-6f842412d06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85930c9-91cf-4969-a8cc-f4f620dae8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ed94aa-d9cc-49c5-aae3-c911cdffb148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 오류 발생: 'cp949' codec can't decode byte 0xab in position 12: illegal multibyte sequence\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import chardet\n",
    "\n",
    "# ✅ 인코딩 감지 함수\n",
    "def detect_encoding(file_path, max_bytes=100000):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        sample = f.read(max_bytes)\n",
    "        result = chardet.detect(sample)\n",
    "        encoding = result['encoding']\n",
    "        if encoding and 'euc' in encoding.lower():\n",
    "            encoding = 'cp949'\n",
    "        return encoding or 'cp949'\n",
    "\n",
    "# ✅ 파일 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250425\\C155_03104_00045.csv'\n",
    "additional_file_path = r\"D:\\시설\\유지\\2025\\3월\\3월마감 조건추출 선택컬럼_2403.csv\"\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250425\\2025년0425_전사 정지조건리스트_완성_서비스번호.xlsx'\n",
    "output_csv_path = r'D:\\시설\\정지\\일일정지\\20250425\\2025년0425_전사 정지조건리스트_완성_서비스번호.csv'\n",
    "\n",
    "try:\n",
    "    # ✅ 데이터 불러오기\n",
    "    df = pd.read_csv(file_path, encoding=detect_encoding(file_path), low_memory=False)\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding=detect_encoding(additional_file_path), low_memory=False)\n",
    "\n",
    "    # ✅ 주요 컬럼 필터링\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '고객번호', '계약번호', '서비스번호', '서비스(대)', '서비스(중)', '서비스(소)',\n",
    "        '상호', '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료(조정)', 'KTT월정료',\n",
    "        '계약시작일', '계약종료일', '영업자명', '정지시작일자', '정지희망종료일', '계약최초서비스게시일', '영업구역정보'\n",
    "    ]\n",
    "    df = df[[col for col in columns_to_extract if col in df.columns]]\n",
    "    df = df[(df['서비스(대)'] == '기본서비스') & (df['사업용구분'] != '사업용')]\n",
    "\n",
    "    # ✅ 본부명 정제\n",
    "    df['관리본부명'] = df['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "    # ✅ 추가 컬럼 병합\n",
    "    additional_columns = ['시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프', '설치주소']\n",
    "    additional_df = additional_df.drop_duplicates(subset=['계약번호'])\n",
    "    additional_df = additional_df[['계약번호'] + [col for col in additional_columns if col in additional_df.columns]]\n",
    "\n",
    "    for col in additional_columns:\n",
    "        df[col] = df['계약번호'].map(additional_df.set_index('계약번호')[col]).fillna('')\n",
    "\n",
    "    # ✅ 제외사유 제거\n",
    "    if '제외사유' in df.columns:\n",
    "        df['제외사유'] = df['제외사유'].astype(str).str.strip()\n",
    "        df = df[df['제외사유'] == '']\n",
    "\n",
    "    # ✅ KTT월정료 통일: 'KTT월정료(조정)' → 'KTT월정료' 우선 적용\n",
    "    if 'KTT월정료(조정)' in df.columns:\n",
    "        df['KTT월정료'] = df['KTT월정료(조정)']\n",
    "    elif 'KTT월정료' not in df.columns:\n",
    "        df['KTT월정료'] = ''  # 없는 경우 빈 컬럼 생성\n",
    "\n",
    "    # ✅ 날짜 포맷 정제 함수\n",
    "    def convert_date(date_str):\n",
    "        try:\n",
    "            if pd.isna(date_str) or not str(date_str).strip():\n",
    "                return None\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    for col in ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    "    # ✅ 종료희망일 보정\n",
    "    today = datetime.today()\n",
    "    last_day = datetime(today.year, today.month, calendar.monthrange(today.year, today.month)[1])\n",
    "    last_day_str = last_day.strftime(\"%Y-%m-%d\")\n",
    "    df['정지희망종료일'] = df['정지희망종료일'].apply(\n",
    "        lambda x: last_day_str if not x or x == '9999-12-31' else x\n",
    "    )\n",
    "\n",
    "    # ✅ 종료희망일 초과 여부\n",
    "    def check_exceeding(row):\n",
    "        try:\n",
    "            end_date = datetime.strptime(row['정지희망종료일'], '%Y-%m-%d')\n",
    "            return '초과' if end_date <= last_day else '미초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['종료희망일 초과 여부'] = df.apply(check_exceeding, axis=1)\n",
    "\n",
    "    # ✅ 정지일수 계산\n",
    "    def calculate_freeze_days(start, end):\n",
    "        try:\n",
    "            if not start or not end:\n",
    "                return None\n",
    "            start = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "            end = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "            return max((end - start).days + 1, 0)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['정지일수'] = df.apply(lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일']), axis=1)\n",
    "\n",
    "    # ✅ 정지일수 구간\n",
    "    def categorize_freeze_days(days):\n",
    "        if pd.isna(days): return None\n",
    "        elif days <= 89: return '89일이하'\n",
    "        elif days <= 119: return '90~119일'\n",
    "        elif days <= 149: return '120~149일'\n",
    "        else: return '150일이상'\n",
    "\n",
    "    df['정지일수 구간'] = df['정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # ✅ 월정료 구간 분류\n",
    "    def categorize_fee(val):\n",
    "        try:\n",
    "            amount = float(str(val).replace(',', ''))\n",
    "            if amount <= 50000:\n",
    "                return '5만 이하'\n",
    "            elif amount <= 70000:\n",
    "                return '5만 ~ 7만 이하'\n",
    "            elif amount <= 100000:\n",
    "                return '7만 ~ 10만 이하'\n",
    "            elif amount <= 200000:\n",
    "                return '10만 ~ 20만 이하'\n",
    "            elif amount <= 500000:\n",
    "                return '20만 ~ 50만 이하'\n",
    "            else:\n",
    "                return '50만 초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['월정료 구간'] = df['KTT월정료'].apply(categorize_fee)\n",
    "\n",
    "    # ✅ 컬럼 순서 정리\n",
    "    final_columns = additional_columns + ['정지일수', '정지일수 구간', '종료희망일 초과 여부', '월정료 구간'] + columns_to_extract\n",
    "    df = df[[col for col in final_columns if col in df.columns]]\n",
    "\n",
    "    # ✅ 엑셀 저장\n",
    "    df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # ✅ 노란색 강조 처리\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "    for col in range(1, len(additional_columns) + 5):\n",
    "        for row in range(2, ws.max_row + 1):\n",
    "            ws.cell(row=row, column=col).fill = yellow_fill\n",
    "    wb.save(output_excel_path)\n",
    "\n",
    "    # ✅ CSV 저장 (한글 호환용)\n",
    "    df.to_csv(output_csv_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(f\"✅ 최종 저장 완료! (행 수: {df.shape[0]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ 오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ebf70-026a-4824-9d5a-4261eb6c3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##중복제거0425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99e88333-7c98-4a4a-9a4c-8fbdae3acfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 최종 저장 완료! 행 수: 5170\n",
      "📄 엑셀 저장 경로: D:\\시설\\정지\\일일정지\\20250425\\2025년0425_전사 정지조건리스트_완성_중복제거0425.xlsx\n",
      "📄 CSV 저장 경로: D:\\시설\\정지\\일일정지\\20250425\\2025년0425_전사 정지조건리스트_완성_중복제거0425.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import chardet\n",
    "import os\n",
    "\n",
    "# ✅ 인코딩 감지 함수\n",
    "def detect_encoding(file_path, max_bytes=100000):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        sample = f.read(max_bytes)\n",
    "        result = chardet.detect(sample)\n",
    "        encoding = result['encoding']\n",
    "        if encoding and 'euc' in encoding.lower():\n",
    "            encoding = 'cp949'\n",
    "        return encoding or 'cp949'\n",
    "\n",
    "# ✅ 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250425\\C155_03104_00045.csv'\n",
    "additional_file_path = r\"D:\\시설\\유지\\2025\\3월\\3월마감 조건추출 선택컬럼_2403.csv\"\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250425\\2025년0425_전사 정지조건리스트_완성_중복제거0425.xlsx'\n",
    "output_csv_path = r'D:\\시설\\정지\\일일정지\\20250425\\2025년0425_전사 정지조건리스트_완성_중복제거0425.csv'\n",
    "\n",
    "try:\n",
    "    # ✅ CSV 로드\n",
    "    df = pd.read_csv(file_path, encoding=detect_encoding(file_path), low_memory=False)\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding=detect_encoding(additional_file_path), low_memory=False)\n",
    "\n",
    "    # ✅ 주요 컬럼 필터링\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '고객번호', '계약번호', '서비스번호', '서비스(대)', '서비스(중)', '서비스(소)',\n",
    "        '상호', '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료(조정)', 'KTT월정료',\n",
    "        '계약시작일', '계약종료일', '영업자명', '정지시작일자', '정지희망종료일', '계약최초서비스게시일', '영업구역정보'\n",
    "    ]\n",
    "    df = df[[col for col in columns_to_extract if col in df.columns]]\n",
    "    df = df[(df['서비스(대)'] == '기본서비스') & (df['사업용구분'] != '사업용')]\n",
    "\n",
    "    # ✅ 본부명 정제\n",
    "    df['관리본부명'] = df['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "    # ✅ 추가 컬럼 병합\n",
    "    additional_columns = ['시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프', '설치주소']\n",
    "    additional_df = additional_df.drop_duplicates(subset=['계약번호'])\n",
    "    additional_df = additional_df[['계약번호'] + [col for col in additional_columns if col in additional_df.columns]]\n",
    "\n",
    "    for col in additional_columns:\n",
    "        df[col] = df['계약번호'].map(additional_df.set_index('계약번호')[col]).fillna('')\n",
    "\n",
    "    # ✅ 제외사유 제거\n",
    "    if '제외사유' in df.columns:\n",
    "        df['제외사유'] = df['제외사유'].astype(str).str.strip()\n",
    "        df = df[df['제외사유'] == '']\n",
    "\n",
    "    # ✅ KTT월정료 통일\n",
    "    if 'KTT월정료(조정)' in df.columns:\n",
    "        df['KTT월정료'] = df['KTT월정료(조정)']\n",
    "    elif 'KTT월정료' not in df.columns:\n",
    "        df['KTT월정료'] = ''\n",
    "\n",
    "    df['KTT월정료'] = pd.to_numeric(df['KTT월정료'], errors='coerce').fillna(0)\n",
    "\n",
    "    # ✅ 날짜 포맷 정제 함수\n",
    "    def convert_date(date_str):\n",
    "        try:\n",
    "            if pd.isna(date_str) or not str(date_str).strip():\n",
    "                return None\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    for col in ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    "    # ✅ 종료희망일 보정\n",
    "    today = datetime.today()\n",
    "    last_day = datetime(today.year, today.month, calendar.monthrange(today.year, today.month)[1])\n",
    "    last_day_str = last_day.strftime(\"%Y-%m-%d\")\n",
    "    df['정지희망종료일'] = df['정지희망종료일'].apply(\n",
    "        lambda x: last_day_str if not x or x == '9999-12-31' else x\n",
    "    )\n",
    "\n",
    "    # ✅ 종료희망일 초과 여부\n",
    "    def check_exceeding(row):\n",
    "        try:\n",
    "            end_date = datetime.strptime(row['정지희망종료일'], '%Y-%m-%d')\n",
    "            return '초과' if end_date <= last_day else '미초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['종료희망일 초과 여부'] = df.apply(check_exceeding, axis=1)\n",
    "\n",
    "    # ✅ 정지일수 계산\n",
    "    def calculate_freeze_days(start, end):\n",
    "        try:\n",
    "            if not start or not end:\n",
    "                return None\n",
    "            start = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "            end = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "            return max((end - start).days + 1, 0)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['정지일수'] = df.apply(lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일']), axis=1)\n",
    "\n",
    "    # ✅ 정지일수 구간\n",
    "    def categorize_freeze_days(days):\n",
    "        if pd.isna(days): return None\n",
    "        elif days <= 89: return '89일이하'\n",
    "        elif days <= 119: return '90~119일'\n",
    "        elif days <= 149: return '120~149일'\n",
    "        else: return '150일이상'\n",
    "\n",
    "    df['정지일수 구간'] = df['정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # ✅ 월정료 구간 분류\n",
    "    def categorize_fee(val):\n",
    "        try:\n",
    "            amount = float(str(val).replace(',', ''))\n",
    "            if amount <= 50000:\n",
    "                return '5만원 이하'\n",
    "            elif amount <= 70000:\n",
    "                return '5만원 초과 ~ 7만원 이하'\n",
    "            elif amount <= 100000:\n",
    "                return '7만원 초과 ~ 10만원 이하'\n",
    "            elif amount <= 200000:\n",
    "                return '10만원 초과 ~ 20만원 이하'\n",
    "            else:\n",
    "                return '20만원 초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['월정료 구간'] = df['KTT월정료'].apply(categorize_fee)\n",
    "\n",
    "    # ✅ 계약번호 기준 중복 제거 + KTT월정료 합산\n",
    "    df = df.groupby('계약번호', as_index=False).agg({\n",
    "        **{col: 'first' for col in df.columns if col not in ['계약번호', 'KTT월정료']},\n",
    "        'KTT월정료': 'sum'\n",
    "    })\n",
    "\n",
    "    # ✅ 컬럼 정렬\n",
    "    final_columns = additional_columns + ['정지일수', '정지일수 구간', '종료희망일 초과 여부', '월정료 구간'] + columns_to_extract\n",
    "    df = df[[col for col in final_columns if col in df.columns]]\n",
    "\n",
    "    # ✅ 엑셀 저장\n",
    "    df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # ✅ 강조 색상 적용 (노란색)\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "    for col in range(1, len(additional_columns) + 5):\n",
    "        for row in range(2, ws.max_row + 1):\n",
    "            ws.cell(row=row, column=col).fill = yellow_fill\n",
    "    wb.save(output_excel_path)\n",
    "\n",
    "    # ✅ CSV 저장 (한글용)\n",
    "    df.to_csv(output_csv_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(f\"\\n✅ 최종 저장 완료! 행 수: {df.shape[0]}\")\n",
    "    print(f\"📄 엑셀 저장 경로: {output_excel_path}\")\n",
    "    print(f\"📄 CSV 저장 경로: {output_csv_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ 오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a30da515-ba71-406d-a6a6-3f99830a8f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 최종 저장 완료! 행 수: 5112\n",
      "📄 엑셀 저장 경로: D:\\시설\\정지\\일일정지\\20250430\\2025년0430_전사 정지조건리스트_완성_중복제거0430-2.xlsx\n",
      "📄 CSV 저장 경로: D:\\시설\\정지\\일일정지\\20250430\\2025년0430_전사 정지조건리스트_완성_중복제거0430-2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import chardet\n",
    "import os\n",
    "\n",
    "# ✅ 인코딩 감지 함수\n",
    "def detect_encoding(file_path, max_bytes=100000):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        sample = f.read(max_bytes)\n",
    "        result = chardet.detect(sample)\n",
    "        encoding = result['encoding']\n",
    "        if encoding and 'euc' in encoding.lower():\n",
    "            encoding = 'cp949'\n",
    "        return encoding or 'cp949'\n",
    "\n",
    "# ✅ 경로 설정\n",
    "file_path = r'D:\\시설\\정지\\일일정지\\20250430\\C150_G0000_00017.csv'\n",
    "additional_file_path = r\"D:\\시설\\유지\\2025\\3월\\3월마감 조건추출 선택컬럼_2403.csv\"\n",
    "output_excel_path = r'D:\\시설\\정지\\일일정지\\20250430\\2025년0430_전사 정지조건리스트_완성_중복제거0430-2.xlsx'\n",
    "output_csv_path = r'D:\\시설\\정지\\일일정지\\20250430\\2025년0430_전사 정지조건리스트_완성_중복제거0430-2.csv'\n",
    "\n",
    "\n",
    "try:\n",
    "    # ✅ 데이터 로드\n",
    "    df = pd.read_csv(file_path, encoding=detect_encoding(file_path), low_memory=False)\n",
    "    additional_df = pd.read_csv(additional_file_path, encoding=detect_encoding(additional_file_path), low_memory=False)\n",
    "\n",
    "    # ✅ 필수 컬럼 정리\n",
    "    columns_to_extract = [\n",
    "        '관리본부명', '관리지사명', '고객번호', '계약번호', '서비스번호', '서비스(대)', '서비스(중)', '서비스(소)',\n",
    "        '상호', '고객구분', '사업용구분', '계약상태(대)', '설치주소', 'KTT월정료(조정)', 'KTT월정료',\n",
    "        '계약시작일', '계약종료일', '영업자명', '정지시작일자', '정지희망종료일', '계약최초서비스게시일', '영업구역정보'\n",
    "    ]\n",
    "    df = df[[col for col in columns_to_extract if col in df.columns]]\n",
    "    df = df[(df['서비스(대)'] == '기본서비스') & (df['사업용구분'] != '사업용')]\n",
    "\n",
    "    # ✅ 본부명 통일\n",
    "    df['관리본부명'] = df['관리본부명'].replace({\n",
    "        '강원본부': '강북/강원본부',\n",
    "        '서부본부': '강남/서부본부'\n",
    "    })\n",
    "\n",
    "    # ✅ 추가 정보 병합\n",
    "    additional_columns = ['시설구분', '요금구분', '제외사유', '매출구분', '실적채널', '고알프', '설치주소']\n",
    "    additional_df = additional_df.drop_duplicates(subset=['계약번호'])\n",
    "    additional_df = additional_df[['계약번호'] + [col for col in additional_columns if col in additional_df.columns]]\n",
    "\n",
    "    for col in additional_columns:\n",
    "        df[col] = df['계약번호'].map(additional_df.set_index('계약번호')[col]).fillna('')\n",
    "\n",
    "    # ✅ 제외사유 제거\n",
    "    if '제외사유' in df.columns:\n",
    "        df['제외사유'] = df['제외사유'].astype(str).str.strip()\n",
    "        df = df[df['제외사유'] == '']\n",
    "\n",
    "    # ✅ KTT월정료 통일 및 숫자화\n",
    "    if 'KTT월정료(조정)' in df.columns:\n",
    "        df['KTT월정료'] = df['KTT월정료(조정)']\n",
    "    elif 'KTT월정료' not in df.columns:\n",
    "        df['KTT월정료'] = ''\n",
    "\n",
    "    df['KTT월정료'] = pd.to_numeric(df['KTT월정료'], errors='coerce').fillna(0)\n",
    "\n",
    "    # ✅ 날짜 포맷 정제\n",
    "    def convert_date(date_str):\n",
    "        try:\n",
    "            if pd.isna(date_str) or not str(date_str).strip():\n",
    "                return None\n",
    "            date_str = str(date_str).strip()\n",
    "            if len(date_str) >= 8:\n",
    "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    for col in ['계약시작일', '계약종료일', '정지시작일자', '정지희망종료일', '계약최초서비스게시일']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).apply(convert_date)\n",
    "\n",
    "    # ✅ 종료희망일 보정\n",
    "    today = datetime.today()\n",
    "    last_day = datetime(today.year, today.month, calendar.monthrange(today.year, today.month)[1])\n",
    "    last_day_str = last_day.strftime(\"%Y-%m-%d\")\n",
    "    df['정지희망종료일'] = df['정지희망종료일'].apply(\n",
    "        lambda x: last_day_str if not x or x == '9999-12-31' else x\n",
    "    )\n",
    "\n",
    "    # ✅ 종료희망일 초과 여부\n",
    "    def check_exceeding(row):\n",
    "        try:\n",
    "            end_date = datetime.strptime(row['정지희망종료일'], '%Y-%m-%d')\n",
    "            return '초과' if end_date <= last_day else '미초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['종료희망일 초과 여부'] = df.apply(check_exceeding, axis=1)\n",
    "\n",
    "    # ✅ 정지일수 계산\n",
    "    def calculate_freeze_days(start, end):\n",
    "        try:\n",
    "            if not start or not end:\n",
    "                return None\n",
    "            start = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "            end = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "            return max((end - start).days + 1, 0)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['정지일수'] = df.apply(lambda row: calculate_freeze_days(row['정지시작일자'], row['정지희망종료일']), axis=1)\n",
    "\n",
    "    # ✅ 정지일수 구간\n",
    "    def categorize_freeze_days(days):\n",
    "        if pd.isna(days): return None\n",
    "        elif days <= 89: return '89일이하'\n",
    "        elif days <= 119: return '90~119일'\n",
    "        elif days <= 149: return '120~149일'\n",
    "        else: return '150일이상'\n",
    "\n",
    "    df['정지일수 구간'] = df['정지일수'].apply(categorize_freeze_days)\n",
    "\n",
    "    # ✅ 계약번호 기준 중복 제거 + KTT월정료 합산\n",
    "    df = df.groupby('계약번호', as_index=False).agg({\n",
    "        **{col: 'first' for col in df.columns if col not in ['계약번호', 'KTT월정료']},\n",
    "        'KTT월정료': 'sum'\n",
    "    })\n",
    "\n",
    "    # ✅ 월정료 구간 재계산\n",
    "    def categorize_fee(val):\n",
    "        try:\n",
    "            if pd.isna(val): return None\n",
    "            amount = float(str(val).replace(',', ''))\n",
    "            if amount <= 50000:\n",
    "                return '5만 이하'\n",
    "            elif amount <= 70000:\n",
    "                return '5만 ~ 7만 이하'\n",
    "            elif amount <= 100000:\n",
    "                return '7만 ~ 10만 이하'\n",
    "            elif amount <= 200000:\n",
    "                return '10만 초과 ~ 20만 이하'\n",
    "            elif amount <= 500000:\n",
    "                return '20만 ~ 50만 이하'\n",
    "            else:\n",
    "                return '50만 초과'\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df['월정료 구간'] = df['KTT월정료'].apply(categorize_fee)\n",
    "\n",
    "    # ✅ 컬럼 순서 정리\n",
    "    final_columns = additional_columns + ['정지일수', '정지일수 구간', '종료희망일 초과 여부', '월정료 구간'] + columns_to_extract\n",
    "    df = df[[col for col in final_columns if col in df.columns]]\n",
    "\n",
    "    # ✅ 엑셀 저장\n",
    "    df.to_excel(output_excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # ✅ 강조 색상 (노란색)\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "    yellow_fill = PatternFill(start_color=\"FFFF99\", end_color=\"FFFF99\", fill_type=\"solid\")\n",
    "    for col in range(1, len(additional_columns) + 5):\n",
    "        for row in range(2, ws.max_row + 1):\n",
    "            ws.cell(row=row, column=col).fill = yellow_fill\n",
    "    wb.save(output_excel_path)\n",
    "\n",
    "    # ✅ CSV 저장 (한글용)\n",
    "    df.to_csv(output_csv_path, index=False, encoding='cp949')\n",
    "\n",
    "    print(f\"\\n✅ 최종 저장 완료! 행 수: {df.shape[0]}\")\n",
    "    print(f\"📄 엑셀 저장 경로: {output_excel_path}\")\n",
    "    print(f\"📄 CSV 저장 경로: {output_csv_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ 오류 발생:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce003b9-6ecb-4ef9-abd1-bee1a13a8c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee1dbc-8736-4f2c-853c-a03fe037b545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6514f-ae7f-46e9-be8d-da59dcbef8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05849ec-dab6-45e1-b9fb-4ef7237a3219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83232af-eb1e-4056-a442-f59477f8d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a1fed-9a04-4fdf-be13-6ddef388fc65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9714419-b73d-4eeb-b266-c7c4d3c7dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
