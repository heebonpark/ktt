{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3936174-b575-4822-b66a-165c19cc1f4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp949' codec can't decode byte 0xab in position 12: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# 인코딩 지정\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp949\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 또는 encoding='euc-kr' 시도\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 모든 DataFrame을 하나로 병합\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0xab in position 12: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일들이 있는 디렉토리 경로\n",
    "directory = \"D:/영업기회자료/영업기회 실적 분석_0903\"\n",
    "\n",
    "# 폴더 내 모든 CSV 파일을 리스트로 가져오기\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# 모든 CSV 파일을 읽어들이고, 하나의 DataFrame으로 병합\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    # 인코딩 지정\n",
    "    df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 DataFrame을 하나로 병합\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 병합된 파일을 저장할 경로\n",
    "output_file = os.path.join(directory, \"merged_output.csv\")\n",
    "\n",
    "# 병합된 데이터 저장\n",
    "merged_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 병합된 데이터 미리보기\n",
    "print(\"병합된 데이터의 상위 5개 행:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"\\n병합된 파일이 성공적으로 저장되었습니다. 저장된 파일 경로: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d6c6b-7503-4524-b046-c3ba7b078f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce213ac-1fdd-4b64-a62e-19c1e7f3af90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35d5d80-808a-4ba5-aa8f-f6b1e32411a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>관리본부코드</th>\n",
       "      <th>관리본부명</th>\n",
       "      <th>관리지사코드</th>\n",
       "      <th>관리지사명</th>\n",
       "      <th>고객번호</th>\n",
       "      <th>고객명</th>\n",
       "      <th>계약번호</th>\n",
       "      <th>유지보수기간</th>\n",
       "      <th>계약자명</th>\n",
       "      <th>서비스번호</th>\n",
       "      <th>...</th>\n",
       "      <th>kt oct 마스터 아이디</th>\n",
       "      <th>정지희망종료일</th>\n",
       "      <th>보조MIN번호</th>\n",
       "      <th>영업지점</th>\n",
       "      <th>설치지점</th>\n",
       "      <th>팩토링여부</th>\n",
       "      <th>외부고객KEY</th>\n",
       "      <th>무인매장구분</th>\n",
       "      <th>무인매장업종구분</th>\n",
       "      <th>팩토링상태</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G000</td>\n",
       "      <td>강북/강원본부</td>\n",
       "      <td>G560</td>\n",
       "      <td>고양지사</td>\n",
       "      <td>31016118</td>\n",
       "      <td>최*임</td>\n",
       "      <td>52010847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>최*임</td>\n",
       "      <td>63095719</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024070e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>미정</td>\n",
       "      <td>NaN</td>\n",
       "      <td>유인매장</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G000</td>\n",
       "      <td>강북/강원본부</td>\n",
       "      <td>G560</td>\n",
       "      <td>고양지사</td>\n",
       "      <td>31016129</td>\n",
       "      <td>최*임</td>\n",
       "      <td>52010871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>최*임</td>\n",
       "      <td>63095782</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024070e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>미정</td>\n",
       "      <td>NaN</td>\n",
       "      <td>유인매장</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G000</td>\n",
       "      <td>강북/강원본부</td>\n",
       "      <td>G560</td>\n",
       "      <td>고양지사</td>\n",
       "      <td>31016700</td>\n",
       "      <td>박*우</td>\n",
       "      <td>52011847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>박*우</td>\n",
       "      <td>63097940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024070e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>미정</td>\n",
       "      <td>NaN</td>\n",
       "      <td>유인매장</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G000</td>\n",
       "      <td>강북/강원본부</td>\n",
       "      <td>G560</td>\n",
       "      <td>고양지사</td>\n",
       "      <td>31016700</td>\n",
       "      <td>박*우</td>\n",
       "      <td>52011847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>박*우</td>\n",
       "      <td>63097942</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024070e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>미정</td>\n",
       "      <td>NaN</td>\n",
       "      <td>유인매장</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G000</td>\n",
       "      <td>강북/강원본부</td>\n",
       "      <td>G560</td>\n",
       "      <td>고양지사</td>\n",
       "      <td>31017013</td>\n",
       "      <td>김*은</td>\n",
       "      <td>52012371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>김*은</td>\n",
       "      <td>63099146</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024071e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>미정</td>\n",
       "      <td>NaN</td>\n",
       "      <td>유인매장</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  관리본부코드    관리본부명 관리지사코드 관리지사명      고객번호  고객명      계약번호  유지보수기간 계약자명  \\\n",
       "0   G000  강북/강원본부   G560  고양지사  31016118  최*임  52010847     NaN  최*임   \n",
       "1   G000  강북/강원본부   G560  고양지사  31016129  최*임  52010871     NaN  최*임   \n",
       "2   G000  강북/강원본부   G560  고양지사  31016700  박*우  52011847     NaN  박*우   \n",
       "3   G000  강북/강원본부   G560  고양지사  31016700  박*우  52011847     NaN  박*우   \n",
       "4   G000  강북/강원본부   G560  고양지사  31017013  김*은  52012371     NaN  김*은   \n",
       "\n",
       "      서비스번호  ... kt oct 마스터 아이디 정지희망종료일 보조MIN번호  영업지점 설치지점 팩토링여부 외부고객KEY  \\\n",
       "0  63095719  ...   2.024070e+12     NaN     NaN   NaN  NaN    미정     NaN   \n",
       "1  63095782  ...   2.024070e+12     NaN     NaN   NaN  NaN    미정     NaN   \n",
       "2  63097940  ...   2.024070e+12     NaN     NaN   NaN  NaN    미정     NaN   \n",
       "3  63097942  ...   2.024070e+12     NaN     NaN   NaN  NaN    미정     NaN   \n",
       "4  63099146  ...   2.024071e+12     NaN     NaN   NaN  NaN    미정     NaN   \n",
       "\n",
       "  무인매장구분  무인매장업종구분 팩토링상태  \n",
       "0   유인매장       NaN   NaN  \n",
       "1   유인매장       NaN   NaN  \n",
       "2   유인매장       NaN   NaN  \n",
       "3   유인매장       NaN   NaN  \n",
       "4   유인매장       NaN   NaN  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞에서 부터 데이터 검색\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43af097-bec3-4cf6-8b4a-10c841a54312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42e898-37a9-4b6b-8f41-6078bed1dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일들이 있는 디렉토리 경로\n",
    "directory = r\"D:\\체납\\11월체납활동\\본사sms발송내역\"\n",
    "\n",
    "# 폴더 내 모든 CSV 파일을 리스트로 가져오기\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# 모든 CSV 파일을 읽어들이고, 하나의 DataFrame으로 병합\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    # 인코딩 지정\n",
    "    df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 DataFrame을 하나로 병합\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 병합된 파일을 저장할 경로\n",
    "output_file = os.path.join(directory, \"merged_output.csv\")\n",
    "\n",
    "# 병합된 데이터 저장\n",
    "merged_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 병합된 데이터 미리보기\n",
    "print(\"병합된 데이터의 상위 5개 행:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"\\n병합된 파일이 성공적으로 저장되었습니다. 저장된 파일 경로: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aacafa-8e49-43fe-a84c-b9b965ca40bd",
   "metadata": {},
   "source": [
    "## 일일유지,해지 병합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83453f2-6169-411e-9ef2-67461b9af270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,33,49,50,55,63,67,68,70,83,96,97,98,109,112,119,121,152,155,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,33,49,50,55,63,67,68,70,83,96,97,98,106,109,112,116,119,121,152,155,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,33,49,50,55,63,67,68,70,83,96,97,98,109,112,116,119,121,152,155,156,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,33,44,49,50,55,63,67,68,70,83,96,97,98,109,112,119,121,152,155,156,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,33,49,50,55,63,67,68,70,83,96,97,98,109,112,119,121,152,155,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,33,44,49,50,55,63,67,68,69,70,83,96,97,98,109,112,119,121,141,152,155,163,169) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,29,33,44,49,50,54,55,63,67,68,69,70,83,96,97,98,106,108,109,111,112,113,116,119,121,127,141,152,155,156,163,169) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11144\\839340287.py:16: DtypeWarning: Columns (17,23,29,33,44,49,50,54,55,63,67,68,70,83,96,97,98,106,108,109,111,112,113,116,119,121,127,141,152,155,156,163,169) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 842. MiB for an array with shape (117, 942922) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# 인코딩 지정\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp949\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 또는 encoding='euc-kr' 시도\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     df_list\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 모든 DataFrame을 하나로 병합\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m   1969\u001b[0m         new_col_dict,\n\u001b[0;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[0;32m   1973\u001b[0m     )\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     mgr\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2270\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2271\u001b[0m     )\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2287\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2294\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([b\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m blocks])  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2296\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 842. MiB for an array with shape (117, 942922) and data type object"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일들이 있는 디렉토리 경로\n",
    "directory = r\"D:\\시설\\일일실적_해지현황(21년)\\전사유지2401~12월\"\n",
    "# directory = r\"D:\\시설\\일일실적_해지현황(21년)\\전사해지2401~12월\"\n",
    "\n",
    "# 폴더 내 모든 CSV 파일을 리스트로 가져오기\n",
    "csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# 모든 CSV 파일을 읽어들이고, 하나의 DataFrame으로 병합\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    # 인코딩 지정\n",
    "    df = pd.read_csv(file_path, encoding='cp949')  # 또는 encoding='euc-kr' 시도\n",
    "    df_list.append(df)\n",
    "\n",
    "# 모든 DataFrame을 하나로 병합\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 병합된 파일을 저장할 경로\n",
    "output_file = os.path.join(directory, \"merged_output.csv\")\n",
    "\n",
    "# 병합된 데이터 저장\n",
    "merged_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 병합된 데이터 미리보기\n",
    "print(\"병합된 데이터의 상위 5개 행:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"\\n병합된 파일이 성공적으로 저장되었습니다. 저장된 파일 경로: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd0262c-ce92-4cb0-acca-5e1a781baf61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c727e-39fc-4809-b4c0-ab495643080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693eb8e-1b25-453e-a106-4e64cbaf7c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
